{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Bricks Identification Project: A Journey of Learning and Adaptation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Motivation 🎯\n",
    "\n",
    "Este proyecto surge como una oportunidad para aplicar y demostrar mis habilidades técnicas en el contexto de un cambio profesional hacia la ciencia de datos e inteligencia artificial. Durante esta transición, decidí combinar mi pasión por los LEGO con mi interés por la visión por computadora, dando vida a una idea que conecta creatividad y tecnología.\n",
    "\n",
    "### 1.1 La Inspiración del Proyecto 🧱\n",
    "\n",
    "LEGO ha sido una de mis pasiones desde la infancia. Me fascinaba cómo piezas aparentemente desordenadas podían transformarse en estructuras organizadas y funcionales. Este proyecto busca replicar esa habilidad humana, enseñando a una máquina a identificar, clasificar y organizar piezas individuales en imágenes desordenadas. Más allá de ser un simple experimento técnico, esta iniciativa refleja mi interés por explorar cómo la inteligencia artificial puede emular procesos humanos de reconocimiento visual.\n",
    "\n",
    "### 1.2 Propósito y Objetivos 🎯\n",
    "\n",
    "El propósito principal del proyecto es desarrollar una solución práctica y escalable que demuestre mis habilidades en ciencia de datos y visión por computadora. Los objetivos específicos incluyen:\n",
    "\n",
    "1. Diseñar un pipeline eficiente para la detección y clasificación de piezas de LEGO.\n",
    "2. Documentar el proceso de desarrollo, desde la creación del dataset hasta la implementación del modelo.\n",
    "3. Generar resultados replicables y visualizaciones claras que destaquen el impacto de mi enfoque técnico.\n",
    "\n",
    "Este proyecto también busca ser una base para aplicaciones futuras, como sistemas de clasificación robótica o asistentes visuales en tiempo real, mostrando la capacidad de escalar esta solución inicial hacia un impacto más amplio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Configuración e Instalación del Entorno en Kaggle 🚀\n",
    "\n",
    "La accesibilidad y reproducibilidad son pilares fundamentales de este proyecto. Por ello, se ha configurado un entorno basado en Kaggle Notebooks, que ofrece acceso gratuito a GPU y una integración sencilla con datasets públicos y privados.\n",
    "\n",
    "#### Código de Configuración Inicial 🖥️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clone the GitHub repository\n",
    "!git clone https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision.git\n",
    "%cd tu_repositorio\n",
    "\n",
    "# Install required libraries\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificación Técnica 📚\n",
    "\n",
    "### Repositorio GitHub 📁\n",
    "Se clonará el repositorio principal del proyecto para mantener sincronizado el código y facilitar su distribución a colaboradores o empleadores.\n",
    "\n",
    "### Instalación de Dependencias 🛠️\n",
    "Las bibliotecas necesarias están especificadas en un archivo `requirements.txt`, lo que asegura que cualquier usuario pueda replicar el entorno.\n",
    "\n",
    "### Uso de GPU 🚀\n",
    "Se verifica automáticamente si hay una GPU disponible, aprovechando las capacidades de Kaggle para entrenamiento acelerado del modelo.\n",
    "\n",
    "## Integración con Kaggle 🌐\n",
    "Se recomienda subir el dataset anotado como un recurso público o privado en Kaggle. Esto permite que los notebooks puedan acceder directamente a los datos, eliminando la necesidad de cargas manuales o configuraciones adicionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creación del Dataset 🗂️\n",
    "\n",
    "El éxito de este proyecto dependió en gran medida de un dataset bien estructurado y diverso que capturara la naturaleza de las piezas de LEGO. El proceso de creación del dataset fue dividido en dos fases principales: una inicial centrada en los ladrillos básicos y otra posterior dedicada a los studs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Recopilación de Datos\n",
    "\n",
    "Para la primera fase, seleccioné ladrillos básicos de mi colección, excluyendo tiles y piezas transparentes, y los clasifiqué por dimensiones. En un espacio bien iluminado, dispuse los ladrillos con suficiente separación para que fueran fácilmente distinguibles. Usando la cámara de mi móvil configurada en modo de baja calidad y captura automática, generé más de 2000 imágenes mientras caminaba lentamente por la habitación, enfocándome en ángulos típicos desde los que un usuario de LEGO observaría las piezas.\n",
    "\n",
    "En la segunda fase, monté un set fotográfico casero utilizando una plataforma giratoria hecha con piezas de LEGO. Coloqué nuevos conjuntos de ladrillos sobre esta plataforma y capturé imágenes desde un trípode con el móvil, utilizando captura automatizada nuevamente.\n",
    "\n",
    "2.2 Procesamiento y Normalización de Imágenes\n",
    "\n",
    "Para garantizar la consistencia en el dataset subido a Kaggle, se desarrolló un script de procesamiento que realiza los siguientes pasos:\n",
    "\n",
    "Redimensionamiento: Todas las imágenes fueron ajustadas a una resolución estándar para optimizar el entrenamiento del modelo.\n",
    "\n",
    "Normalización de Nombres: Los nombres de archivo se renombraron siguiendo un formato coherente (image_#.jpg).\n",
    "\n",
    "Código del Script de Procesamiento 🖥️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Ruta de la carpeta con las imágenes originales\n",
    "data_dir = \"path_to_images\"\n",
    "processed_dir = \"processed_images\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Parámetros para redimensionar\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Procesamiento de imágenes\n",
    "for i, filename in enumerate(sorted(os.listdir(data_dir))):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img = Image.open(os.path.join(data_dir, filename))\n",
    "        img_resized = img.resize(target_size)\n",
    "        new_filename = f\"image_{i}.jpg\"\n",
    "        img_resized.save(os.path.join(processed_dir, new_filename))\n",
    "        print(f\"Processed {filename} -> {new_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Recopilación de Datos 📸\n",
    "\n",
    "Para la primera fase, seleccioné ladrillos básicos de mi colección, excluyendo tiles y piezas transparentes, y los clasifiqué por dimensiones. En un espacio bien iluminado, dispuse los ladrillos con suficiente separación para que fueran fácilmente distinguibles. Usando la cámara de mi móvil configurada en modo de baja calidad y captura automática, generé más de 2000 imágenes mientras caminaba lentamente por la habitación, enfocándome en ángulos típicos desde los que un usuario de LEGO observaría las piezas.\n",
    "\n",
    "En la segunda fase, monté un set fotográfico casero utilizando una plataforma giratoria hecha con piezas de LEGO. Coloqué nuevos conjuntos de ladrillos sobre esta plataforma y capturé imágenes desde un trípode con el móvil, utilizando captura automatizada nuevamente.\n",
    "\n",
    "### 2.2 Anotación de los Datos 📝\n",
    "\n",
    "En la primera fase, utilicé LabelMe para anotar las piezas con bounding boxes en las más de 2000 imágenes, eliminando aquellas que estaban borrosas. Posteriormente, desarrollé scripts para convertir estas anotaciones al formato compatible con YOLO y organizar las carpetas de acuerdo con los requerimientos del modelo.\n",
    "\n",
    "En la segunda fase, utilicé un modelo entrenado inicialmente para detectar ladrillos y generé anotaciones de puntos (point annotations) dentro de las bounding boxes recortadas. Un script adicional transformó estos puntos en nuevas bounding boxes dinámicas, adaptándose a las dimensiones y posiciones de los studs detectados.\n",
    "\n",
    "### 2.3 Limpieza y Preparación del Dataset 🧹\n",
    "\n",
    "Las imágenes borrosas o redundantes fueron eliminadas. Para mitigar la falta de calidad en algunas capturas iniciales, implementé técnicas de aumento de datos (data augmentation) directamente en el alimentador del modelo durante las sesiones de entrenamiento. Esto incluyó rotaciones, variaciones de iluminación y espejado para incrementar la diversidad de las muestras.\n",
    "\n",
    "### 2.4 Insights para Iteraciones Futuras 🔍\n",
    "\n",
    "- **Automatización en la anotación inicial**: Considera herramientas como Supervisely o plataformas que integren anotación semiautomática para acelerar procesos iniciales de bounding boxes.\n",
    "- **Mejorar la calidad inicial**: Aunque la baja calidad fue útil para la primera fase, para futuros proyectos se recomienda una resolución estándar para maximizar el detalle en las imágenes.\n",
    "- **Balance de clases**: Implementar análisis de distribución más temprano en el proceso puede garantizar un balance adecuado en el dataset y evitar clases subrepresentadas.\n",
    "- **Data augmentation externo**: Herramientas como Albumentations o Fastai podrían ofrecer técnicas más avanzadas de aumento, como distorsiones geométricas y filtros, fuera del alimentador del modelo.\n",
    "- **Pruebas preliminares del modelo**: Entrenar modelos pequeños desde el inicio puede revelar rápidamente problemas en el dataset, como errores de anotación o distribuciones desbalanceadas, y ahorrar tiempo en iteraciones posteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selección del Modelo 🤖\n",
    "\n",
    "### 3.1 Elección del Modelo 🏆\n",
    "\n",
    "El desafío central del proyecto era diseñar un modelo que pudiera identificar piezas individuales de LEGO en imágenes desordenadas y con condiciones variables de iluminación y fondo. Para abordar este problema, era crucial elegir un modelo que equilibrara precisión, rapidez y facilidad de implementación. Tras investigar varias opciones, seleccioné YOLO (You Only Look Once), específicamente la versión YOLOv8n, por las siguientes razones:\n",
    "\n",
    "- **Simplicidad y Configuración Inicial**: YOLO ofrecía una configuración amigable para mi hardware con capacidades de GPU limitadas. Su implementación directa me permitió centrarme más en la preparación del dataset y en los ajustes iterativos.\n",
    "- **Velocidad en Detección en Tiempo Real**: YOLO es conocido por su capacidad de realizar detecciones en una sola pasada de red neuronal, optimizando tanto el tiempo como el uso de recursos computacionales. Esto resultó ideal para entrenar y validar rápidamente el modelo con un dataset en constante refinamiento.\n",
    "- **Robustez en Ambientes Complejos**: Su arquitectura permite manejar imágenes con múltiples objetos, incluso en escenarios donde las piezas están parcialmente ocluidas, lo que alineaba perfectamente con las condiciones del proyecto.\n",
    "\n",
    "### 3.2 Estrategia de Entrenamiento y Adaptación 🛠️\n",
    "\n",
    "El proceso de entrenamiento incluyó los siguientes pasos:\n",
    "\n",
    "- **Creación y Preparación del Dataset**: Se definió un pipeline para convertir anotaciones en formato LabelMe a un formato compatible con YOLO. Esto incluyó la limpieza de datos, aumento (augmentation) durante el entrenamiento y un split 80-20 para entrenamiento y validación.\n",
    "- **Hiperparámetros**: Ajusté los siguientes parámetros clave para optimizar el rendimiento:\n",
    "    - Tamaño de imágenes: Utilicé imágenes redimensionadas para maximizar la compatibilidad con el modelo.\n",
    "    - Épocas: Comencé con 50 épocas para pruebas rápidas, aumentando gradualmente según los resultados.\n",
    "    - Tasa de aprendizaje inicial: 0.001, con un decaimiento cíclico (cos_lr).\n",
    "- **Uso de Scripts Personalizados**: Implementé scripts para:\n",
    "    - Recortar piezas detectadas en imágenes, simplificando tareas posteriores de clasificación.\n",
    "    - Transformar anotaciones de puntos clave en bounding boxes adaptativas según los studs detectados y dimensiones de entrada.\n",
    "- **Iteraciones y Validación**: Cada iteración del modelo fue validada visualizando predicciones sobre nuevas imágenes del dataset, ajustando hiperparámetros según las métricas de precisión y recall.\n",
    "\n",
    "### 3.3 Ejemplos y Visualizaciones 📊\n",
    "\n",
    "Para esta sección se incluirán:\n",
    "\n",
    "- Imágenes con Bounding Boxes de ladrillos detectados: Visualizaciones de ejemplos representativos de detecciones exitosas, resaltando piezas con múltiples colores y tamaños.\n",
    "- Comparación antes y después del modelo: Mostrar ejemplos de imágenes con y sin anotaciones generadas automáticamente por el modelo.\n",
    "- Visualización de transformación de keypoints a bounding boxes: Ejemplos ilustrativos de cómo las anotaciones de studs se convirtieron en cajas 2D.\n",
    "\n",
    "## 4. Próximos Pasos 🚀\n",
    "\n",
    "El desarrollo iterativo del modelo ha proporcionado un camino claro para expandir el alcance del proyecto. A medida que se continúe mejorando, estas iteraciones ayudarán a explorar nuevas áreas de aplicación y optimización en el reconocimiento visual de LEGO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementación del Modelo y Validación 🤖\n",
    "\n",
    "### 4.1 Entrenamiento Inicial y Ajustes 🛠️\n",
    "\n",
    "Una vez seleccionado el modelo YOLOv8n, el entrenamiento se realizó iterativamente para ajustar el modelo a las condiciones específicas del dataset:\n",
    "\n",
    "- **Inicio del Entrenamiento**: Se utilizó el dataset procesado y anotado para realizar pruebas iniciales con un modelo preentrenado. Estas pruebas se centraron en establecer una base para los parámetros clave, como el tamaño de las imágenes y el número de épocas.\n",
    "- **Evaluación Continua**: Durante el entrenamiento, se monitorearon métricas como la precisión y el recall para identificar áreas de mejora. Las visualizaciones de las predicciones ayudaron a identificar sesgos o problemas en el dataset.\n",
    "\n",
    "### 4.2 Validación en Escenarios Controlados 🧪\n",
    "\n",
    "Para evaluar el rendimiento del modelo:\n",
    "\n",
    "- **Pruebas en Dataset Anotado**: Se utilizaron imágenes del conjunto de validación para comparar la detección y clasificación con las etiquetas originales. Esto permitió identificar las clases o condiciones donde el modelo tenía mayor dificultad.\n",
    "- **Pruebas con Transformaciones**: Se aplicaron aumentos artificiales (rotaciones, cambios de iluminación, etc.) para evaluar la robustez del modelo ante variaciones comunes en la captura de imágenes.\n",
    "\n",
    "### 4.3 Resultados en Imágenes Reales 📸\n",
    "\n",
    "El modelo fue probado en escenarios más diversos:\n",
    "\n",
    "- **Colección No Anotada**: Se seleccionaron imágenes reales del entorno, no incluidas en el entrenamiento, para validar la capacidad del modelo en condiciones no vistas.\n",
    "- **Evaluación de Robustez**: Se analizaron las predicciones en piezas o configuraciones no consideradas en el diseño inicial del dataset, evaluando su capacidad de generalización.\n",
    "\n",
    "### 4.4 Visualizaciones y Métricas 📊\n",
    "\n",
    "Para esta sección se incluirán:\n",
    "\n",
    "- **Predicciones con Bounding Boxes**: Imágenes que muestran cómo el modelo detecta las piezas, con especial atención a las detecciones erróneas o falsas positivas.\n",
    "- **Estadísticas Generales**: Tablas y gráficos que presentan las métricas clave: precisión, recall, F1-score, y tiempo promedio por predicción.\n",
    "- **Análisis Comparativo**: Comparación de ejemplos con predicciones y etiquetas originales, mostrando casos representativos de éxito y áreas de mejora.\n",
    "- **Visualización Tipo Spread Grid**: Una visualización tipo grid de miniaturas, mostrando imágenes anotadas aleatorias de todo el dataset.\n",
    "\n",
    "## 5. Próximos Pasos 🚀\n",
    "\n",
    "El desarrollo iterativo del modelo ha proporcionado un camino claro para expandir el alcance del proyecto. A medida que se continúe mejorando, estas iteraciones ayudarán a explorar nuevas áreas de aplicación y optimización en el reconocimiento visual de LEGO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflexión y Futuro 🔍\n",
    "\n",
    "### 5.1 Lecciones Aprendidas 📚\n",
    "\n",
    "Este proyecto no solo amplió mis conocimientos técnicos en visión por computadora y machine learning, sino que también reforzó habilidades esenciales como:\n",
    "\n",
    "- **Gestión de Proyectos Técnicos**: Desde la conceptualización hasta la ejecución, aprendí a planificar y priorizar tareas clave para lograr un resultado completo.\n",
    "- **Iteración y Resolución de Problemas**: Los desafíos encontrados, como la selección inicial de MediaPipe y ajustes en el dataset, me enseñaron a ser flexible y adaptarme rápidamente.\n",
    "- **Documentación y Visualización**: Documentar el proceso de manera clara y crear visualizaciones efectivas fue crucial para comunicar el impacto del trabajo.\n",
    "\n",
    "### 5.2 Mejoras Futuras 🔧\n",
    "\n",
    "Si pudiera comenzar de nuevo, consideraría:\n",
    "\n",
    "- **Ampliar el Dataset Inicial**: Incluir más clases y piezas más variadas desde el principio habría mejorado la capacidad del modelo para generalizar.\n",
    "- **Explorar Alternativas a YOLO**: Experimentar con otros modelos para comparar rendimiento y adaptabilidad.\n",
    "- **Automatizar Anotaciones**: Implementar técnicas más avanzadas para reducir el tiempo dedicado a tareas manuales.\n",
    "\n",
    "### 5.3 Próximos Pasos 🚀\n",
    "\n",
    "- **Optimización del Modelo**: Afinar los hiperparámetros y explorar técnicas de fine-tuning más avanzadas.\n",
    "- **Ampliación del Dataset**: Incorporar nuevos tipos de piezas, incluidos tiles y elementos transparentes.\n",
    "- **Desarrollo de una Interfaz**: Crear una aplicación interactiva que permita a los usuarios cargar imágenes y obtener predicciones en tiempo real.\n",
    "- **Exploración de Nuevas Aplicaciones**: Investigar cómo este pipeline podría adaptarse a otros dominios, como la clasificación de piezas en manufactura o reciclaje.\n",
    "\n",
    "Con estos pasos, espero seguir construyendo sobre este proyecto y expandiendo su alcance e impacto potencial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnvHaB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
