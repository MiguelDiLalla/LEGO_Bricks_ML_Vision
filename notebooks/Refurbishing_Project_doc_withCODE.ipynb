{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Bricks Identification Project: A Journey of Learning and Adaptation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Motivation \n",
    "\n",
    "Este proyecto surge como una oportunidad para aplicar y demostrar mis habilidades t茅cnicas en el contexto de un cambio profesional hacia la ciencia de datos e inteligencia artificial. Durante esta transici贸n, decid铆 combinar mi pasi贸n por los LEGO con mi inter茅s por la visi贸n por computadora, dando vida a una idea que conecta creatividad y tecnolog铆a.\n",
    "\n",
    "### 1.1 La Inspiraci贸n del Proyecto П\n",
    "\n",
    "LEGO ha sido una de mis pasiones desde la infancia. Me fascinaba c贸mo piezas aparentemente desordenadas pod铆an transformarse en estructuras organizadas y funcionales. Este proyecto busca replicar esa habilidad humana, ense帽ando a una m谩quina a identificar, clasificar y organizar piezas individuales en im谩genes desordenadas. M谩s all谩 de ser un simple experimento t茅cnico, esta iniciativa refleja mi inter茅s por explorar c贸mo la inteligencia artificial puede emular procesos humanos de reconocimiento visual.\n",
    "\n",
    "### 1.2 Prop贸sito y Objetivos \n",
    "\n",
    "El prop贸sito principal del proyecto es desarrollar una soluci贸n pr谩ctica y escalable que demuestre mis habilidades en ciencia de datos y visi贸n por computadora. Los objetivos espec铆ficos incluyen:\n",
    "\n",
    "1. Dise帽ar un pipeline eficiente para la detecci贸n y clasificaci贸n de piezas de LEGO.\n",
    "2. Documentar el proceso de desarrollo, desde la creaci贸n del dataset hasta la implementaci贸n del modelo.\n",
    "3. Generar resultados replicables y visualizaciones claras que destaquen el impacto de mi enfoque t茅cnico.\n",
    "\n",
    "Este proyecto tambi茅n busca ser una base para aplicaciones futuras, como sistemas de clasificaci贸n rob贸tica o asistentes visuales en tiempo real, mostrando la capacidad de escalar esta soluci贸n inicial hacia un impacto m谩s amplio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Configuraci贸n e Instalaci贸n del Entorno en Kaggle \n",
    "\n",
    "La accesibilidad y reproducibilidad son pilares fundamentales de este proyecto. Por ello, se ha configurado un entorno basado en Kaggle Notebooks, que ofrece acceso gratuito a GPU y una integraci贸n sencilla con datasets p煤blicos y privados.\n",
    "\n",
    "#### C贸digo de Configuraci贸n Inicial ワ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clone the GitHub repository\n",
    "!git clone https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision.git\n",
    "%cd tu_repositorio\n",
    "\n",
    "# Install required libraries\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificaci贸n T茅cnica \n",
    "\n",
    "### Repositorio GitHub \n",
    "Se clonar谩 el repositorio principal del proyecto para mantener sincronizado el c贸digo y facilitar su distribuci贸n a colaboradores o empleadores.\n",
    "\n",
    "### Instalaci贸n de Dependencias 锔\n",
    "Las bibliotecas necesarias est谩n especificadas en un archivo `requirements.txt`, lo que asegura que cualquier usuario pueda replicar el entorno.\n",
    "\n",
    "### Uso de GPU \n",
    "Se verifica autom谩ticamente si hay una GPU disponible, aprovechando las capacidades de Kaggle para entrenamiento acelerado del modelo.\n",
    "\n",
    "## Integraci贸n con Kaggle \n",
    "Se recomienda subir el dataset anotado como un recurso p煤blico o privado en Kaggle. Esto permite que los notebooks puedan acceder directamente a los datos, eliminando la necesidad de cargas manuales o configuraciones adicionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creaci贸n del Dataset 锔\n",
    "\n",
    "El 茅xito de este proyecto dependi贸 en gran medida de un dataset bien estructurado y diverso que capturara la naturaleza de las piezas de LEGO. El proceso de creaci贸n del dataset fue dividido en dos fases principales: una inicial centrada en los ladrillos b谩sicos y otra posterior dedicada a los studs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Recopilaci贸n de Datos\n",
    "\n",
    "Para la primera fase, seleccion茅 ladrillos b谩sicos de mi colecci贸n, excluyendo tiles y piezas transparentes, y los clasifiqu茅 por dimensiones. En un espacio bien iluminado, dispuse los ladrillos con suficiente separaci贸n para que fueran f谩cilmente distinguibles. Usando la c谩mara de mi m贸vil configurada en modo de baja calidad y captura autom谩tica, gener茅 m谩s de 2000 im谩genes mientras caminaba lentamente por la habitaci贸n, enfoc谩ndome en 谩ngulos t铆picos desde los que un usuario de LEGO observar铆a las piezas.\n",
    "\n",
    "En la segunda fase, mont茅 un set fotogr谩fico casero utilizando una plataforma giratoria hecha con piezas de LEGO. Coloqu茅 nuevos conjuntos de ladrillos sobre esta plataforma y captur茅 im谩genes desde un tr铆pode con el m贸vil, utilizando captura automatizada nuevamente.\n",
    "\n",
    "2.2 Procesamiento y Normalizaci贸n de Im谩genes\n",
    "\n",
    "Para garantizar la consistencia en el dataset subido a Kaggle, se desarroll贸 un script de procesamiento que realiza los siguientes pasos:\n",
    "\n",
    "Redimensionamiento: Todas las im谩genes fueron ajustadas a una resoluci贸n est谩ndar para optimizar el entrenamiento del modelo.\n",
    "\n",
    "Normalizaci贸n de Nombres: Los nombres de archivo se renombraron siguiendo un formato coherente (image_#.jpg).\n",
    "\n",
    "C贸digo del Script de Procesamiento ワ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Ruta de la carpeta con las im谩genes originales\n",
    "data_dir = \"path_to_images\"\n",
    "processed_dir = \"processed_images\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Par谩metros para redimensionar\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Procesamiento de im谩genes\n",
    "for i, filename in enumerate(sorted(os.listdir(data_dir))):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img = Image.open(os.path.join(data_dir, filename))\n",
    "        img_resized = img.resize(target_size)\n",
    "        new_filename = f\"image_{i}.jpg\"\n",
    "        img_resized.save(os.path.join(processed_dir, new_filename))\n",
    "        print(f\"Processed {filename} -> {new_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Recopilaci贸n de Datos \n",
    "\n",
    "Para la primera fase, seleccion茅 ladrillos b谩sicos de mi colecci贸n, excluyendo tiles y piezas transparentes, y los clasifiqu茅 por dimensiones. En un espacio bien iluminado, dispuse los ladrillos con suficiente separaci贸n para que fueran f谩cilmente distinguibles. Usando la c谩mara de mi m贸vil configurada en modo de baja calidad y captura autom谩tica, gener茅 m谩s de 2000 im谩genes mientras caminaba lentamente por la habitaci贸n, enfoc谩ndome en 谩ngulos t铆picos desde los que un usuario de LEGO observar铆a las piezas.\n",
    "\n",
    "En la segunda fase, mont茅 un set fotogr谩fico casero utilizando una plataforma giratoria hecha con piezas de LEGO. Coloqu茅 nuevos conjuntos de ladrillos sobre esta plataforma y captur茅 im谩genes desde un tr铆pode con el m贸vil, utilizando captura automatizada nuevamente.\n",
    "\n",
    "### 2.2 Anotaci贸n de los Datos \n",
    "\n",
    "En la primera fase, utilic茅 LabelMe para anotar las piezas con bounding boxes en las m谩s de 2000 im谩genes, eliminando aquellas que estaban borrosas. Posteriormente, desarroll茅 scripts para convertir estas anotaciones al formato compatible con YOLO y organizar las carpetas de acuerdo con los requerimientos del modelo.\n",
    "\n",
    "En la segunda fase, utilic茅 un modelo entrenado inicialmente para detectar ladrillos y gener茅 anotaciones de puntos (point annotations) dentro de las bounding boxes recortadas. Un script adicional transform贸 estos puntos en nuevas bounding boxes din谩micas, adapt谩ndose a las dimensiones y posiciones de los studs detectados.\n",
    "\n",
    "### 2.3 Limpieza y Preparaci贸n del Dataset Ч\n",
    "\n",
    "Las im谩genes borrosas o redundantes fueron eliminadas. Para mitigar la falta de calidad en algunas capturas iniciales, implement茅 t茅cnicas de aumento de datos (data augmentation) directamente en el alimentador del modelo durante las sesiones de entrenamiento. Esto incluy贸 rotaciones, variaciones de iluminaci贸n y espejado para incrementar la diversidad de las muestras.\n",
    "\n",
    "### 2.4 Insights para Iteraciones Futuras \n",
    "\n",
    "- **Automatizaci贸n en la anotaci贸n inicial**: Considera herramientas como Supervisely o plataformas que integren anotaci贸n semiautom谩tica para acelerar procesos iniciales de bounding boxes.\n",
    "- **Mejorar la calidad inicial**: Aunque la baja calidad fue 煤til para la primera fase, para futuros proyectos se recomienda una resoluci贸n est谩ndar para maximizar el detalle en las im谩genes.\n",
    "- **Balance de clases**: Implementar an谩lisis de distribuci贸n m谩s temprano en el proceso puede garantizar un balance adecuado en el dataset y evitar clases subrepresentadas.\n",
    "- **Data augmentation externo**: Herramientas como Albumentations o Fastai podr铆an ofrecer t茅cnicas m谩s avanzadas de aumento, como distorsiones geom茅tricas y filtros, fuera del alimentador del modelo.\n",
    "- **Pruebas preliminares del modelo**: Entrenar modelos peque帽os desde el inicio puede revelar r谩pidamente problemas en el dataset, como errores de anotaci贸n o distribuciones desbalanceadas, y ahorrar tiempo en iteraciones posteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecci贸n del Modelo \n",
    "\n",
    "### 3.1 Elecci贸n del Modelo \n",
    "\n",
    "El desaf铆o central del proyecto era dise帽ar un modelo que pudiera identificar piezas individuales de LEGO en im谩genes desordenadas y con condiciones variables de iluminaci贸n y fondo. Para abordar este problema, era crucial elegir un modelo que equilibrara precisi贸n, rapidez y facilidad de implementaci贸n. Tras investigar varias opciones, seleccion茅 YOLO (You Only Look Once), espec铆ficamente la versi贸n YOLOv8n, por las siguientes razones:\n",
    "\n",
    "- **Simplicidad y Configuraci贸n Inicial**: YOLO ofrec铆a una configuraci贸n amigable para mi hardware con capacidades de GPU limitadas. Su implementaci贸n directa me permiti贸 centrarme m谩s en la preparaci贸n del dataset y en los ajustes iterativos.\n",
    "- **Velocidad en Detecci贸n en Tiempo Real**: YOLO es conocido por su capacidad de realizar detecciones en una sola pasada de red neuronal, optimizando tanto el tiempo como el uso de recursos computacionales. Esto result贸 ideal para entrenar y validar r谩pidamente el modelo con un dataset en constante refinamiento.\n",
    "- **Robustez en Ambientes Complejos**: Su arquitectura permite manejar im谩genes con m煤ltiples objetos, incluso en escenarios donde las piezas est谩n parcialmente ocluidas, lo que alineaba perfectamente con las condiciones del proyecto.\n",
    "\n",
    "### 3.2 Estrategia de Entrenamiento y Adaptaci贸n 锔\n",
    "\n",
    "El proceso de entrenamiento incluy贸 los siguientes pasos:\n",
    "\n",
    "- **Creaci贸n y Preparaci贸n del Dataset**: Se defini贸 un pipeline para convertir anotaciones en formato LabelMe a un formato compatible con YOLO. Esto incluy贸 la limpieza de datos, aumento (augmentation) durante el entrenamiento y un split 80-20 para entrenamiento y validaci贸n.\n",
    "- **Hiperpar谩metros**: Ajust茅 los siguientes par谩metros clave para optimizar el rendimiento:\n",
    "    - Tama帽o de im谩genes: Utilic茅 im谩genes redimensionadas para maximizar la compatibilidad con el modelo.\n",
    "    - pocas: Comenc茅 con 50 茅pocas para pruebas r谩pidas, aumentando gradualmente seg煤n los resultados.\n",
    "    - Tasa de aprendizaje inicial: 0.001, con un decaimiento c铆clico (cos_lr).\n",
    "- **Uso de Scripts Personalizados**: Implement茅 scripts para:\n",
    "    - Recortar piezas detectadas en im谩genes, simplificando tareas posteriores de clasificaci贸n.\n",
    "    - Transformar anotaciones de puntos clave en bounding boxes adaptativas seg煤n los studs detectados y dimensiones de entrada.\n",
    "- **Iteraciones y Validaci贸n**: Cada iteraci贸n del modelo fue validada visualizando predicciones sobre nuevas im谩genes del dataset, ajustando hiperpar谩metros seg煤n las m茅tricas de precisi贸n y recall.\n",
    "\n",
    "### 3.3 Ejemplos y Visualizaciones \n",
    "\n",
    "Para esta secci贸n se incluir谩n:\n",
    "\n",
    "- Im谩genes con Bounding Boxes de ladrillos detectados: Visualizaciones de ejemplos representativos de detecciones exitosas, resaltando piezas con m煤ltiples colores y tama帽os.\n",
    "- Comparaci贸n antes y despu茅s del modelo: Mostrar ejemplos de im谩genes con y sin anotaciones generadas autom谩ticamente por el modelo.\n",
    "- Visualizaci贸n de transformaci贸n de keypoints a bounding boxes: Ejemplos ilustrativos de c贸mo las anotaciones de studs se convirtieron en cajas 2D.\n",
    "\n",
    "## 4. Pr贸ximos Pasos \n",
    "\n",
    "El desarrollo iterativo del modelo ha proporcionado un camino claro para expandir el alcance del proyecto. A medida que se contin煤e mejorando, estas iteraciones ayudar谩n a explorar nuevas 谩reas de aplicaci贸n y optimizaci贸n en el reconocimiento visual de LEGO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementaci贸n del Modelo y Validaci贸n \n",
    "\n",
    "### 4.1 Entrenamiento Inicial y Ajustes 锔\n",
    "\n",
    "Una vez seleccionado el modelo YOLOv8n, el entrenamiento se realiz贸 iterativamente para ajustar el modelo a las condiciones espec铆ficas del dataset:\n",
    "\n",
    "- **Inicio del Entrenamiento**: Se utiliz贸 el dataset procesado y anotado para realizar pruebas iniciales con un modelo preentrenado. Estas pruebas se centraron en establecer una base para los par谩metros clave, como el tama帽o de las im谩genes y el n煤mero de 茅pocas.\n",
    "- **Evaluaci贸n Continua**: Durante el entrenamiento, se monitorearon m茅tricas como la precisi贸n y el recall para identificar 谩reas de mejora. Las visualizaciones de las predicciones ayudaron a identificar sesgos o problemas en el dataset.\n",
    "\n",
    "### 4.2 Validaci贸n en Escenarios Controlados И\n",
    "\n",
    "Para evaluar el rendimiento del modelo:\n",
    "\n",
    "- **Pruebas en Dataset Anotado**: Se utilizaron im谩genes del conjunto de validaci贸n para comparar la detecci贸n y clasificaci贸n con las etiquetas originales. Esto permiti贸 identificar las clases o condiciones donde el modelo ten铆a mayor dificultad.\n",
    "- **Pruebas con Transformaciones**: Se aplicaron aumentos artificiales (rotaciones, cambios de iluminaci贸n, etc.) para evaluar la robustez del modelo ante variaciones comunes en la captura de im谩genes.\n",
    "\n",
    "### 4.3 Resultados en Im谩genes Reales \n",
    "\n",
    "El modelo fue probado en escenarios m谩s diversos:\n",
    "\n",
    "- **Colecci贸n No Anotada**: Se seleccionaron im谩genes reales del entorno, no incluidas en el entrenamiento, para validar la capacidad del modelo en condiciones no vistas.\n",
    "- **Evaluaci贸n de Robustez**: Se analizaron las predicciones en piezas o configuraciones no consideradas en el dise帽o inicial del dataset, evaluando su capacidad de generalizaci贸n.\n",
    "\n",
    "### 4.4 Visualizaciones y M茅tricas \n",
    "\n",
    "Para esta secci贸n se incluir谩n:\n",
    "\n",
    "- **Predicciones con Bounding Boxes**: Im谩genes que muestran c贸mo el modelo detecta las piezas, con especial atenci贸n a las detecciones err贸neas o falsas positivas.\n",
    "- **Estad铆sticas Generales**: Tablas y gr谩ficos que presentan las m茅tricas clave: precisi贸n, recall, F1-score, y tiempo promedio por predicci贸n.\n",
    "- **An谩lisis Comparativo**: Comparaci贸n de ejemplos con predicciones y etiquetas originales, mostrando casos representativos de 茅xito y 谩reas de mejora.\n",
    "- **Visualizaci贸n Tipo Spread Grid**: Una visualizaci贸n tipo grid de miniaturas, mostrando im谩genes anotadas aleatorias de todo el dataset.\n",
    "\n",
    "## 5. Pr贸ximos Pasos \n",
    "\n",
    "El desarrollo iterativo del modelo ha proporcionado un camino claro para expandir el alcance del proyecto. A medida que se contin煤e mejorando, estas iteraciones ayudar谩n a explorar nuevas 谩reas de aplicaci贸n y optimizaci贸n en el reconocimiento visual de LEGO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflexi贸n y Futuro \n",
    "\n",
    "### 5.1 Lecciones Aprendidas \n",
    "\n",
    "Este proyecto no solo ampli贸 mis conocimientos t茅cnicos en visi贸n por computadora y machine learning, sino que tambi茅n reforz贸 habilidades esenciales como:\n",
    "\n",
    "- **Gesti贸n de Proyectos T茅cnicos**: Desde la conceptualizaci贸n hasta la ejecuci贸n, aprend铆 a planificar y priorizar tareas clave para lograr un resultado completo.\n",
    "- **Iteraci贸n y Resoluci贸n de Problemas**: Los desaf铆os encontrados, como la selecci贸n inicial de MediaPipe y ajustes en el dataset, me ense帽aron a ser flexible y adaptarme r谩pidamente.\n",
    "- **Documentaci贸n y Visualizaci贸n**: Documentar el proceso de manera clara y crear visualizaciones efectivas fue crucial para comunicar el impacto del trabajo.\n",
    "\n",
    "### 5.2 Mejoras Futuras \n",
    "\n",
    "Si pudiera comenzar de nuevo, considerar铆a:\n",
    "\n",
    "- **Ampliar el Dataset Inicial**: Incluir m谩s clases y piezas m谩s variadas desde el principio habr铆a mejorado la capacidad del modelo para generalizar.\n",
    "- **Explorar Alternativas a YOLO**: Experimentar con otros modelos para comparar rendimiento y adaptabilidad.\n",
    "- **Automatizar Anotaciones**: Implementar t茅cnicas m谩s avanzadas para reducir el tiempo dedicado a tareas manuales.\n",
    "\n",
    "### 5.3 Pr贸ximos Pasos \n",
    "\n",
    "- **Optimizaci贸n del Modelo**: Afinar los hiperpar谩metros y explorar t茅cnicas de fine-tuning m谩s avanzadas.\n",
    "- **Ampliaci贸n del Dataset**: Incorporar nuevos tipos de piezas, incluidos tiles y elementos transparentes.\n",
    "- **Desarrollo de una Interfaz**: Crear una aplicaci贸n interactiva que permita a los usuarios cargar im谩genes y obtener predicciones en tiempo real.\n",
    "- **Exploraci贸n de Nuevas Aplicaciones**: Investigar c贸mo este pipeline podr铆a adaptarse a otros dominios, como la clasificaci贸n de piezas en manufactura o reciclaje.\n",
    "\n",
    "Con estos pasos, espero seguir construyendo sobre este proyecto y expandiendo su alcance e impacto potencial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnvHaB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
