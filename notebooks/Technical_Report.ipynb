{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d843645",
   "metadata": {},
   "source": [
    "## LEGO Bricks Identification Project: A Technical Report\n",
    "\n",
    "### 1. Introduction and Motivation üåü\n",
    "\n",
    "This project leverages the **`lego-bricks-ml-vision`** package to implement an efficient pipeline for detecting and classifying LEGO bricks. Inspired by the challenge of identifying specific pieces within a cluttered set of LEGO bricks, this project combines computer vision, machine learning, and dataset management to achieve scalable and replicable results.\n",
    "\n",
    "The key objectives include:\n",
    "\n",
    "1. Designing a pipeline for object detection using YOLOv8.\n",
    "2. Documenting the process to ensure reproducibility and scalability.\n",
    "3. Providing tools for visualization and analysis to showcase the model‚Äôs performance.\n",
    "\n",
    "### 2. Dataset Creation üìù\n",
    "\n",
    "The dataset creation process is streamlined using the **`lego-bricks-ml-vision`** package. This package provides commands for downloading datasets, preprocessing images, and converting annotations.\n",
    "\n",
    "#### 2.1 Dataset Overview \n",
    "\n",
    "The dataset used for this project is hosted on Kaggle:\n",
    "- **Dataset Name**: [Spiled LEGO Bricks](https://www.kaggle.com/datasets/migueldilalla/spiled-lego-bricks)\n",
    "- **Contents**:\n",
    "  - **Images**: 1803 images (600√ó800 resolution)\n",
    "  - **Annotations**: LabelMe-compatible `.txt` files with bounding box data.\n",
    "\n",
    "#### 2.2 Setting Up the Environment \n",
    "\n",
    "Install the **`lego-bricks-ml-vision`** package from PyPI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lego-bricks-ml-vision\n",
    "\n",
    "!pip show lego-bricks-ml-vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.config/kaggle\n",
    "!cp kaggle.json ~/.config/kaggle/\n",
    "!chmod 600 ~/.config/kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac11ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd456b",
   "metadata": {},
   "source": [
    "\n",
    "Configure the pipeline:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lego_bricks_ml_vision import setup_environment\n",
    "setup_environment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a97d5",
   "metadata": {},
   "source": [
    "\n",
    "This command ensures that all dependencies are installed and that your environment is ready.\n",
    "\n",
    "#### 2.3 Downloading the Dataset \n",
    "\n",
    "The dataset can be directly downloaded and extracted using the following commands:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174806f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-pipeline download-dataset \\\n",
    "    --kaggle-dataset \"migueldilalla/spiled-lego-bricks\" \\\n",
    "    --output-dir \"datasets\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21b8a0",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.4 Preprocessing Images \n",
    "\n",
    "Resize the images to a consistent size (e.g., 256x256) for model training:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-pipeline preprocess-images \\\n",
    "    --input-dir \"datasets/Images_600x800\" \\\n",
    "    --output-dir \"datasets/processed_images\" \\\n",
    "    --target-size 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6993264",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.5 Converting Annotations \n",
    "\n",
    "Convert annotations from LabelMe format to YOLO format:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84917968",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-pipeline labelme-to-yolo \\\n",
    "    --input-folder \"datasets/LabelMe_txt_bricks\" \\\n",
    "    --output-folder \"datasets/annotations\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52de670",
   "metadata": {},
   "source": [
    "\n",
    "By automating these tasks, the package ensures consistency and reduces manual effort.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Model Training üß¨\n",
    "\n",
    "The project uses YOLOv8 for LEGO brick detection. Training is performed using the preprocessed dataset and YOLO-compatible annotations.\n",
    "\n",
    "#### 3.1 Training the YOLO Model\n",
    "\n",
    "The `train_yolo_pipeline` function enables straightforward model training:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76afd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-pipeline train-yolo \\\n",
    "    --dataset-path \"datasets\" \\\n",
    "    --epochs 50 \\\n",
    "    --img-size 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702dd9e5",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 Validating the Model\n",
    "\n",
    "Evaluate the trained model on test images:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c722a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-pipeline test-model \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --test-images-dir \"test_images\" \\\n",
    "    --output-dir \"results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918abd2e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 4. Visualization and Results üé®\n",
    "\n",
    "#### 4.1 Visualizing Results\n",
    "\n",
    "Visualize predictions and annotations using:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-visualize annotate-results \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/model_results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f7977",
   "metadata": {},
   "source": [
    "\n",
    "#### 4.2 Generating Comparison Grids\n",
    "\n",
    "Compare predictions against ground truth:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-visualize comparison-grid \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/comparison\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812b0bc",
   "metadata": {},
   "source": [
    "\n",
    "#### 4.3 Creating Presentation Grids\n",
    "\n",
    "Summarize dataset samples in a grid format:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59530590",
   "metadata": {},
   "outputs": [],
   "source": [
    "!run-visualize create-grid \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/dataset_samples\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7be84",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 5. Reflection and Future Work üîÑ\n",
    "\n",
    "This project demonstrates the effectiveness of modular pipelines for scalable machine learning workflows. Key insights include:\n",
    "\n",
    "- **Data Quality**: High-quality, annotated datasets significantly enhance model performance.\n",
    "- **Modularity**: Breaking down the pipeline into distinct stages improves reproducibility.\n",
    "- **Visualization**: Effective visual tools aid in debugging and communicating results.\n",
    "\n",
    "#### Future Improvements:\n",
    "1. Expanding the dataset to include more LEGO pieces.\n",
    "2. Integrating semi-automated annotation tools.\n",
    "3. Developing an interactive interface for real-time predictions.\n",
    "\n",
    "---\n",
    "\n",
    "For more details, refer to the [LEGO Bricks ML Vision Documentation](https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnvHaB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
