{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Bricks Identification Project: A Journey of Learning and Adaptation\n",
    "\n",
    "## 1. Introduction and Motivation 🎯\n",
    "\n",
    "Este proyecto surge como una oportunidad para aplicar y demostrar mis habilidades técnicas en el contexto de un cambio profesional hacia la ciencia de datos e inteligencia artificial. Durante esta transición, decidí combinar mi pasión por los LEGO con mi interés por la visión por computadora, dando vida a una idea que conecta creatividad y tecnología.\n",
    "\n",
    "### 1.1 Propósito y Objetivos 🎯\n",
    "\n",
    "El propósito principal del proyecto es desarrollar una solución práctica y escalable que demuestre mis habilidades en ciencia de datos y visión por computadora. Los objetivos específicos incluyen:\n",
    "\n",
    "1. Diseñar un pipeline eficiente para la detección y clasificación de piezas de LEGO.\n",
    "2. Documentar el proceso de desarrollo, desde la creación del dataset hasta la implementación del modelo.\n",
    "3. Generar resultados replicables y visualizaciones claras que destaquen el impacto de mi enfoque técnico.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Creación del Dataset 🗂️\n",
    "\n",
    "La base de este proyecto es un dataset bien estructurado y diverso. El proceso de creación incluyó la recolección, anotación y preprocesamiento de datos.\n",
    "\n",
    "### 2.1 Recolección de Datos 📸\n",
    "\n",
    "Para capturar imágenes representativas de piezas LEGO, utilicé diferentes configuraciones de iluminación y disposición, generando un dataset inicial de más de 2000 imágenes.\n",
    "\n",
    "### 2.2 Anotación de los Datos 📝\n",
    "\n",
    "Se utilizó LabelMe para anotar las imágenes con bounding boxes y puntos clave, generando archivos JSON que posteriormente se convirtieron al formato YOLO.\n",
    "\n",
    "### 2.3 Preprocesamiento y Normalización 🧹\n",
    "\n",
    "**Código para Preprocesamiento y Descarga de Datos:**\n",
    "\n",
    "```python\n",
    "from scripts.pipeline import download_dataset_from_kaggle, preprocess_images\n",
    "\n",
    "# Descargar el dataset desde Kaggle\n",
    "kaggle_dataset = \"migueldilalla/spiled-lego-bricks\"\n",
    "output_dir = \"datasets\"\n",
    "download_dataset_from_kaggle(kaggle_dataset, output_dir)\n",
    "\n",
    "# Preprocesar imágenes\n",
    "preprocess_images(f\"{output_dir}/raw\", f\"{output_dir}/processed\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Selección e Implementación del Modelo 🤖\n",
    "\n",
    "### 3.1 Configuración del Pipeline de Entrenamiento\n",
    "\n",
    "El pipeline implementa un enfoque modular para la preparación, entrenamiento y validación del modelo YOLOv8n.\n",
    "\n",
    "**Entrenamiento del Modelo:**\n",
    "\n",
    "```python\n",
    "from scripts.pipeline import train_yolo_pipeline\n",
    "\n",
    "# Configurar y entrenar YOLO\n",
    "train_yolo_pipeline(\n",
    "    dataset_path=\"datasets\", \n",
    "    annotations_format=\"YOLO\", \n",
    "    epochs=50, \n",
    "    img_size=256\n",
    ")\n",
    "```\n",
    "\n",
    "### 3.2 Conversión de Anotaciones\n",
    "\n",
    "**Código para Convertir Anotaciones de LabelMe a YOLO:**\n",
    "\n",
    "```python\n",
    "from scripts.pipeline import labelme_to_yolo\n",
    "\n",
    "# Convertir anotaciones al formato YOLO\n",
    "labelme_to_yolo(\n",
    "    input_folder=\"datasets/processed\", \n",
    "    output_folder=\"datasets/annotations\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Validación y Resultados 📊\n",
    "\n",
    "### 4.1 Pruebas en Imágenes Reales\n",
    "\n",
    "**Código para Probar el Modelo en Imágenes Reales:**\n",
    "\n",
    "```python\n",
    "from scripts.pipeline import test_model_on_real_images\n",
    "\n",
    "# Evaluar modelo YOLO entrenado\n",
    "model_path = \"YOLO_Lego_Detection/best.pt\"\n",
    "test_images_dir = \"test_images\"\n",
    "output_dir = \"results\"\n",
    "\n",
    "test_model_on_real_images(model_path, test_images_dir, output_dir)\n",
    "```\n",
    "\n",
    "### 4.2 Visualización de Resultados\n",
    "\n",
    "**Visualización de Imágenes Anotadas:**\n",
    "\n",
    "```python\n",
    "from scripts.pipeline import visualize_results\n",
    "\n",
    "visualize_results(\"datasets\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Reflexión y Futuro 🔮\n",
    "\n",
    "### 5.1 Mejoras Futuras\n",
    "\n",
    "1. **Optimización del Pipeline:** Explorar estrategias de fine-tuning para mejorar el rendimiento del modelo.\n",
    "2. **Ampliación del Dataset:** Incorporar nuevos tipos de piezas y condiciones de captura.\n",
    "3. **Automatización Completa:** Integrar herramientas avanzadas para anotaciones automáticas y expansión de datos.\n",
    "\n",
    "**Con este enfoque iterativo y modular, el proyecto está diseñado para evolucionar continuamente y adaptarse a nuevas aplicaciones y desafíos.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnvHaB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
