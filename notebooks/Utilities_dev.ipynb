{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")  # Ajusta según tu estructura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate_folders_ImageDataProject.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project structure created successfully at: c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_project_structure():\n",
    "    \"\"\"\n",
    "    Create a folder structure for an image data project.\n",
    "\n",
    "    The base path is automatically set to the current working directory.\n",
    "    \"\"\"\n",
    "    # Set the base directory to the current working directory\n",
    "    base_path = os.getcwd()\n",
    "\n",
    "    # Define the folder structure\n",
    "    structure = {\n",
    "        \"data\": [\n",
    "            \"raw\",\n",
    "            \"processed\",\n",
    "            \"annotations\"\n",
    "        ],\n",
    "        \"src\": [\n",
    "            \"data_preprocessing\",\n",
    "            \"models\",\n",
    "            \"visualization\"\n",
    "        ],\n",
    "        \"models\": [\n",
    "            \"checkpoints\",\n",
    "            \"final\"\n",
    "        ],\n",
    "        \"results\": [\n",
    "            \"predictions\",\n",
    "            \"logs\"\n",
    "        ],\n",
    "        \"docs\": [],\n",
    "        \"notebooks\": [],\n",
    "        \"tests\": [],\n",
    "        \"presentation\": []\n",
    "    }\n",
    "\n",
    "    # Function to create folders recursively\n",
    "    def create_folders(base, folders):\n",
    "        for folder, subfolders in folders.items():\n",
    "            folder_path = os.path.join(base, folder)\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            for subfolder in subfolders:\n",
    "                os.makedirs(os.path.join(folder_path, subfolder), exist_ok=True)\n",
    "\n",
    "    # Create the structure\n",
    "    create_folders(base_path, structure)\n",
    "\n",
    "    print(f\"Project structure created successfully at: {base_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    create_project_structure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportar Refurbished PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook LEGO_Bricks_Identification_Project_Overview.ipynb to pdf\n",
      "[NbConvertApp] Writing 34205 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | b had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 42940 bytes to LEGO_Bricks_Identification_Project_Overview.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf LEGO_Bricks_Identification_Project_Overview.ipynb\n",
    "# !jupyter nbconvert --to pdf LEGO_Bricks_Identification_Project_Technical_Report.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refurbishing Pipeline\n",
    "\n",
    "(chatGPT is having bugs remembering converstions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "¡Perfecto! Vamos a estructurar esta entrevista para guiarte a reflexionar sobre cada etapa del proyecto y asegurarnos de que tu storytelling esté alineado con las mejores prácticas. Este enfoque también nos permitirá planear cómo documentar, reproducir y organizar el proyecto de manera profesional.\n",
    "\n",
    "Entrevista Inicial\n",
    "Te haré preguntas relevantes por etapas del proyecto. Responde según tu experiencia, y construiré secciones del documento con base en tus respuestas. También sugeriré scripts o ajustes según lo que compartas.\n",
    "\n",
    "1. Origen del Proyecto\n",
    "¿Qué te motivó a iniciar este proyecto? ¿Fue un desafío técnico que querías resolver, una curiosidad personal, o algo más?\n",
    "¿Cómo conectaste tus habilidades previas con esta idea? Por ejemplo, ¿qué experiencias te influyeron a elegir visión por computadora y no otro campo?\n",
    "2. Creación del Dataset\n",
    "¿Qué tipo de datos recopilaste y cómo? Comparte detalles sobre el proceso, como herramientas utilizadas, número de imágenes, y estrategias para capturar diferentes ángulos y condiciones.\n",
    "¿Cómo manejaste la anotación de los datos? ¿Usaste alguna herramienta específica como LabelMe o desarrollaste algo propio? ¿Hubo desafíos en esta etapa?\n",
    "¿Qué criterios usaste para limpiar y preparar los datos? Por ejemplo, ¿eliminaste imágenes borrosas o hiciste algún balanceo entre clases?\n",
    "3. Selección del Modelo\n",
    "¿Por qué elegiste YOLO? ¿Probaste otros modelos antes? Si es así, ¿cuáles y por qué los descartaste?\n",
    "¿Cómo ajustaste los hiperparámetros durante el entrenamiento? Por ejemplo, tamaño de lotes, número de épocas, etc.\n",
    "¿Qué limitaciones encontraste en el modelo, y cómo las abordaste?\n",
    "4. Implementación y Resultados\n",
    "¿Cómo transformaste los resultados del modelo en algo práctico? Por ejemplo, ¿cómo calculaste las dimensiones de las piezas basándote en la detección de studs?\n",
    "¿Qué métricas utilizaste para medir el éxito? ¿Precision, recall, F1-score, u otras? ¿Cómo documentaste estos resultados?\n",
    "¿Qué visualizaciones creaste para entender mejor los resultados?\n",
    "5. Reflexión y Futuro\n",
    "¿Qué aprendiste en términos técnicos y personales? ¿Qué habilidades desarrollaste o reforzaste?\n",
    "Si comenzaras de nuevo, ¿qué harías diferente?\n",
    "¿Qué pasos futuros te gustaría explorar? Por ejemplo, ¿mejorar el modelo, ampliar el dataset, o implementar nuevas funcionalidades?\n",
    "Próximos Pasos\n",
    "Conforme respondas, construiré borradores de las secciones correspondientes del documento. Si surgen necesidades específicas (como scripts para repetir entrenamientos), las desarrollaremos y definiremos cómo integrarlas al proyecto.\n",
    "\n",
    "Comencemos con tus respuestas a las primeras preguntas de la sección 1 sobre la motivación y el origen del proyecto. 😊\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion de pipeline central\n",
    "\n",
    "## pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "\n",
    "# import os\n",
    "\n",
    "# def generate_structure_file(output_file=\"estructura.txt\"):\n",
    "#     \"\"\"\n",
    "#     Genera un archivo con la estructura de directorios solo si el directorio actual\n",
    "#     contiene una carpeta 'src' o está relacionado con ella.\n",
    "\n",
    "#     Args:\n",
    "#         output_file (str): Nombre del archivo para guardar la estructura.\n",
    "#     \"\"\"\n",
    "#     # Directorio actual\n",
    "#     current_dir = os.getcwd()\n",
    "\n",
    "#     # Verificar si existe la carpeta 'src' en el directorio actual\n",
    "#     if \"src\" in os.listdir(current_dir):\n",
    "#         # Crear la estructura en el directorio actual\n",
    "#         target_dir = current_dir\n",
    "#         print(f\"Directorio 'src' encontrado en el directorio actual: {target_dir}\")\n",
    "#     else:\n",
    "#         # Subir al directorio padre y verificar si 'src' es una carpeta hermana\n",
    "#         parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "#         if \"src\" in os.listdir(parent_dir):\n",
    "#             # Crear la estructura en el directorio padre\n",
    "#             target_dir = parent_dir\n",
    "#             print(f\"Directorio 'src' encontrado como carpeta hermana. Generando estructura en: {target_dir}\")\n",
    "#         else:\n",
    "#             print(\"No se encontró la carpeta 'src'. No se generará el archivo de estructura.\")\n",
    "#             return\n",
    "\n",
    "#     # Generar la estructura\n",
    "#     with open(output_file, \"w\") as f:\n",
    "#         for root, dirs, files in os.walk(target_dir):\n",
    "#             level = root.replace(target_dir, \"\").count(os.sep)\n",
    "#             indent = \" \" * 4 * level\n",
    "#             f.write(f\"{indent}{os.path.basename(root)}/\\n\")\n",
    "#             subindent = \" \" * 4 * (level + 1)\n",
    "#             for file in files:\n",
    "#                 f.write(f\"{subindent}{file}\\n\")\n",
    "\n",
    "#     print(f\"Estructura generada exitosamente en: {output_file}\")\n",
    "\n",
    "# # Ejecutar la función\n",
    "# if __name__ == \"__main__\":\n",
    "#     generate_structure_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\n",
      "c:\\Users\\User\\Projects_Unprotected\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Muestra la ruta actual\n",
    "print(os.getcwd())\n",
    "\n",
    "# Cambia al directorio raíz del proyecto\n",
    "os.chdir(\"..\")  # Cambia al directorio raíz\n",
    "\n",
    "# Confirma el cambio de directorio\n",
    "print(os.getcwd())\n",
    "\n",
    "# Importa funciones desde el pipeline\n",
    "from scripts.pipeline import (\n",
    "    setup_environment,\n",
    "    get_kaggle_credentials,\n",
    "    download_dataset_from_kaggle,\n",
    "    validate_directories,\n",
    "    preprocess_images,\n",
    "    labelme_to_yolo,\n",
    "    train_yolo_pipeline,\n",
    "    test_model_on_real_images,\n",
    "    visualize_results,\n",
    ")\n",
    "\n",
    "# Prueba de las funciones importadas\n",
    "setup_environment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview.pdf\n",
    "\n",
    "## visualize_presentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from pipeline import test_model_on_real_images\n",
    "\n",
    "# # Crear grids de muestras del dataset\n",
    "# def create_dataset_grid(input_folder, output_folder, grid_size=(3, 3)):\n",
    "#     \"\"\"\n",
    "#     Genera un grid de imágenes de muestra del dataset y las guarda en la carpeta especificada.\n",
    "\n",
    "#     Parameters:\n",
    "#     - input_folder (str): Ruta de la carpeta con las imágenes de entrada.\n",
    "#     - output_folder (str): Ruta donde se guardará el grid generado.\n",
    "#     - grid_size (tuple): Dimensiones del grid (filas, columnas).\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     random.shuffle(image_files)\n",
    "    \n",
    "#     selected_files = image_files[:grid_size[0] * grid_size[1]]\n",
    "#     fig, axes = plt.subplots(*grid_size, figsize=(grid_size[1] * 4, grid_size[0] * 4))\n",
    "\n",
    "#     for idx, img_file in enumerate(selected_files):\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         img = Image.open(img_path)\n",
    "#         row, col = divmod(idx, grid_size[1])\n",
    "#         axes[row, col].imshow(img)\n",
    "#         axes[row, col].axis('off')\n",
    "#         axes[row, col].set_title(f\"{img_file}\", fontsize=10)\n",
    "\n",
    "#     for ax in axes.flat[len(selected_files):]:\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     grid_path = os.path.join(output_folder, \"dataset_grid.png\")\n",
    "#     plt.savefig(grid_path, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "#     print(f\"Grid de dataset guardado en {grid_path}.\")\n",
    "\n",
    "# # Generar visualizaciones anotadas\n",
    "# def annotate_model_results(model_path, input_folder, output_folder, conf_threshold=0.5):\n",
    "#     \"\"\"\n",
    "#     Genera imágenes con anotaciones del modelo y las guarda en la carpeta especificada.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#     - input_folder (str): Carpeta con imágenes de entrada.\n",
    "#     - output_folder (str): Carpeta para guardar las imágenes anotadas.\n",
    "#     - conf_threshold (float): Umbral de confianza para las detecciones.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     test_model_on_real_images(model_path, input_folder, output_folder)\n",
    "#     print(f\"Resultados anotados guardados en {output_folder}.\")\n",
    "\n",
    "# # Crear comparaciones antes/después\n",
    "# def generate_comparison_grid(model_path, input_folder, output_folder, num_samples=5):\n",
    "#     \"\"\"\n",
    "#     Crea un grid comparativo de imágenes antes y después de las predicciones del modelo.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#     - input_folder (str): Carpeta con imágenes de entrada.\n",
    "#     - output_folder (str): Carpeta para guardar los grids generados.\n",
    "#     - num_samples (int): Número de imágenes a comparar.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     random.shuffle(image_files)\n",
    "#     selected_files = image_files[:num_samples]\n",
    "\n",
    "#     for img_file in selected_files:\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         result_path = os.path.join(output_folder, img_file)\n",
    "\n",
    "#         test_model_on_real_images(model_path, img_path, output_folder)\n",
    "#         annotated_img = Image.open(result_path)\n",
    "#         original_img = Image.open(img_path)\n",
    "\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#         axes[0].imshow(original_img)\n",
    "#         axes[0].axis('off')\n",
    "#         axes[0].set_title(\"Original\")\n",
    "\n",
    "#         axes[1].imshow(annotated_img)\n",
    "#         axes[1].axis('off')\n",
    "#         axes[1].set_title(\"Anotado\")\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         comparison_path = os.path.join(output_folder, f\"comparison_{img_file}\")\n",
    "#         plt.savefig(comparison_path, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "#         print(f\"Grid de comparación guardado en {comparison_path}.\")\n",
    "\n",
    "# # Organización automática de subcarpetas\n",
    "# def organize_presentation_folders(base_folder):\n",
    "#     \"\"\"\n",
    "#     Crea y organiza las subcarpetas necesarias para las visualizaciones.\n",
    "\n",
    "#     Parameters:\n",
    "#     - base_folder (str): Carpeta raíz para las subcarpetas.\n",
    "#     \"\"\"\n",
    "#     subfolders = [\"dataset_samples\", \"model_results\", \"before_after\"]\n",
    "#     for subfolder in subfolders:\n",
    "#         os.makedirs(os.path.join(base_folder, subfolder), exist_ok=True)\n",
    "#     print(f\"Subcarpetas creadas en {base_folder}: {', '.join(subfolders)}\")\n",
    "\n",
    "# # Ejecución del pipeline de visualización\n",
    "# def main():\n",
    "#     base_folder = \"presentation\"\n",
    "#     organize_presentation_folders(base_folder)\n",
    "\n",
    "#     dataset_folder = \"datasets/processed_images\"\n",
    "#     model_path = \"YOLO_Lego_Detection/best.pt\"\n",
    "\n",
    "#     create_dataset_grid(dataset_folder, os.path.join(base_folder, \"dataset_samples\"))\n",
    "#     annotate_model_results(model_path, dataset_folder, os.path.join(base_folder, \"model_results\"))\n",
    "#     generate_comparison_grid(model_path, dataset_folder, os.path.join(base_folder, \"before_after\"))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Projects_Unprotected\n",
      "c:\\Users\\User\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualize_presentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Importar funciones clave\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvisualize_presentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     create_dataset_grid,\n\u001b[0;32m     18\u001b[0m     annotate_model_results,\n\u001b[0;32m     19\u001b[0m     generate_comparison_grid,\n\u001b[0;32m     20\u001b[0m     organize_presentation_folders\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Definir rutas de entrada y salida\u001b[39;00m\n\u001b[0;32m     24\u001b[0m BASE_FOLDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visualize_presentation'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Muestra la ruta actual\n",
    "print(os.getcwd())\n",
    "\n",
    "# Cambia al directorio raíz del proyecto\n",
    "os.chdir(\"..\")  # Cambia al directorio raíz\n",
    "\n",
    "# Confirma el cambio de directorio\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Importar funciones clave\n",
    "from visualize_presentation import (\n",
    "    create_dataset_grid,\n",
    "    annotate_model_results,\n",
    "    generate_comparison_grid,\n",
    "    organize_presentation_folders\n",
    ")\n",
    "\n",
    "# Definir rutas de entrada y salida\n",
    "BASE_FOLDER = \"presentation\"\n",
    "DATASET_FOLDER = \"datasets/processed_images\"\n",
    "MODEL_PATH = \"YOLO_Lego_Detection/best.pt\"\n",
    "\n",
    "# Crear y organizar las carpetas de presentación\n",
    "organize_presentation_folders(BASE_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\n",
      "c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\n",
      "['c:\\\\Users\\\\User\\\\Projects_Unprotected\\\\LEGO_Bricks_ML_Vision\\\\notebooks',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\python312.zip',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\DLLs',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB',\n",
      " '',\n",
      " 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\win32',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\win32\\\\lib',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\Pythonwin',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor',\n",
      " 'c:\\\\Users\\\\User\\\\Projects_Unprotected\\\\LEGO_Bricks_ML_Vision']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# Muestra la ruta actual\n",
    "print(os.getcwd())\n",
    "\n",
    "# Cambia al directorio raíz del proyecto\n",
    "os.chdir(\"..\")  # Cambia al directorio raíz\n",
    "\n",
    "# Confirma el cambio de directorio\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(os.getcwd()) \n",
    "\n",
    "pprint(sys.path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar todo el pipeline de visualización\n",
    "def run_visualization_pipeline():\n",
    "    organize_presentation_folders(BASE_FOLDER)\n",
    "    create_dataset_grid(DATASET_FOLDER, f\"{BASE_FOLDER}/dataset_samples\", grid_size=(3, 3))\n",
    "    annotate_model_results(MODEL_PATH, DATASET_FOLDER, f\"{BASE_FOLDER}/model_results\")\n",
    "    generate_comparison_grid(MODEL_PATH, DATASET_FOLDER, f\"{BASE_FOLDER}/before_after\", num_samples=5)\n",
    "\n",
    "run_visualization_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup.py \n",
    "\n",
    "Packege publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from setuptools import setup, find_packages\n",
    "\n",
    "# setup(\n",
    "#     name=\"lego_bricks_ml_vision\",\n",
    "#     version=\"0.1.0\",\n",
    "#     packages=find_packages(),\n",
    "#     install_requires=[\n",
    "#         \"torch>=1.8.0\",\n",
    "#         \"ultralytics\",\n",
    "#         \"pillow\",\n",
    "#         \"matplotlib\",\n",
    "#         \"kaggle\",\n",
    "#     ],\n",
    "#     entry_points={\n",
    "#         \"console_scripts\": [\n",
    "#             \"run-pipeline=scripts.pipeline:main\",\n",
    "#             \"run-visualize=scripts.visualize_presentation:main\",\n",
    "#         ],\n",
    "#     },\n",
    "#     author=\"Miguel Di Lalla\",\n",
    "#     description=\"A package for LEGO brick detection and visualization using YOLO.\",\n",
    "#     long_description=open(\"README.md\").read(),\n",
    "#     long_description_content_type=\"text/markdown\",\n",
    "#     license=\"Apache License 2.0\",\n",
    "#     classifiers=[\n",
    "#         \"Programming Language :: Python :: 3\",\n",
    "#         \"License :: OSI Approved :: Apache Software License\",\n",
    "#         \"Operating System :: OS Independent\",\n",
    "#     ],\n",
    "#     python_requires=\">=3.8\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rqueriments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Versions:\n",
      "PyTorch: 2.4.1+cpu\n",
      "Ultralytics: 8.2.99\n",
      "Pillow (PIL): 11.1.0\n",
      "Matplotlib: 3.8.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "import PIL\n",
    "import matplotlib\n",
    "import kaggle\n",
    "\n",
    "print(\"Environment Versions:\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Ultralytics: {ultralytics.__version__}\")\n",
    "print(f\"Pillow (PIL): {PIL.__version__}\")\n",
    "print(f\"Matplotlib: {matplotlib.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kaggle\n",
      "Version: 1.6.17\n",
      "Summary: Kaggle API\n",
      "Home-page: https://github.com/Kaggle/kaggle-api\n",
      "Author: Kaggle\n",
      "Author-email: support@kaggle.com\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\n",
      "Requires: bleach, certifi, python-dateutil, python-slugify, requests, six, tqdm, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# print(f\"Kaggle: {kaggle.__version__}\")\n",
    "! pip show kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch==2.4.1+cpu #torch==2.0.1+cpu\n",
    "ultralytics==8.2.99\n",
    "pillow==11.1.0\n",
    "matplotlib==3.8.4\n",
    "kaggle==1.6.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Bricks ML Vision\n",
    "\n",
    "A Python package for detecting and visualizing LEGO bricks using YOLO and custom visualization pipelines. This project is designed to streamline the process of detecting LEGO pieces in cluttered environments and producing meaningful visualizations for analysis and presentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Object Detection**: Detect LEGO bricks using YOLOv8.\n",
    "- **Preprocessing Tools**: Scripts to preprocess images and datasets.\n",
    "- **Dataset Conversion**: Convert LabelMe annotations to YOLO format.\n",
    "- **Visualization Pipelines**: Create annotated grids, comparisons, and organized folders for presentations.\n",
    "- **Modular Design**: Easy-to-use package structure for scaling or adapting the project.\n",
    "\n",
    "---\n",
    "\n",
    "## Installation\n",
    "\n",
    "To get started with the project, clone the repository and install the package:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision.git\n",
    "cd LEGO_Bricks_ML_Vision\n",
    "pip install -e .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.pipeline import train_yolo_pipeline\n",
    "from scripts.visualize_presentation import create_dataset_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Train YOLO pipeline\n",
    "train_yolo_pipeline(\"path/to/dataset\")\n",
    "\n",
    "# Example: Create a dataset grid\n",
    "create_dataset_grid(\"path/to/images\", \"path/to/output\", grid_size=(3, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt conversacion del pipeline.py\n",
    "\n",
    "para actualizar el comentariado luego de la publicacion en PyPl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "Tengo un script en Python que necesita ser revisado y refinado para alcanzar un nivel profesional. Aquí están los objetivos específicos que quiero lograr:\n",
    "\n",
    "1. **Comentarios claros y precisos**: Cada función debe tener una docstring descriptiva que explique claramente su propósito, parámetros, y valores de retorno (si los hay). Los comentarios en línea deben ser breves, relevantes y ayudar a entender el código.\n",
    "\n",
    "2. **Formato consistente**: El código debe seguir el estándar **PEP 8**, incluyendo:\n",
    "   - Longitud de línea máxima de 79 caracteres.\n",
    "   - Identación adecuada (4 espacios).\n",
    "   - Espaciado entre bloques y funciones.\n",
    "   - Organización lógica de las importaciones (primero estándar, luego librerías externas, y finalmente locales).\n",
    "\n",
    "3. **Organización de secciones**: Agrupa las funciones relacionadas y añade encabezados de comentarios (# ===) para separar las secciones principales del script.\n",
    "\n",
    "4. **Buena práctica en manejo de errores**: Incluye excepciones manejadas correctamente donde sea relevante (e.g., para operaciones de I/O o dependencias externas).\n",
    "\n",
    "5. **Estilo profesional en los print()**: Usa mensajes formateados de manera clara y profesional, por ejemplo:\n",
    "   ```python\n",
    "   print(f\"[INFO] Dataset descargado y extraído en {destination}\")\n",
    "\n",
    "6. **Detalles adicionales:** Si algo en el código puede ser optimizado o mejorado, propón cambios para hacerlo más eficiente y profesional.\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# import shutil\n",
    "# import kaggle\n",
    "# import zipfile\n",
    "\n",
    "# # === Configuración Inicial ===\n",
    "# def setup_environment():\n",
    "#     \"\"\"\n",
    "#     Clona el repositorio y configura el entorno necesario para ejecutar el pipeline.\n",
    "\n",
    "#     - Clona el repositorio de GitHub.\n",
    "#     - Instala las dependencias desde el archivo requirements.txt.\n",
    "#     - Configura el dispositivo de ejecución (CPU o GPU).\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         os.system(\"git clone https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision.git\")\n",
    "#         os.chdir(\"LEGO_Bricks_ML_Vision\")\n",
    "#         os.system(\"pip install -r requirements.txt\")\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#         print(f\"[INFO] Using device: {device}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Error al configurar el entorno: {e}\")\n",
    "\n",
    "# # === Manejo de Credenciales de Kaggle ===\n",
    "# def get_kaggle_credentials():\n",
    "#     \"\"\"\n",
    "#     Obtiene las credenciales de Kaggle desde variables de entorno o archivo kaggle.json.\n",
    "\n",
    "#     Prioridad de búsqueda:\n",
    "#     1. Variables de entorno: KAGGLE_USERNAME y KAGGLE_KEY.\n",
    "#     2. Archivo ~/.kaggle/kaggle.json.\n",
    "\n",
    "#     Returns:\n",
    "#     - dict: Diccionario con 'username' y 'key'.\n",
    "#     \"\"\"\n",
    "#     username = os.getenv(\"KAGGLE_USERNAME\")\n",
    "#     key = os.getenv(\"KAGGLE_KEY\")\n",
    "\n",
    "#     if username and key:\n",
    "#         return {\"username\": username, \"key\": key}\n",
    "\n",
    "#     kaggle_json_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "#     if os.path.exists(kaggle_json_path):\n",
    "#         try:\n",
    "#             with open(kaggle_json_path, \"r\") as f:\n",
    "#                 return json.load(f)\n",
    "#         except Exception as e:\n",
    "#             raise ValueError(f\"[ERROR] No se pudo leer kaggle.json: {e}\")\n",
    "\n",
    "#     raise ValueError(\"[ERROR] Credenciales de Kaggle no encontradas. Configure las variables de entorno o coloque kaggle.json en ~/.kaggle.\")\n",
    "\n",
    "# # === Descarga de Dataset ===\n",
    "# def download_dataset_from_kaggle(dataset, destination):\n",
    "#     \"\"\"\n",
    "#     Descarga y extrae un dataset de Kaggle.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset (str): Nombre del dataset en el formato \"usuario/dataset\".\n",
    "#     - destination (str): Ruta donde se extraerán los archivos.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         credentials = get_kaggle_credentials()\n",
    "\n",
    "#         os.makedirs(destination, exist_ok=True)\n",
    "#         os.environ[\"KAGGLE_USERNAME\"] = credentials[\"username\"]\n",
    "#         os.environ[\"KAGGLE_KEY\"] = credentials[\"key\"]\n",
    "\n",
    "#         kaggle.api.dataset_download_files(dataset, path=destination, unzip=True)\n",
    "#         print(f\"[INFO] Dataset descargado y extraído en {destination}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] No se pudo descargar el dataset: {e}\")\n",
    "\n",
    "# # === Validación de Directorios ===\n",
    "# def validate_directories(directories):\n",
    "#     \"\"\"\n",
    "#     Valida la existencia de los directorios especificados.\n",
    "\n",
    "#     Parameters:\n",
    "#     - directories (list): Lista de rutas a validar.\n",
    "\n",
    "#     Returns:\n",
    "#     - bool: True si todos los directorios existen, False en caso contrario.\n",
    "#     \"\"\"\n",
    "#     for directory in directories:\n",
    "#         if not os.path.exists(directory):\n",
    "#             print(f\"[ERROR] Directorio no encontrado: {directory}\")\n",
    "#             return False\n",
    "#     print(\"[INFO] Todos los directorios están correctamente configurados.\")\n",
    "#     return True\n",
    "\n",
    "# # === Preprocesamiento de Imágenes ===\n",
    "# def preprocess_images(input_dir, output_dir, target_size=(256, 256)):\n",
    "#     \"\"\"\n",
    "#     Redimensiona imágenes y asegura consistencia en nombres de archivos.\n",
    "\n",
    "#     Parameters:\n",
    "#     - input_dir (str): Ruta de la carpeta con imágenes originales.\n",
    "#     - output_dir (str): Ruta de la carpeta para guardar las imágenes procesadas.\n",
    "#     - target_size (tuple): Dimensiones objetivo para las imágenes (ancho, alto).\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     for i, filename in enumerate(sorted(os.listdir(input_dir))):\n",
    "#         if filename.endswith(\".jpg\"):\n",
    "#             try:\n",
    "#                 img = Image.open(os.path.join(input_dir, filename))\n",
    "#                 img_resized = img.resize(target_size)\n",
    "#                 new_filename = f\"image_{i}.jpg\"\n",
    "#                 img_resized.save(os.path.join(output_dir, new_filename))\n",
    "#                 print(f\"[INFO] Procesado: {filename} -> {new_filename}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"[ERROR] No se pudo procesar {filename}: {e}\")\n",
    "\n",
    "# # === Conversión de Anotaciones de LabelMe a YOLO ===\n",
    "# def labelme_to_yolo(input_folder, output_folder):\n",
    "#     \"\"\"\n",
    "#     Convierte archivos JSON de LabelMe al formato YOLO.\n",
    "\n",
    "#     Parameters:\n",
    "#     - input_folder (str): Carpeta con archivos JSON de LabelMe.\n",
    "#     - output_folder (str): Carpeta donde se guardarán los archivos YOLO.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     for filename in os.listdir(input_folder):\n",
    "#         if filename.endswith('.json'):\n",
    "#             try:\n",
    "#                 json_file = os.path.join(input_folder, filename)\n",
    "#                 yolo_file = os.path.join(output_folder, filename.replace('.json', '.txt'))\n",
    "#                 # Conversión aquí (implementación omitida para brevedad)\n",
    "#                 print(f\"[INFO] Convertido: {json_file} -> {yolo_file}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"[ERROR] Error al convertir {filename}: {e}\")\n",
    "\n",
    "# # === Entrenamiento del Modelo YOLOv8n ===\n",
    "# def train_yolo_pipeline(dataset_path, annotations_format=\"YOLO\", epochs=50, img_size=256):\n",
    "#     \"\"\"\n",
    "#     Configura y entrena el modelo YOLO.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset_path (str): Ruta del dataset procesado.\n",
    "#     - annotations_format (str): Formato de las anotaciones (por defecto \"YOLO\").\n",
    "#     - epochs (int): Número de épocas de entrenamiento.\n",
    "#     - img_size (int): Tamaño de las imágenes usadas para entrenamiento.\n",
    "#     \"\"\"\n",
    "#     from ultralytics import YOLO\n",
    "\n",
    "#     dataset_dir = os.path.join(dataset_path, \"processed_images\")\n",
    "#     annotations_dir = os.path.join(dataset_path, \"annotations\")\n",
    "\n",
    "#     if not validate_directories([dataset_dir, annotations_dir]):\n",
    "#         return\n",
    "\n",
    "#     try:\n",
    "#         model = YOLO(\"yolov8n.pt\")\n",
    "#         results = model.train(\n",
    "#             data=annotations_format,\n",
    "#             imgsz=img_size,\n",
    "#             epochs=epochs,\n",
    "#             batch=16,\n",
    "#             project=\"LEGO_Training\",\n",
    "#             name=\"YOLO_Lego_Detection\"\n",
    "#         )\n",
    "#         print(\"[INFO] Entrenamiento finalizado. Resultados:\", results)\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Error durante el entrenamiento: {e}\")\n",
    "\n",
    "# # === Evaluación del Modelo Entrenado ===\n",
    "# def test_model_on_real_images(model_path, test_images_dir, output_dir):\n",
    "#     \"\"\"\n",
    "#     Evalúa el modelo YOLO entrenado en imágenes reales.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_path (str): Ruta del modelo YOLO entrenado.\n",
    "#     - test_images_dir (str): Carpeta con imágenes para evaluación.\n",
    "#     - output_dir (str): Carpeta para guardar los resultados visualizados.\n",
    "#     \"\"\"\n",
    "#     from ultralytics import YOLO\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     model = YOLO(model_path)\n",
    "\n",
    "#     for img_file in os.listdir(test_images_dir):\n",
    "#         if img_file.endswith(\".jpg\"):\n",
    "#             try:\n",
    "#                 img_path = os.path.join(test_images_dir, img_file)\n",
    "#                 results = model(img_path)\n",
    "#                 result_image = results[0].plot()\n",
    "#                 output_path = os.path.join(output_dir, img_file)\n",
    "#                 Image.fromarray(result_image).save(output_path)\n",
    "#                 print(f\"[INFO] Procesado: {img_file} -> {output_path}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"[ERROR] Error al procesar {img_file}: {e}\")\n",
    "\n",
    "# # === Visualización de Resultados ===\n",
    "# def visualize_results(dataset_path):\n",
    "#     \"\"\"\n",
    "#     Visualiza detecciones en un grid de imágenes anotadas.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset_path (str): Ruta del dataset procesado.\n",
    "#     \"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     processed_dir = os.path.join(dataset_path, \"processed_images\")\n",
    "#     images = [os.path.join(processed_dir, img) for img in os.listdir(processed_dir) if img.endswith(\".jpg\")]\n",
    "\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     for i, img_path in enumerate(images[:16]):  # Mostrar 16 imágenes\n",
    "#         try:\n",
    "#             img = Image.open(img_path)\n",
    "#             plt.subplot(4, 4, i + 1)\n",
    "#             plt.imshow(img)\n",
    "#             plt.axis('off')\n",
    "#         except Exception as e:\n",
    "#             print(f\"[ERROR] No se pudo cargar {img_path}: {e}\")\n",
    "#     plt.show()\n",
    "\n",
    "# # === Ejecución del Pipeline ===\n",
    "# def main():\n",
    "#     \"\"\"Ejecución principal del pipeline de detección de LEGO.\"\"\"\n",
    "#     setup_environment()\n",
    "#     download_dataset_from_kaggle(\"usuario/dataset\", \"datasets\")\n",
    "#     preprocess_images(\"datasets/raw\", \"datasets/processed\")\n",
    "#     labelme_to_yolo(\"datasets/processed\", \"datasets/annotations\")\n",
    "#     train_yolo_pipeline(\"datasets\")\n",
    "#     test_model_on_real_images(\"YOLO_Lego_Detection/best.pt\", \"test_images\", \"results\")\n",
    "#     visualize_results(\"datasets\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt conversacion del visualization_presentation.py\n",
    "\n",
    "para actualizar el comentariado luego de la publicacion en PyPl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "Tengo el siguiente script en Python que quiero mejorar para alcanzar un nivel profesional. El script incluye varias funciones relacionadas con la visualización de resultados de modelos y organización de carpetas. Estos son los aspectos específicos que quiero mejorar:\n",
    "\n",
    "1. **Comentarios más claros y precisos**:\n",
    "   - Las docstrings deben ser detalladas, siguiendo el estándar Google o NumPy, e incluir:\n",
    "     - Propósito de la función.\n",
    "     - Parámetros (`Args`).\n",
    "     - Valores de retorno (`Returns`), si aplica.\n",
    "   - Los comentarios en línea deben ser breves y específicos para mejorar la comprensión del código.\n",
    "\n",
    "2. **Formato y organización del código**:\n",
    "   - Aplicar el estándar **PEP 8**, como longitud máxima de líneas (79 caracteres) y espaciado adecuado.\n",
    "   - Asegurar que las importaciones estén organizadas (estándar, externas, locales).\n",
    "\n",
    "3. **Manejo de errores**:\n",
    "   - Proponer o incluir excepciones donde sea relevante, como manejo de archivos o directorios inexistentes.\n",
    "\n",
    "4. **Mensajes más profesionales**:\n",
    "   - Reemplazar mensajes `print()` por logs informativos utilizando la librería estándar `logging`.\n",
    "\n",
    "5. **Optimización del flujo de funciones**:\n",
    "   - Identificar redundancias o mejoras en la eficiencia de las funciones.\n",
    "\n",
    "6. **Mejoras generales**:\n",
    "   - Proponer o aplicar cualquier ajuste que haga el script más limpio, profesional y eficiente.\n",
    "\n",
    "A continuación, te comparto el script para que lo refines según estos criterios:\n",
    "\n",
    "\n",
    "Por favor, realiza los ajustes directamente en el código y explica las mejoras realizadas para que pueda aprender del proceso.\n",
    "\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import logging\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from scripts.pipeline import test_model_on_real_images\n",
    "\n",
    "# # Configuración del logger\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def create_dataset_grid(input_folder: str, output_folder: str, grid_size=(3, 3)) -> None:\n",
    "#     \"\"\"\n",
    "#     Genera un grid de imágenes de muestra del dataset y lo guarda en la carpeta especificada.\n",
    "\n",
    "#     Args:\n",
    "#         input_folder (str): Ruta de la carpeta con las imágenes de entrada.\n",
    "#         output_folder (str): Ruta donde se guardará el grid generado.\n",
    "#         grid_size (tuple): Dimensiones del grid (filas, columnas).\n",
    "\n",
    "#     Raises:\n",
    "#         FileNotFoundError: Si la carpeta de entrada no existe o está vacía.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(input_folder):\n",
    "#         logging.error(\"La carpeta de entrada no existe.\")\n",
    "#         raise FileNotFoundError(\"Carpeta de entrada no encontrada.\")\n",
    "\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     if not image_files:\n",
    "#         logging.error(\"No se encontraron imágenes en la carpeta de entrada.\")\n",
    "#         raise FileNotFoundError(\"No se encontraron imágenes en la carpeta de entrada.\")\n",
    "\n",
    "#     random.shuffle(image_files)\n",
    "#     selected_files = image_files[:grid_size[0] * grid_size[1]]\n",
    "#     fig, axes = plt.subplots(*grid_size, figsize=(grid_size[1] * 4, grid_size[0] * 4))\n",
    "\n",
    "#     for idx, img_file in enumerate(selected_files):\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         img = Image.open(img_path)\n",
    "#         row, col = divmod(idx, grid_size[1])\n",
    "#         axes[row, col].imshow(img)\n",
    "#         axes[row, col].axis('off')\n",
    "#         axes[row, col].set_title(f\"{img_file}\", fontsize=10)\n",
    "\n",
    "#     for ax in axes.flat[len(selected_files):]:\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     grid_path = os.path.join(output_folder, \"dataset_grid.png\")\n",
    "#     plt.savefig(grid_path, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "#     logging.info(f\"Grid de dataset guardado en {grid_path}.\")\n",
    "\n",
    "# def annotate_model_results(model_path: str, input_folder: str, output_folder: str, conf_threshold=0.5) -> None:\n",
    "#     \"\"\"\n",
    "#     Genera imágenes con anotaciones del modelo y las guarda en la carpeta especificada.\n",
    "\n",
    "#     Args:\n",
    "#         model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#         input_folder (str): Carpeta con imágenes de entrada.\n",
    "#         output_folder (str): Carpeta para guardar las imágenes anotadas.\n",
    "#         conf_threshold (float): Umbral de confianza para las detecciones.\n",
    "\n",
    "#     Raises:\n",
    "#         FileNotFoundError: Si la carpeta de entrada no contiene imágenes.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(input_folder):\n",
    "#         logging.error(\"La carpeta de entrada no existe.\")\n",
    "#         raise FileNotFoundError(\"Carpeta de entrada no encontrada.\")\n",
    "\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     test_model_on_real_images(model_path, input_folder, output_folder)\n",
    "#     logging.info(f\"Resultados anotados guardados en {output_folder}.\")\n",
    "\n",
    "# def generate_comparison_grid(model_path: str, input_folder: str, output_folder: str, num_samples=5) -> None:\n",
    "#     \"\"\"\n",
    "#     Crea un grid comparativo de imágenes antes y después de las predicciones del modelo.\n",
    "\n",
    "#     Args:\n",
    "#         model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#         input_folder (str): Carpeta con imágenes de entrada.\n",
    "#         output_folder (str): Carpeta para guardar los grids generados.\n",
    "#         num_samples (int): Número de imágenes a comparar.\n",
    "\n",
    "#     Raises:\n",
    "#         FileNotFoundError: Si la carpeta de entrada no contiene imágenes.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(input_folder):\n",
    "#         logging.error(\"La carpeta de entrada no existe.\")\n",
    "#         raise FileNotFoundError(\"Carpeta de entrada no encontrada.\")\n",
    "\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     if not image_files:\n",
    "#         logging.error(\"No se encontraron imágenes en la carpeta de entrada.\")\n",
    "#         raise FileNotFoundError(\"No se encontraron imágenes en la carpeta de entrada.\")\n",
    "\n",
    "#     random.shuffle(image_files)\n",
    "#     selected_files = image_files[:num_samples]\n",
    "\n",
    "#     for img_file in selected_files:\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         result_path = os.path.join(output_folder, img_file)\n",
    "\n",
    "#         test_model_on_real_images(model_path, img_path, output_folder)\n",
    "#         annotated_img = Image.open(result_path)\n",
    "#         original_img = Image.open(img_path)\n",
    "\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#         axes[0].imshow(original_img)\n",
    "#         axes[0].axis('off')\n",
    "#         axes[0].set_title(\"Original\")\n",
    "\n",
    "#         axes[1].imshow(annotated_img)\n",
    "#         axes[1].axis('off')\n",
    "#         axes[1].set_title(\"Anotado\")\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         comparison_path = os.path.join(output_folder, f\"comparison_{img_file}\")\n",
    "#         plt.savefig(comparison_path, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "#         logging.info(f\"Grid de comparación guardado en {comparison_path}.\")\n",
    "\n",
    "# def organize_presentation_folders(base_folder: str) -> None:\n",
    "#     \"\"\"\n",
    "#     Crea y organiza las subcarpetas necesarias para las visualizaciones.\n",
    "\n",
    "#     Args:\n",
    "#         base_folder (str): Carpeta raíz para las subcarpetas.\n",
    "#     \"\"\"\n",
    "#     subfolders = [\"dataset_samples\", \"model_results\", \"before_after\"]\n",
    "#     for subfolder in subfolders:\n",
    "#         os.makedirs(os.path.join(base_folder, subfolder), exist_ok=True)\n",
    "#     logging.info(f\"Subcarpetas creadas en {base_folder}: {', '.join(subfolders)}\")\n",
    "\n",
    "# def main() -> None:\n",
    "#     \"\"\"\n",
    "#     Ejecución principal del pipeline de visualización.\n",
    "#     \"\"\"\n",
    "#     base_folder = \"presentation\"\n",
    "#     organize_presentation_folders(base_folder)\n",
    "\n",
    "#     dataset_folder = \"datasets/processed_images\"\n",
    "#     model_path = \"YOLO_Lego_Detection/best.pt\"\n",
    "\n",
    "#     create_dataset_grid(dataset_folder, os.path.join(base_folder, \"dataset_samples\"))\n",
    "#     annotate_model_results(model_path, dataset_folder, os.path.join(base_folder, \"model_results\"))\n",
    "#     generate_comparison_grid(model_path, dataset_folder, os.path.join(base_folder, \"before_after\"))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt conversacion de refinamiento de README.md\n",
    "\n",
    "para actualizar el comentariado luego de la publicacion en PyPl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "Tengo dos scripts bien comentados y refinados que forman el núcleo de mi proyecto. También tengo un archivo `README.md` existente, pero necesito actualizarlo para reflejar los cambios y documentar de forma profesional el proyecto. Aquí están las instrucciones:\n",
    "\n",
    "1. **Descripción clara del proyecto**:\n",
    "   - Explica qué resuelve el proyecto y por qué es útil.\n",
    "   - Destaca las funcionalidades principales basadas en los scripts proporcionados.\n",
    "\n",
    "2. **Estructura profesional**:\n",
    "   - Introducción: Breve descripción del proyecto.\n",
    "   - Instalación: Cómo instalar las dependencias y preparar el entorno.\n",
    "   - Uso: Instrucciones para ejecutar las funcionalidades principales.\n",
    "   - Detalle de scripts y funciones: Documenta cada función clave basada en las docstrings de los scripts refinados.\n",
    "   - Contribuciones: Guía para colaborar.\n",
    "\n",
    "3. **Ejemplos prácticos**:\n",
    "   - Muestra cómo usar funciones principales, con ejemplos claros y fáciles de entender en bloques de código.\n",
    "\n",
    "4. **Estructura del proyecto**:\n",
    "   - Describe la organización de carpetas y archivos, indicando dónde encontrar scripts, datos y resultados.\n",
    "\n",
    "5. **Consistencia y claridad**:\n",
    "   - El README.md debe ser accesible tanto para principiantes como para desarrolladores avanzados.\n",
    "\n",
    "A continuación, tienes los archivos necesarios:\n",
    "1. El estado actual del archivo `README.md`.\n",
    "2. Los dos scripts refinados (`pipeline.py` y `visualize_presentation.py`).\n",
    "\n",
    "Por favor, actualiza el `README.md` para reflejar toda la funcionalidad implementada, utilizando una estructura clara y profesional. Asegúrate de incluir ejemplos prácticos y explicaciones detalladas basadas en las docstrings de los scripts.\n",
    "\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt para actualizar el technical_report.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \"\n",
    "\n",
    "Quiero integrar el código de mi paquete publicado en PyPI (lego-bricks-ml-vision) en el documento técnico LEGO_Bricks_Identification_Project_Technical_Report.pdf. El objetivo principal es actualizar el documento para que:\n",
    "\n",
    "Utilice las funciones del paquete:\n",
    "\n",
    "Sustituir bloques de código existentes por ejemplos claros de cómo usar el paquete.\n",
    "Mostrar cómo el pipeline completo puede ser ejecutado con las herramientas del paquete.\n",
    "Simplifique la reproducción de la experiencia:\n",
    "\n",
    "Incluir comandos claros para instalar el paquete y ejecutar pipelines directamente desde el CLI (run-pipeline y run-visualize).\n",
    "Agregar ejemplos de configuración inicial y manejo de errores.\n",
    "Actualice la estructura del documento:\n",
    "\n",
    "Reorganizar las secciones de \"Creación del Dataset\", \"Entrenamiento del Modelo\" y \"Visualización de Resultados\" para reflejar el flujo modular del paquete.\n",
    "Ajustar las secciones de reflexión para resaltar la escalabilidad y facilidad de uso del paquete.\n",
    "Incluya referencias al README:\n",
    "\n",
    "Citar el README y documentación del paquete como recursos adicionales para ampliar la información técnica.\n",
    "Tareas específicas:\n",
    "Revise la sección de introducción para incorporar una descripción breve del paquete y cómo facilita el flujo de trabajo.\n",
    "Sustituya el código en Python por ejemplos concretos de uso de las funciones del paquete (preprocess_images, train_yolo_pipeline, etc.).\n",
    "Proporcione instrucciones para ejecutar pipelines y generar visualizaciones utilizando los comandos de CLI (run-pipeline y run-visualize).\n",
    "Verifique la claridad y profesionalismo del lenguaje, garantizando un tono técnico accesible.\n",
    "Por favor, comencemos revisando la sección de \"Creación del Dataset\" y trabajemos iterativamente para integrar las funciones del paquete.\n",
    "\n",
    "\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First iteration technical_report.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEGO Bricks Identification Project: A Technical Report\n",
    "\n",
    "### 1. Introduction and Motivation 🌟\n",
    "\n",
    "This project leverages the **`lego-bricks-ml-vision`** package to implement an efficient pipeline for detecting and classifying LEGO bricks. Inspired by the challenge of identifying specific pieces within a cluttered set of LEGO bricks, this project combines computer vision, machine learning, and dataset management to achieve scalable and replicable results.\n",
    "\n",
    "The key objectives include:\n",
    "\n",
    "1. Designing a pipeline for object detection using YOLOv8.\n",
    "2. Documenting the process to ensure reproducibility and scalability.\n",
    "3. Providing tools for visualization and analysis to showcase the model’s performance.\n",
    "\n",
    "### 2. Dataset Creation 📝\n",
    "\n",
    "The dataset creation process is streamlined using the **`lego-bricks-ml-vision`** package. This package provides commands for downloading datasets, preprocessing images, and converting annotations.\n",
    "\n",
    "#### 2.1 Dataset Overview \n",
    "\n",
    "The dataset used for this project is hosted on Kaggle:\n",
    "- **Dataset Name**: [Spiled LEGO Bricks](https://www.kaggle.com/datasets/migueldilalla/spiled-lego-bricks)\n",
    "- **Contents**:\n",
    "  - **Images**: 1803 images (600×800 resolution)\n",
    "  - **Annotations**: LabelMe-compatible `.txt` files with bounding box data.\n",
    "\n",
    "#### 2.2 Setting Up the Environment \n",
    "\n",
    "Install the **`lego-bricks-ml-vision`** package from PyPI:\n",
    "\n",
    "```python\n",
    "!pip install lego-bricks-ml-vision\n",
    "```\n",
    "\n",
    "Configure the pipeline:\n",
    "\n",
    "```python\n",
    "from lego_bricks_ml_vision import setup_environment\n",
    "setup_environment()\n",
    "```\n",
    "\n",
    "This command ensures that all dependencies are installed and that your environment is ready.\n",
    "\n",
    "#### 2.3 Downloading the Dataset \n",
    "\n",
    "The dataset can be directly downloaded and extracted using the following commands:\n",
    "\n",
    "```python\n",
    "!run-pipeline download-dataset \\\n",
    "    --kaggle-dataset \"migueldilalla/spiled-lego-bricks\" \\\n",
    "    --output-dir \"datasets\"\n",
    "```\n",
    "\n",
    "#### 2.4 Preprocessing Images \n",
    "\n",
    "Resize the images to a consistent size (e.g., 256x256) for model training:\n",
    "\n",
    "```python\n",
    "!run-pipeline preprocess-images \\\n",
    "    --input-dir \"datasets/Images_600x800\" \\\n",
    "    --output-dir \"datasets/processed_images\" \\\n",
    "    --target-size 256\n",
    "```\n",
    "\n",
    "#### 2.5 Converting Annotations \n",
    "\n",
    "Convert annotations from LabelMe format to YOLO format:\n",
    "\n",
    "```python\n",
    "!run-pipeline labelme-to-yolo \\\n",
    "    --input-folder \"datasets/LabelMe_txt_bricks\" \\\n",
    "    --output-folder \"datasets/annotations\"\n",
    "```\n",
    "\n",
    "By automating these tasks, the package ensures consistency and reduces manual effort.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Model Training 🧬\n",
    "\n",
    "The project uses YOLOv8 for LEGO brick detection. Training is performed using the preprocessed dataset and YOLO-compatible annotations.\n",
    "\n",
    "#### 3.1 Training the YOLO Model\n",
    "\n",
    "The `train_yolo_pipeline` function enables straightforward model training:\n",
    "\n",
    "```python\n",
    "!run-pipeline train-yolo \\\n",
    "    --dataset-path \"datasets\" \\\n",
    "    --epochs 50 \\\n",
    "    --img-size 256\n",
    "```\n",
    "\n",
    "#### 3.2 Validating the Model\n",
    "\n",
    "Evaluate the trained model on test images:\n",
    "\n",
    "```python\n",
    "!run-pipeline test-model \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --test-images-dir \"test_images\" \\\n",
    "    --output-dir \"results\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Visualization and Results 🎨\n",
    "\n",
    "#### 4.1 Visualizing Results\n",
    "\n",
    "Visualize predictions and annotations using:\n",
    "\n",
    "```python\n",
    "!run-visualize annotate-results \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/model_results\"\n",
    "```\n",
    "\n",
    "#### 4.2 Generating Comparison Grids\n",
    "\n",
    "Compare predictions against ground truth:\n",
    "\n",
    "```python\n",
    "!run-visualize comparison-grid \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/comparison\"\n",
    "```\n",
    "\n",
    "#### 4.3 Creating Presentation Grids\n",
    "\n",
    "Summarize dataset samples in a grid format:\n",
    "\n",
    "```python\n",
    "!run-visualize create-grid \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/dataset_samples\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Reflection and Future Work 🔄\n",
    "\n",
    "This project demonstrates the effectiveness of modular pipelines for scalable machine learning workflows. Key insights include:\n",
    "\n",
    "- **Data Quality**: High-quality, annotated datasets significantly enhance model performance.\n",
    "- **Modularity**: Breaking down the pipeline into distinct stages improves reproducibility.\n",
    "- **Visualization**: Effective visual tools aid in debugging and communicating results.\n",
    "\n",
    "#### Future Improvements:\n",
    "1. Expanding the dataset to include more LEGO pieces.\n",
    "2. Integrating semi-automated annotation tools.\n",
    "3. Developing an interactive interface for real-time predictions.\n",
    "\n",
    "---\n",
    "\n",
    "For more details, refer to the [LEGO Bricks ML Vision Documentation](https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook saved to: C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\Technical_Report.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nbformat as nbf\n",
    "\n",
    "# Paths for input and output\n",
    "input_md_path = r\"C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\Technical_Report.md\"\n",
    "output_nb_path = r\"C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\Technical_Report.ipynb\"\n",
    "\n",
    "# Read the markdown file\n",
    "with open(input_md_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize a new notebook\n",
    "notebook = nbf.v4.new_notebook()\n",
    "\n",
    "# Process the markdown file line by line\n",
    "current_cell_type = \"markdown\"\n",
    "current_cell_content = []\n",
    "\n",
    "for line in lines:\n",
    "    # Detect code block start or end\n",
    "    if line.strip().startswith(\"```\"):  # Toggle between markdown and code\n",
    "        if current_cell_type == \"code\":\n",
    "            # End of a code cell\n",
    "            notebook.cells.append(nbf.v4.new_code_cell(\"\".join(current_cell_content)))\n",
    "            current_cell_content = []\n",
    "            current_cell_type = \"markdown\"\n",
    "        else:\n",
    "            # End of a markdown cell\n",
    "            if current_cell_content:\n",
    "                notebook.cells.append(nbf.v4.new_markdown_cell(\"\".join(current_cell_content)))\n",
    "            current_cell_content = []\n",
    "            current_cell_type = \"code\"\n",
    "    else:\n",
    "        # Append content to the current cell\n",
    "        current_cell_content.append(line)\n",
    "\n",
    "# Add any remaining content as a final cell\n",
    "if current_cell_content:\n",
    "    if current_cell_type == \"markdown\":\n",
    "        notebook.cells.append(nbf.v4.new_markdown_cell(\"\".join(current_cell_content)))\n",
    "    elif current_cell_type == \"code\":\n",
    "        notebook.cells.append(nbf.v4.new_code_cell(\"\".join(current_cell_content)))\n",
    "\n",
    "# Save the notebook\n",
    "nbf.write(notebook, output_nb_path)\n",
    "print(f\"Notebook saved to: {output_nb_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnvHaB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
