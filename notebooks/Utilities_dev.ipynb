{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")  # Ajusta segÃºn tu estructura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate_folders_ImageDataProject.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project structure created successfully at: c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_project_structure():\n",
    "    \"\"\"\n",
    "    Create a folder structure for an image data project.\n",
    "\n",
    "    The base path is automatically set to the current working directory.\n",
    "    \"\"\"\n",
    "    # Set the base directory to the current working directory\n",
    "    base_path = os.getcwd()\n",
    "\n",
    "    # Define the folder structure\n",
    "    structure = {\n",
    "        \"data\": [\n",
    "            \"raw\",\n",
    "            \"processed\",\n",
    "            \"annotations\"\n",
    "        ],\n",
    "        \"src\": [\n",
    "            \"data_preprocessing\",\n",
    "            \"models\",\n",
    "            \"visualization\"\n",
    "        ],\n",
    "        \"models\": [\n",
    "            \"checkpoints\",\n",
    "            \"final\"\n",
    "        ],\n",
    "        \"results\": [\n",
    "            \"predictions\",\n",
    "            \"logs\"\n",
    "        ],\n",
    "        \"docs\": [],\n",
    "        \"notebooks\": [],\n",
    "        \"tests\": [],\n",
    "        \"presentation\": []\n",
    "    }\n",
    "\n",
    "    # Function to create folders recursively\n",
    "    def create_folders(base, folders):\n",
    "        for folder, subfolders in folders.items():\n",
    "            folder_path = os.path.join(base, folder)\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            for subfolder in subfolders:\n",
    "                os.makedirs(os.path.join(folder_path, subfolder), exist_ok=True)\n",
    "\n",
    "    # Create the structure\n",
    "    create_folders(base_path, structure)\n",
    "\n",
    "    print(f\"Project structure created successfully at: {base_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    create_project_structure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportar Refurbished PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook LEGO_Bricks_Identification_Project_Overview.ipynb to pdf\n",
      "[NbConvertApp] Writing 34205 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | b had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 42940 bytes to LEGO_Bricks_Identification_Project_Overview.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf LEGO_Bricks_Identification_Project_Overview.ipynb\n",
    "# !jupyter nbconvert --to pdf LEGO_Bricks_Identification_Project_Technical_Report.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refurbishing Pipeline\n",
    "\n",
    "(chatGPT is having bugs remembering converstions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "Â¡Perfecto! Vamos a estructurar esta entrevista para guiarte a reflexionar sobre cada etapa del proyecto y asegurarnos de que tu storytelling estÃ© alineado con las mejores prÃ¡cticas. Este enfoque tambiÃ©n nos permitirÃ¡ planear cÃ³mo documentar, reproducir y organizar el proyecto de manera profesional.\n",
    "\n",
    "Entrevista Inicial\n",
    "Te harÃ© preguntas relevantes por etapas del proyecto. Responde segÃºn tu experiencia, y construirÃ© secciones del documento con base en tus respuestas. TambiÃ©n sugerirÃ© scripts o ajustes segÃºn lo que compartas.\n",
    "\n",
    "1. Origen del Proyecto\n",
    "Â¿QuÃ© te motivÃ³ a iniciar este proyecto? Â¿Fue un desafÃ­o tÃ©cnico que querÃ­as resolver, una curiosidad personal, o algo mÃ¡s?\n",
    "Â¿CÃ³mo conectaste tus habilidades previas con esta idea? Por ejemplo, Â¿quÃ© experiencias te influyeron a elegir visiÃ³n por computadora y no otro campo?\n",
    "2. CreaciÃ³n del Dataset\n",
    "Â¿QuÃ© tipo de datos recopilaste y cÃ³mo? Comparte detalles sobre el proceso, como herramientas utilizadas, nÃºmero de imÃ¡genes, y estrategias para capturar diferentes Ã¡ngulos y condiciones.\n",
    "Â¿CÃ³mo manejaste la anotaciÃ³n de los datos? Â¿Usaste alguna herramienta especÃ­fica como LabelMe o desarrollaste algo propio? Â¿Hubo desafÃ­os en esta etapa?\n",
    "Â¿QuÃ© criterios usaste para limpiar y preparar los datos? Por ejemplo, Â¿eliminaste imÃ¡genes borrosas o hiciste algÃºn balanceo entre clases?\n",
    "3. SelecciÃ³n del Modelo\n",
    "Â¿Por quÃ© elegiste YOLO? Â¿Probaste otros modelos antes? Si es asÃ­, Â¿cuÃ¡les y por quÃ© los descartaste?\n",
    "Â¿CÃ³mo ajustaste los hiperparÃ¡metros durante el entrenamiento? Por ejemplo, tamaÃ±o de lotes, nÃºmero de Ã©pocas, etc.\n",
    "Â¿QuÃ© limitaciones encontraste en el modelo, y cÃ³mo las abordaste?\n",
    "4. ImplementaciÃ³n y Resultados\n",
    "Â¿CÃ³mo transformaste los resultados del modelo en algo prÃ¡ctico? Por ejemplo, Â¿cÃ³mo calculaste las dimensiones de las piezas basÃ¡ndote en la detecciÃ³n de studs?\n",
    "Â¿QuÃ© mÃ©tricas utilizaste para medir el Ã©xito? Â¿Precision, recall, F1-score, u otras? Â¿CÃ³mo documentaste estos resultados?\n",
    "Â¿QuÃ© visualizaciones creaste para entender mejor los resultados?\n",
    "5. ReflexiÃ³n y Futuro\n",
    "Â¿QuÃ© aprendiste en tÃ©rminos tÃ©cnicos y personales? Â¿QuÃ© habilidades desarrollaste o reforzaste?\n",
    "Si comenzaras de nuevo, Â¿quÃ© harÃ­as diferente?\n",
    "Â¿QuÃ© pasos futuros te gustarÃ­a explorar? Por ejemplo, Â¿mejorar el modelo, ampliar el dataset, o implementar nuevas funcionalidades?\n",
    "PrÃ³ximos Pasos\n",
    "Conforme respondas, construirÃ© borradores de las secciones correspondientes del documento. Si surgen necesidades especÃ­ficas (como scripts para repetir entrenamientos), las desarrollaremos y definiremos cÃ³mo integrarlas al proyecto.\n",
    "\n",
    "Comencemos con tus respuestas a las primeras preguntas de la secciÃ³n 1 sobre la motivaciÃ³n y el origen del proyecto. ðŸ˜Š\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion de pipeline central\n",
    "\n",
    "## pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "\n",
    "# import os\n",
    "\n",
    "# def generate_structure_file(output_file=\"estructura.txt\"):\n",
    "#     \"\"\"\n",
    "#     Genera un archivo con la estructura de directorios solo si el directorio actual\n",
    "#     contiene una carpeta 'src' o estÃ¡ relacionado con ella.\n",
    "\n",
    "#     Args:\n",
    "#         output_file (str): Nombre del archivo para guardar la estructura.\n",
    "#     \"\"\"\n",
    "#     # Directorio actual\n",
    "#     current_dir = os.getcwd()\n",
    "\n",
    "#     # Verificar si existe la carpeta 'src' en el directorio actual\n",
    "#     if \"src\" in os.listdir(current_dir):\n",
    "#         # Crear la estructura en el directorio actual\n",
    "#         target_dir = current_dir\n",
    "#         print(f\"Directorio 'src' encontrado en el directorio actual: {target_dir}\")\n",
    "#     else:\n",
    "#         # Subir al directorio padre y verificar si 'src' es una carpeta hermana\n",
    "#         parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "#         if \"src\" in os.listdir(parent_dir):\n",
    "#             # Crear la estructura en el directorio padre\n",
    "#             target_dir = parent_dir\n",
    "#             print(f\"Directorio 'src' encontrado como carpeta hermana. Generando estructura en: {target_dir}\")\n",
    "#         else:\n",
    "#             print(\"No se encontrÃ³ la carpeta 'src'. No se generarÃ¡ el archivo de estructura.\")\n",
    "#             return\n",
    "\n",
    "#     # Generar la estructura\n",
    "#     with open(output_file, \"w\") as f:\n",
    "#         for root, dirs, files in os.walk(target_dir):\n",
    "#             level = root.replace(target_dir, \"\").count(os.sep)\n",
    "#             indent = \" \" * 4 * level\n",
    "#             f.write(f\"{indent}{os.path.basename(root)}/\\n\")\n",
    "#             subindent = \" \" * 4 * (level + 1)\n",
    "#             for file in files:\n",
    "#                 f.write(f\"{subindent}{file}\\n\")\n",
    "\n",
    "#     print(f\"Estructura generada exitosamente en: {output_file}\")\n",
    "\n",
    "# # Ejecutar la funciÃ³n\n",
    "# if __name__ == \"__main__\":\n",
    "#     generate_structure_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\n",
      "c:\\Users\\User\\Projects_Unprotected\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Muestra la ruta actual\n",
    "print(os.getcwd())\n",
    "\n",
    "# Cambia al directorio raÃ­z del proyecto\n",
    "os.chdir(\"..\")  # Cambia al directorio raÃ­z\n",
    "\n",
    "# Confirma el cambio de directorio\n",
    "print(os.getcwd())\n",
    "\n",
    "# Importa funciones desde el pipeline\n",
    "from scripts.pipeline import (\n",
    "    setup_environment,\n",
    "    get_kaggle_credentials,\n",
    "    download_dataset_from_kaggle,\n",
    "    validate_directories,\n",
    "    preprocess_images,\n",
    "    labelme_to_yolo,\n",
    "    train_yolo_pipeline,\n",
    "    test_model_on_real_images,\n",
    "    visualize_results,\n",
    ")\n",
    "\n",
    "# Prueba de las funciones importadas\n",
    "setup_environment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview.pdf\n",
    "\n",
    "## visualize_presentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from pipeline import test_model_on_real_images\n",
    "\n",
    "# # Crear grids de muestras del dataset\n",
    "# def create_dataset_grid(input_folder, output_folder, grid_size=(3, 3)):\n",
    "#     \"\"\"\n",
    "#     Genera un grid de imÃ¡genes de muestra del dataset y las guarda en la carpeta especificada.\n",
    "\n",
    "#     Parameters:\n",
    "#     - input_folder (str): Ruta de la carpeta con las imÃ¡genes de entrada.\n",
    "#     - output_folder (str): Ruta donde se guardarÃ¡ el grid generado.\n",
    "#     - grid_size (tuple): Dimensiones del grid (filas, columnas).\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     random.shuffle(image_files)\n",
    "    \n",
    "#     selected_files = image_files[:grid_size[0] * grid_size[1]]\n",
    "#     fig, axes = plt.subplots(*grid_size, figsize=(grid_size[1] * 4, grid_size[0] * 4))\n",
    "\n",
    "#     for idx, img_file in enumerate(selected_files):\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         img = Image.open(img_path)\n",
    "#         row, col = divmod(idx, grid_size[1])\n",
    "#         axes[row, col].imshow(img)\n",
    "#         axes[row, col].axis('off')\n",
    "#         axes[row, col].set_title(f\"{img_file}\", fontsize=10)\n",
    "\n",
    "#     for ax in axes.flat[len(selected_files):]:\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     grid_path = os.path.join(output_folder, \"dataset_grid.png\")\n",
    "#     plt.savefig(grid_path, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "#     print(f\"Grid de dataset guardado en {grid_path}.\")\n",
    "\n",
    "# # Generar visualizaciones anotadas\n",
    "# def annotate_model_results(model_path, input_folder, output_folder, conf_threshold=0.5):\n",
    "#     \"\"\"\n",
    "#     Genera imÃ¡genes con anotaciones del modelo y las guarda en la carpeta especificada.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#     - input_folder (str): Carpeta con imÃ¡genes de entrada.\n",
    "#     - output_folder (str): Carpeta para guardar las imÃ¡genes anotadas.\n",
    "#     - conf_threshold (float): Umbral de confianza para las detecciones.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     test_model_on_real_images(model_path, input_folder, output_folder)\n",
    "#     print(f\"Resultados anotados guardados en {output_folder}.\")\n",
    "\n",
    "# # Crear comparaciones antes/despuÃ©s\n",
    "# def generate_comparison_grid(model_path, input_folder, output_folder, num_samples=5):\n",
    "#     \"\"\"\n",
    "#     Crea un grid comparativo de imÃ¡genes antes y despuÃ©s de las predicciones del modelo.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#     - input_folder (str): Carpeta con imÃ¡genes de entrada.\n",
    "#     - output_folder (str): Carpeta para guardar los grids generados.\n",
    "#     - num_samples (int): NÃºmero de imÃ¡genes a comparar.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     random.shuffle(image_files)\n",
    "#     selected_files = image_files[:num_samples]\n",
    "\n",
    "#     for img_file in selected_files:\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         result_path = os.path.join(output_folder, img_file)\n",
    "\n",
    "#         test_model_on_real_images(model_path, img_path, output_folder)\n",
    "#         annotated_img = Image.open(result_path)\n",
    "#         original_img = Image.open(img_path)\n",
    "\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#         axes[0].imshow(original_img)\n",
    "#         axes[0].axis('off')\n",
    "#         axes[0].set_title(\"Original\")\n",
    "\n",
    "#         axes[1].imshow(annotated_img)\n",
    "#         axes[1].axis('off')\n",
    "#         axes[1].set_title(\"Anotado\")\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         comparison_path = os.path.join(output_folder, f\"comparison_{img_file}\")\n",
    "#         plt.savefig(comparison_path, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "#         print(f\"Grid de comparaciÃ³n guardado en {comparison_path}.\")\n",
    "\n",
    "# # OrganizaciÃ³n automÃ¡tica de subcarpetas\n",
    "# def organize_presentation_folders(base_folder):\n",
    "#     \"\"\"\n",
    "#     Crea y organiza las subcarpetas necesarias para las visualizaciones.\n",
    "\n",
    "#     Parameters:\n",
    "#     - base_folder (str): Carpeta raÃ­z para las subcarpetas.\n",
    "#     \"\"\"\n",
    "#     subfolders = [\"dataset_samples\", \"model_results\", \"before_after\"]\n",
    "#     for subfolder in subfolders:\n",
    "#         os.makedirs(os.path.join(base_folder, subfolder), exist_ok=True)\n",
    "#     print(f\"Subcarpetas creadas en {base_folder}: {', '.join(subfolders)}\")\n",
    "\n",
    "# # EjecuciÃ³n del pipeline de visualizaciÃ³n\n",
    "# def main():\n",
    "#     base_folder = \"presentation\"\n",
    "#     organize_presentation_folders(base_folder)\n",
    "\n",
    "#     dataset_folder = \"datasets/processed_images\"\n",
    "#     model_path = \"YOLO_Lego_Detection/best.pt\"\n",
    "\n",
    "#     create_dataset_grid(dataset_folder, os.path.join(base_folder, \"dataset_samples\"))\n",
    "#     annotate_model_results(model_path, dataset_folder, os.path.join(base_folder, \"model_results\"))\n",
    "#     generate_comparison_grid(model_path, dataset_folder, os.path.join(base_folder, \"before_after\"))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Projects_Unprotected\n",
      "c:\\Users\\User\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualize_presentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Importar funciones clave\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvisualize_presentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     create_dataset_grid,\n\u001b[0;32m     18\u001b[0m     annotate_model_results,\n\u001b[0;32m     19\u001b[0m     generate_comparison_grid,\n\u001b[0;32m     20\u001b[0m     organize_presentation_folders\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Definir rutas de entrada y salida\u001b[39;00m\n\u001b[0;32m     24\u001b[0m BASE_FOLDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visualize_presentation'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Muestra la ruta actual\n",
    "print(os.getcwd())\n",
    "\n",
    "# Cambia al directorio raÃ­z del proyecto\n",
    "os.chdir(\"..\")  # Cambia al directorio raÃ­z\n",
    "\n",
    "# Confirma el cambio de directorio\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Importar funciones clave\n",
    "from visualize_presentation import (\n",
    "    create_dataset_grid,\n",
    "    annotate_model_results,\n",
    "    generate_comparison_grid,\n",
    "    organize_presentation_folders\n",
    ")\n",
    "\n",
    "# Definir rutas de entrada y salida\n",
    "BASE_FOLDER = \"presentation\"\n",
    "DATASET_FOLDER = \"datasets/processed_images\"\n",
    "MODEL_PATH = \"YOLO_Lego_Detection/best.pt\"\n",
    "\n",
    "# Crear y organizar las carpetas de presentaciÃ³n\n",
    "organize_presentation_folders(BASE_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\n",
      "c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\n",
      "['c:\\\\Users\\\\User\\\\Projects_Unprotected\\\\LEGO_Bricks_ML_Vision\\\\notebooks',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\python312.zip',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\DLLs',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB',\n",
      " '',\n",
      " 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\win32',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\win32\\\\lib',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\Pythonwin',\n",
      " 'c:\\\\Users\\\\User\\\\.conda\\\\envs\\\\MiguelEnvHaB\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor',\n",
      " 'c:\\\\Users\\\\User\\\\Projects_Unprotected\\\\LEGO_Bricks_ML_Vision']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# Muestra la ruta actual\n",
    "print(os.getcwd())\n",
    "\n",
    "# Cambia al directorio raÃ­z del proyecto\n",
    "os.chdir(\"..\")  # Cambia al directorio raÃ­z\n",
    "\n",
    "# Confirma el cambio de directorio\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(os.getcwd()) \n",
    "\n",
    "pprint(sys.path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar todo el pipeline de visualizaciÃ³n\n",
    "def run_visualization_pipeline():\n",
    "    organize_presentation_folders(BASE_FOLDER)\n",
    "    create_dataset_grid(DATASET_FOLDER, f\"{BASE_FOLDER}/dataset_samples\", grid_size=(3, 3))\n",
    "    annotate_model_results(MODEL_PATH, DATASET_FOLDER, f\"{BASE_FOLDER}/model_results\")\n",
    "    generate_comparison_grid(MODEL_PATH, DATASET_FOLDER, f\"{BASE_FOLDER}/before_after\", num_samples=5)\n",
    "\n",
    "run_visualization_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup.py \n",
    "\n",
    "Packege publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from setuptools import setup, find_packages\n",
    "\n",
    "# setup(\n",
    "#     name=\"lego_bricks_ml_vision\",\n",
    "#     version=\"0.1.0\",\n",
    "#     packages=find_packages(),\n",
    "#     install_requires=[\n",
    "#         \"torch>=1.8.0\",\n",
    "#         \"ultralytics\",\n",
    "#         \"pillow\",\n",
    "#         \"matplotlib\",\n",
    "#         \"kaggle\",\n",
    "#     ],\n",
    "#     entry_points={\n",
    "#         \"console_scripts\": [\n",
    "#             \"run-pipeline=scripts.pipeline:main\",\n",
    "#             \"run-visualize=scripts.visualize_presentation:main\",\n",
    "#         ],\n",
    "#     },\n",
    "#     author=\"Miguel Di Lalla\",\n",
    "#     description=\"A package for LEGO brick detection and visualization using YOLO.\",\n",
    "#     long_description=open(\"README.md\").read(),\n",
    "#     long_description_content_type=\"text/markdown\",\n",
    "#     license=\"Apache License 2.0\",\n",
    "#     classifiers=[\n",
    "#         \"Programming Language :: Python :: 3\",\n",
    "#         \"License :: OSI Approved :: Apache Software License\",\n",
    "#         \"Operating System :: OS Independent\",\n",
    "#     ],\n",
    "#     python_requires=\">=3.8\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rqueriments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Versions:\n",
      "PyTorch: 2.4.1+cpu\n",
      "Ultralytics: 8.2.99\n",
      "Pillow (PIL): 11.1.0\n",
      "Matplotlib: 3.8.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "import PIL\n",
    "import matplotlib\n",
    "import kaggle\n",
    "\n",
    "print(\"Environment Versions:\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Ultralytics: {ultralytics.__version__}\")\n",
    "print(f\"Pillow (PIL): {PIL.__version__}\")\n",
    "print(f\"Matplotlib: {matplotlib.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kaggle\n",
      "Version: 1.6.17\n",
      "Summary: Kaggle API\n",
      "Home-page: https://github.com/Kaggle/kaggle-api\n",
      "Author: Kaggle\n",
      "Author-email: support@kaggle.com\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\n",
      "Requires: bleach, certifi, python-dateutil, python-slugify, requests, six, tqdm, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# print(f\"Kaggle: {kaggle.__version__}\")\n",
    "! pip show kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch==2.4.1+cpu #torch==2.0.1+cpu\n",
    "ultralytics==8.2.99\n",
    "pillow==11.1.0\n",
    "matplotlib==3.8.4\n",
    "kaggle==1.6.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Bricks ML Vision\n",
    "\n",
    "A Python package for detecting and visualizing LEGO bricks using YOLO and custom visualization pipelines. This project is designed to streamline the process of detecting LEGO pieces in cluttered environments and producing meaningful visualizations for analysis and presentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Object Detection**: Detect LEGO bricks using YOLOv8.\n",
    "- **Preprocessing Tools**: Scripts to preprocess images and datasets.\n",
    "- **Dataset Conversion**: Convert LabelMe annotations to YOLO format.\n",
    "- **Visualization Pipelines**: Create annotated grids, comparisons, and organized folders for presentations.\n",
    "- **Modular Design**: Easy-to-use package structure for scaling or adapting the project.\n",
    "\n",
    "---\n",
    "\n",
    "## Installation\n",
    "\n",
    "To get started with the project, clone the repository and install the package:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision.git\n",
    "cd LEGO_Bricks_ML_Vision\n",
    "pip install -e .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.pipeline import train_yolo_pipeline\n",
    "from scripts.visualize_presentation import create_dataset_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Train YOLO pipeline\n",
    "train_yolo_pipeline(\"path/to/dataset\")\n",
    "\n",
    "# Example: Create a dataset grid\n",
    "create_dataset_grid(\"path/to/images\", \"path/to/output\", grid_size=(3, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt conversacion del pipeline.py\n",
    "\n",
    "para actualizar el comentariado luego de la publicacion en PyPl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "Tengo un script en Python que necesita ser revisado y refinado para alcanzar un nivel profesional. AquÃ­ estÃ¡n los objetivos especÃ­ficos que quiero lograr:\n",
    "\n",
    "1. **Comentarios claros y precisos**: Cada funciÃ³n debe tener una docstring descriptiva que explique claramente su propÃ³sito, parÃ¡metros, y valores de retorno (si los hay). Los comentarios en lÃ­nea deben ser breves, relevantes y ayudar a entender el cÃ³digo.\n",
    "\n",
    "2. **Formato consistente**: El cÃ³digo debe seguir el estÃ¡ndar **PEP 8**, incluyendo:\n",
    "   - Longitud de lÃ­nea mÃ¡xima de 79 caracteres.\n",
    "   - IdentaciÃ³n adecuada (4 espacios).\n",
    "   - Espaciado entre bloques y funciones.\n",
    "   - OrganizaciÃ³n lÃ³gica de las importaciones (primero estÃ¡ndar, luego librerÃ­as externas, y finalmente locales).\n",
    "\n",
    "3. **OrganizaciÃ³n de secciones**: Agrupa las funciones relacionadas y aÃ±ade encabezados de comentarios (# ===) para separar las secciones principales del script.\n",
    "\n",
    "4. **Buena prÃ¡ctica en manejo de errores**: Incluye excepciones manejadas correctamente donde sea relevante (e.g., para operaciones de I/O o dependencias externas).\n",
    "\n",
    "5. **Estilo profesional en los print()**: Usa mensajes formateados de manera clara y profesional, por ejemplo:\n",
    "   ```python\n",
    "   print(f\"[INFO] Dataset descargado y extraÃ­do en {destination}\")\n",
    "\n",
    "6. **Detalles adicionales:** Si algo en el cÃ³digo puede ser optimizado o mejorado, propÃ³n cambios para hacerlo mÃ¡s eficiente y profesional.\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# import shutil\n",
    "# import kaggle\n",
    "# import zipfile\n",
    "\n",
    "# # === ConfiguraciÃ³n Inicial ===\n",
    "# def setup_environment():\n",
    "#     \"\"\"\n",
    "#     Clona el repositorio y configura el entorno necesario para ejecutar el pipeline.\n",
    "\n",
    "#     - Clona el repositorio de GitHub.\n",
    "#     - Instala las dependencias desde el archivo requirements.txt.\n",
    "#     - Configura el dispositivo de ejecuciÃ³n (CPU o GPU).\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         os.system(\"git clone https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision.git\")\n",
    "#         os.chdir(\"LEGO_Bricks_ML_Vision\")\n",
    "#         os.system(\"pip install -r requirements.txt\")\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#         print(f\"[INFO] Using device: {device}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Error al configurar el entorno: {e}\")\n",
    "\n",
    "# # === Manejo de Credenciales de Kaggle ===\n",
    "# def get_kaggle_credentials():\n",
    "#     \"\"\"\n",
    "#     Obtiene las credenciales de Kaggle desde variables de entorno o archivo kaggle.json.\n",
    "\n",
    "#     Prioridad de bÃºsqueda:\n",
    "#     1. Variables de entorno: KAGGLE_USERNAME y KAGGLE_KEY.\n",
    "#     2. Archivo ~/.kaggle/kaggle.json.\n",
    "\n",
    "#     Returns:\n",
    "#     - dict: Diccionario con 'username' y 'key'.\n",
    "#     \"\"\"\n",
    "#     username = os.getenv(\"KAGGLE_USERNAME\")\n",
    "#     key = os.getenv(\"KAGGLE_KEY\")\n",
    "\n",
    "#     if username and key:\n",
    "#         return {\"username\": username, \"key\": key}\n",
    "\n",
    "#     kaggle_json_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "#     if os.path.exists(kaggle_json_path):\n",
    "#         try:\n",
    "#             with open(kaggle_json_path, \"r\") as f:\n",
    "#                 return json.load(f)\n",
    "#         except Exception as e:\n",
    "#             raise ValueError(f\"[ERROR] No se pudo leer kaggle.json: {e}\")\n",
    "\n",
    "#     raise ValueError(\"[ERROR] Credenciales de Kaggle no encontradas. Configure las variables de entorno o coloque kaggle.json en ~/.kaggle.\")\n",
    "\n",
    "# # === Descarga de Dataset ===\n",
    "# def download_dataset_from_kaggle(dataset, destination):\n",
    "#     \"\"\"\n",
    "#     Descarga y extrae un dataset de Kaggle.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset (str): Nombre del dataset en el formato \"usuario/dataset\".\n",
    "#     - destination (str): Ruta donde se extraerÃ¡n los archivos.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         credentials = get_kaggle_credentials()\n",
    "\n",
    "#         os.makedirs(destination, exist_ok=True)\n",
    "#         os.environ[\"KAGGLE_USERNAME\"] = credentials[\"username\"]\n",
    "#         os.environ[\"KAGGLE_KEY\"] = credentials[\"key\"]\n",
    "\n",
    "#         kaggle.api.dataset_download_files(dataset, path=destination, unzip=True)\n",
    "#         print(f\"[INFO] Dataset descargado y extraÃ­do en {destination}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] No se pudo descargar el dataset: {e}\")\n",
    "\n",
    "# # === ValidaciÃ³n de Directorios ===\n",
    "# def validate_directories(directories):\n",
    "#     \"\"\"\n",
    "#     Valida la existencia de los directorios especificados.\n",
    "\n",
    "#     Parameters:\n",
    "#     - directories (list): Lista de rutas a validar.\n",
    "\n",
    "#     Returns:\n",
    "#     - bool: True si todos los directorios existen, False en caso contrario.\n",
    "#     \"\"\"\n",
    "#     for directory in directories:\n",
    "#         if not os.path.exists(directory):\n",
    "#             print(f\"[ERROR] Directorio no encontrado: {directory}\")\n",
    "#             return False\n",
    "#     print(\"[INFO] Todos los directorios estÃ¡n correctamente configurados.\")\n",
    "#     return True\n",
    "\n",
    "# # === Preprocesamiento de ImÃ¡genes ===\n",
    "# def preprocess_images(input_dir, output_dir, target_size=(256, 256)):\n",
    "#     \"\"\"\n",
    "#     Redimensiona imÃ¡genes y asegura consistencia en nombres de archivos.\n",
    "\n",
    "#     Parameters:\n",
    "#     - input_dir (str): Ruta de la carpeta con imÃ¡genes originales.\n",
    "#     - output_dir (str): Ruta de la carpeta para guardar las imÃ¡genes procesadas.\n",
    "#     - target_size (tuple): Dimensiones objetivo para las imÃ¡genes (ancho, alto).\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     for i, filename in enumerate(sorted(os.listdir(input_dir))):\n",
    "#         if filename.endswith(\".jpg\"):\n",
    "#             try:\n",
    "#                 img = Image.open(os.path.join(input_dir, filename))\n",
    "#                 img_resized = img.resize(target_size)\n",
    "#                 new_filename = f\"image_{i}.jpg\"\n",
    "#                 img_resized.save(os.path.join(output_dir, new_filename))\n",
    "#                 print(f\"[INFO] Procesado: {filename} -> {new_filename}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"[ERROR] No se pudo procesar {filename}: {e}\")\n",
    "\n",
    "# # === ConversiÃ³n de Anotaciones de LabelMe a YOLO ===\n",
    "# def labelme_to_yolo(input_folder, output_folder):\n",
    "#     \"\"\"\n",
    "#     Convierte archivos JSON de LabelMe al formato YOLO.\n",
    "\n",
    "#     Parameters:\n",
    "#     - input_folder (str): Carpeta con archivos JSON de LabelMe.\n",
    "#     - output_folder (str): Carpeta donde se guardarÃ¡n los archivos YOLO.\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     for filename in os.listdir(input_folder):\n",
    "#         if filename.endswith('.json'):\n",
    "#             try:\n",
    "#                 json_file = os.path.join(input_folder, filename)\n",
    "#                 yolo_file = os.path.join(output_folder, filename.replace('.json', '.txt'))\n",
    "#                 # ConversiÃ³n aquÃ­ (implementaciÃ³n omitida para brevedad)\n",
    "#                 print(f\"[INFO] Convertido: {json_file} -> {yolo_file}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"[ERROR] Error al convertir {filename}: {e}\")\n",
    "\n",
    "# # === Entrenamiento del Modelo YOLOv8n ===\n",
    "# def train_yolo_pipeline(dataset_path, annotations_format=\"YOLO\", epochs=50, img_size=256):\n",
    "#     \"\"\"\n",
    "#     Configura y entrena el modelo YOLO.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset_path (str): Ruta del dataset procesado.\n",
    "#     - annotations_format (str): Formato de las anotaciones (por defecto \"YOLO\").\n",
    "#     - epochs (int): NÃºmero de Ã©pocas de entrenamiento.\n",
    "#     - img_size (int): TamaÃ±o de las imÃ¡genes usadas para entrenamiento.\n",
    "#     \"\"\"\n",
    "#     from ultralytics import YOLO\n",
    "\n",
    "#     dataset_dir = os.path.join(dataset_path, \"processed_images\")\n",
    "#     annotations_dir = os.path.join(dataset_path, \"annotations\")\n",
    "\n",
    "#     if not validate_directories([dataset_dir, annotations_dir]):\n",
    "#         return\n",
    "\n",
    "#     try:\n",
    "#         model = YOLO(\"yolov8n.pt\")\n",
    "#         results = model.train(\n",
    "#             data=annotations_format,\n",
    "#             imgsz=img_size,\n",
    "#             epochs=epochs,\n",
    "#             batch=16,\n",
    "#             project=\"LEGO_Training\",\n",
    "#             name=\"YOLO_Lego_Detection\"\n",
    "#         )\n",
    "#         print(\"[INFO] Entrenamiento finalizado. Resultados:\", results)\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Error durante el entrenamiento: {e}\")\n",
    "\n",
    "# # === EvaluaciÃ³n del Modelo Entrenado ===\n",
    "# def test_model_on_real_images(model_path, test_images_dir, output_dir):\n",
    "#     \"\"\"\n",
    "#     EvalÃºa el modelo YOLO entrenado en imÃ¡genes reales.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_path (str): Ruta del modelo YOLO entrenado.\n",
    "#     - test_images_dir (str): Carpeta con imÃ¡genes para evaluaciÃ³n.\n",
    "#     - output_dir (str): Carpeta para guardar los resultados visualizados.\n",
    "#     \"\"\"\n",
    "#     from ultralytics import YOLO\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     model = YOLO(model_path)\n",
    "\n",
    "#     for img_file in os.listdir(test_images_dir):\n",
    "#         if img_file.endswith(\".jpg\"):\n",
    "#             try:\n",
    "#                 img_path = os.path.join(test_images_dir, img_file)\n",
    "#                 results = model(img_path)\n",
    "#                 result_image = results[0].plot()\n",
    "#                 output_path = os.path.join(output_dir, img_file)\n",
    "#                 Image.fromarray(result_image).save(output_path)\n",
    "#                 print(f\"[INFO] Procesado: {img_file} -> {output_path}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"[ERROR] Error al procesar {img_file}: {e}\")\n",
    "\n",
    "# # === VisualizaciÃ³n de Resultados ===\n",
    "# def visualize_results(dataset_path):\n",
    "#     \"\"\"\n",
    "#     Visualiza detecciones en un grid de imÃ¡genes anotadas.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset_path (str): Ruta del dataset procesado.\n",
    "#     \"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     processed_dir = os.path.join(dataset_path, \"processed_images\")\n",
    "#     images = [os.path.join(processed_dir, img) for img in os.listdir(processed_dir) if img.endswith(\".jpg\")]\n",
    "\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     for i, img_path in enumerate(images[:16]):  # Mostrar 16 imÃ¡genes\n",
    "#         try:\n",
    "#             img = Image.open(img_path)\n",
    "#             plt.subplot(4, 4, i + 1)\n",
    "#             plt.imshow(img)\n",
    "#             plt.axis('off')\n",
    "#         except Exception as e:\n",
    "#             print(f\"[ERROR] No se pudo cargar {img_path}: {e}\")\n",
    "#     plt.show()\n",
    "\n",
    "# # === EjecuciÃ³n del Pipeline ===\n",
    "# def main():\n",
    "#     \"\"\"EjecuciÃ³n principal del pipeline de detecciÃ³n de LEGO.\"\"\"\n",
    "#     setup_environment()\n",
    "#     download_dataset_from_kaggle(\"usuario/dataset\", \"datasets\")\n",
    "#     preprocess_images(\"datasets/raw\", \"datasets/processed\")\n",
    "#     labelme_to_yolo(\"datasets/processed\", \"datasets/annotations\")\n",
    "#     train_yolo_pipeline(\"datasets\")\n",
    "#     test_model_on_real_images(\"YOLO_Lego_Detection/best.pt\", \"test_images\", \"results\")\n",
    "#     visualize_results(\"datasets\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt conversacion del visualization_presentation.py\n",
    "\n",
    "para actualizar el comentariado luego de la publicacion en PyPl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "Tengo el siguiente script en Python que quiero mejorar para alcanzar un nivel profesional. El script incluye varias funciones relacionadas con la visualizaciÃ³n de resultados de modelos y organizaciÃ³n de carpetas. Estos son los aspectos especÃ­ficos que quiero mejorar:\n",
    "\n",
    "1. **Comentarios mÃ¡s claros y precisos**:\n",
    "   - Las docstrings deben ser detalladas, siguiendo el estÃ¡ndar Google o NumPy, e incluir:\n",
    "     - PropÃ³sito de la funciÃ³n.\n",
    "     - ParÃ¡metros (`Args`).\n",
    "     - Valores de retorno (`Returns`), si aplica.\n",
    "   - Los comentarios en lÃ­nea deben ser breves y especÃ­ficos para mejorar la comprensiÃ³n del cÃ³digo.\n",
    "\n",
    "2. **Formato y organizaciÃ³n del cÃ³digo**:\n",
    "   - Aplicar el estÃ¡ndar **PEP 8**, como longitud mÃ¡xima de lÃ­neas (79 caracteres) y espaciado adecuado.\n",
    "   - Asegurar que las importaciones estÃ©n organizadas (estÃ¡ndar, externas, locales).\n",
    "\n",
    "3. **Manejo de errores**:\n",
    "   - Proponer o incluir excepciones donde sea relevante, como manejo de archivos o directorios inexistentes.\n",
    "\n",
    "4. **Mensajes mÃ¡s profesionales**:\n",
    "   - Reemplazar mensajes `print()` por logs informativos utilizando la librerÃ­a estÃ¡ndar `logging`.\n",
    "\n",
    "5. **OptimizaciÃ³n del flujo de funciones**:\n",
    "   - Identificar redundancias o mejoras en la eficiencia de las funciones.\n",
    "\n",
    "6. **Mejoras generales**:\n",
    "   - Proponer o aplicar cualquier ajuste que haga el script mÃ¡s limpio, profesional y eficiente.\n",
    "\n",
    "A continuaciÃ³n, te comparto el script para que lo refines segÃºn estos criterios:\n",
    "\n",
    "\n",
    "Por favor, realiza los ajustes directamente en el cÃ³digo y explica las mejoras realizadas para que pueda aprender del proceso.\n",
    "\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import logging\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from scripts.pipeline import test_model_on_real_images\n",
    "\n",
    "# # ConfiguraciÃ³n del logger\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def create_dataset_grid(input_folder: str, output_folder: str, grid_size=(3, 3)) -> None:\n",
    "#     \"\"\"\n",
    "#     Genera un grid de imÃ¡genes de muestra del dataset y lo guarda en la carpeta especificada.\n",
    "\n",
    "#     Args:\n",
    "#         input_folder (str): Ruta de la carpeta con las imÃ¡genes de entrada.\n",
    "#         output_folder (str): Ruta donde se guardarÃ¡ el grid generado.\n",
    "#         grid_size (tuple): Dimensiones del grid (filas, columnas).\n",
    "\n",
    "#     Raises:\n",
    "#         FileNotFoundError: Si la carpeta de entrada no existe o estÃ¡ vacÃ­a.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(input_folder):\n",
    "#         logging.error(\"La carpeta de entrada no existe.\")\n",
    "#         raise FileNotFoundError(\"Carpeta de entrada no encontrada.\")\n",
    "\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     if not image_files:\n",
    "#         logging.error(\"No se encontraron imÃ¡genes en la carpeta de entrada.\")\n",
    "#         raise FileNotFoundError(\"No se encontraron imÃ¡genes en la carpeta de entrada.\")\n",
    "\n",
    "#     random.shuffle(image_files)\n",
    "#     selected_files = image_files[:grid_size[0] * grid_size[1]]\n",
    "#     fig, axes = plt.subplots(*grid_size, figsize=(grid_size[1] * 4, grid_size[0] * 4))\n",
    "\n",
    "#     for idx, img_file in enumerate(selected_files):\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         img = Image.open(img_path)\n",
    "#         row, col = divmod(idx, grid_size[1])\n",
    "#         axes[row, col].imshow(img)\n",
    "#         axes[row, col].axis('off')\n",
    "#         axes[row, col].set_title(f\"{img_file}\", fontsize=10)\n",
    "\n",
    "#     for ax in axes.flat[len(selected_files):]:\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     grid_path = os.path.join(output_folder, \"dataset_grid.png\")\n",
    "#     plt.savefig(grid_path, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "#     logging.info(f\"Grid de dataset guardado en {grid_path}.\")\n",
    "\n",
    "# def annotate_model_results(model_path: str, input_folder: str, output_folder: str, conf_threshold=0.5) -> None:\n",
    "#     \"\"\"\n",
    "#     Genera imÃ¡genes con anotaciones del modelo y las guarda en la carpeta especificada.\n",
    "\n",
    "#     Args:\n",
    "#         model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#         input_folder (str): Carpeta con imÃ¡genes de entrada.\n",
    "#         output_folder (str): Carpeta para guardar las imÃ¡genes anotadas.\n",
    "#         conf_threshold (float): Umbral de confianza para las detecciones.\n",
    "\n",
    "#     Raises:\n",
    "#         FileNotFoundError: Si la carpeta de entrada no contiene imÃ¡genes.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(input_folder):\n",
    "#         logging.error(\"La carpeta de entrada no existe.\")\n",
    "#         raise FileNotFoundError(\"Carpeta de entrada no encontrada.\")\n",
    "\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     test_model_on_real_images(model_path, input_folder, output_folder)\n",
    "#     logging.info(f\"Resultados anotados guardados en {output_folder}.\")\n",
    "\n",
    "# def generate_comparison_grid(model_path: str, input_folder: str, output_folder: str, num_samples=5) -> None:\n",
    "#     \"\"\"\n",
    "#     Crea un grid comparativo de imÃ¡genes antes y despuÃ©s de las predicciones del modelo.\n",
    "\n",
    "#     Args:\n",
    "#         model_path (str): Ruta al modelo YOLO entrenado.\n",
    "#         input_folder (str): Carpeta con imÃ¡genes de entrada.\n",
    "#         output_folder (str): Carpeta para guardar los grids generados.\n",
    "#         num_samples (int): NÃºmero de imÃ¡genes a comparar.\n",
    "\n",
    "#     Raises:\n",
    "#         FileNotFoundError: Si la carpeta de entrada no contiene imÃ¡genes.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(input_folder):\n",
    "#         logging.error(\"La carpeta de entrada no existe.\")\n",
    "#         raise FileNotFoundError(\"Carpeta de entrada no encontrada.\")\n",
    "\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "#     image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "#     if not image_files:\n",
    "#         logging.error(\"No se encontraron imÃ¡genes en la carpeta de entrada.\")\n",
    "#         raise FileNotFoundError(\"No se encontraron imÃ¡genes en la carpeta de entrada.\")\n",
    "\n",
    "#     random.shuffle(image_files)\n",
    "#     selected_files = image_files[:num_samples]\n",
    "\n",
    "#     for img_file in selected_files:\n",
    "#         img_path = os.path.join(input_folder, img_file)\n",
    "#         result_path = os.path.join(output_folder, img_file)\n",
    "\n",
    "#         test_model_on_real_images(model_path, img_path, output_folder)\n",
    "#         annotated_img = Image.open(result_path)\n",
    "#         original_img = Image.open(img_path)\n",
    "\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#         axes[0].imshow(original_img)\n",
    "#         axes[0].axis('off')\n",
    "#         axes[0].set_title(\"Original\")\n",
    "\n",
    "#         axes[1].imshow(annotated_img)\n",
    "#         axes[1].axis('off')\n",
    "#         axes[1].set_title(\"Anotado\")\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         comparison_path = os.path.join(output_folder, f\"comparison_{img_file}\")\n",
    "#         plt.savefig(comparison_path, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "#         logging.info(f\"Grid de comparaciÃ³n guardado en {comparison_path}.\")\n",
    "\n",
    "# def organize_presentation_folders(base_folder: str) -> None:\n",
    "#     \"\"\"\n",
    "#     Crea y organiza las subcarpetas necesarias para las visualizaciones.\n",
    "\n",
    "#     Args:\n",
    "#         base_folder (str): Carpeta raÃ­z para las subcarpetas.\n",
    "#     \"\"\"\n",
    "#     subfolders = [\"dataset_samples\", \"model_results\", \"before_after\"]\n",
    "#     for subfolder in subfolders:\n",
    "#         os.makedirs(os.path.join(base_folder, subfolder), exist_ok=True)\n",
    "#     logging.info(f\"Subcarpetas creadas en {base_folder}: {', '.join(subfolders)}\")\n",
    "\n",
    "# def main() -> None:\n",
    "#     \"\"\"\n",
    "#     EjecuciÃ³n principal del pipeline de visualizaciÃ³n.\n",
    "#     \"\"\"\n",
    "#     base_folder = \"presentation\"\n",
    "#     organize_presentation_folders(base_folder)\n",
    "\n",
    "#     dataset_folder = \"datasets/processed_images\"\n",
    "#     model_path = \"YOLO_Lego_Detection/best.pt\"\n",
    "\n",
    "#     create_dataset_grid(dataset_folder, os.path.join(base_folder, \"dataset_samples\"))\n",
    "#     annotate_model_results(model_path, dataset_folder, os.path.join(base_folder, \"model_results\"))\n",
    "#     generate_comparison_grid(model_path, dataset_folder, os.path.join(base_folder, \"before_after\"))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt conversacion de refinamiento de README.md\n",
    "\n",
    "para actualizar el comentariado luego de la publicacion en PyPl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"\n",
    "\n",
    "Tengo dos scripts bien comentados y refinados que forman el nÃºcleo de mi proyecto. TambiÃ©n tengo un archivo `README.md` existente, pero necesito actualizarlo para reflejar los cambios y documentar de forma profesional el proyecto. AquÃ­ estÃ¡n las instrucciones:\n",
    "\n",
    "1. **DescripciÃ³n clara del proyecto**:\n",
    "   - Explica quÃ© resuelve el proyecto y por quÃ© es Ãºtil.\n",
    "   - Destaca las funcionalidades principales basadas en los scripts proporcionados.\n",
    "\n",
    "2. **Estructura profesional**:\n",
    "   - IntroducciÃ³n: Breve descripciÃ³n del proyecto.\n",
    "   - InstalaciÃ³n: CÃ³mo instalar las dependencias y preparar el entorno.\n",
    "   - Uso: Instrucciones para ejecutar las funcionalidades principales.\n",
    "   - Detalle de scripts y funciones: Documenta cada funciÃ³n clave basada en las docstrings de los scripts refinados.\n",
    "   - Contribuciones: GuÃ­a para colaborar.\n",
    "\n",
    "3. **Ejemplos prÃ¡cticos**:\n",
    "   - Muestra cÃ³mo usar funciones principales, con ejemplos claros y fÃ¡ciles de entender en bloques de cÃ³digo.\n",
    "\n",
    "4. **Estructura del proyecto**:\n",
    "   - Describe la organizaciÃ³n de carpetas y archivos, indicando dÃ³nde encontrar scripts, datos y resultados.\n",
    "\n",
    "5. **Consistencia y claridad**:\n",
    "   - El README.md debe ser accesible tanto para principiantes como para desarrolladores avanzados.\n",
    "\n",
    "A continuaciÃ³n, tienes los archivos necesarios:\n",
    "1. El estado actual del archivo `README.md`.\n",
    "2. Los dos scripts refinados (`pipeline.py` y `visualize_presentation.py`).\n",
    "\n",
    "Por favor, actualiza el `README.md` para reflejar toda la funcionalidad implementada, utilizando una estructura clara y profesional. AsegÃºrate de incluir ejemplos prÃ¡cticos y explicaciones detalladas basadas en las docstrings de los scripts.\n",
    "\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt para actualizar el technical_report.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \"\n",
    "\n",
    "Quiero integrar el cÃ³digo de mi paquete publicado en PyPI (lego-bricks-ml-vision) en el documento tÃ©cnico LEGO_Bricks_Identification_Project_Technical_Report.pdf. El objetivo principal es actualizar el documento para que:\n",
    "\n",
    "Utilice las funciones del paquete:\n",
    "\n",
    "Sustituir bloques de cÃ³digo existentes por ejemplos claros de cÃ³mo usar el paquete.\n",
    "Mostrar cÃ³mo el pipeline completo puede ser ejecutado con las herramientas del paquete.\n",
    "Simplifique la reproducciÃ³n de la experiencia:\n",
    "\n",
    "Incluir comandos claros para instalar el paquete y ejecutar pipelines directamente desde el CLI (run-pipeline y run-visualize).\n",
    "Agregar ejemplos de configuraciÃ³n inicial y manejo de errores.\n",
    "Actualice la estructura del documento:\n",
    "\n",
    "Reorganizar las secciones de \"CreaciÃ³n del Dataset\", \"Entrenamiento del Modelo\" y \"VisualizaciÃ³n de Resultados\" para reflejar el flujo modular del paquete.\n",
    "Ajustar las secciones de reflexiÃ³n para resaltar la escalabilidad y facilidad de uso del paquete.\n",
    "Incluya referencias al README:\n",
    "\n",
    "Citar el README y documentaciÃ³n del paquete como recursos adicionales para ampliar la informaciÃ³n tÃ©cnica.\n",
    "Tareas especÃ­ficas:\n",
    "Revise la secciÃ³n de introducciÃ³n para incorporar una descripciÃ³n breve del paquete y cÃ³mo facilita el flujo de trabajo.\n",
    "Sustituya el cÃ³digo en Python por ejemplos concretos de uso de las funciones del paquete (preprocess_images, train_yolo_pipeline, etc.).\n",
    "Proporcione instrucciones para ejecutar pipelines y generar visualizaciones utilizando los comandos de CLI (run-pipeline y run-visualize).\n",
    "Verifique la claridad y profesionalismo del lenguaje, garantizando un tono tÃ©cnico accesible.\n",
    "Por favor, comencemos revisando la secciÃ³n de \"CreaciÃ³n del Dataset\" y trabajemos iterativamente para integrar las funciones del paquete.\n",
    "\n",
    "\n",
    "\n",
    "# \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First iteration technical_report.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEGO Bricks Identification Project: A Technical Report\n",
    "\n",
    "### 1. Introduction and Motivation ðŸŒŸ\n",
    "\n",
    "This project leverages the **`lego-bricks-ml-vision`** package to implement an efficient pipeline for detecting and classifying LEGO bricks. Inspired by the challenge of identifying specific pieces within a cluttered set of LEGO bricks, this project combines computer vision, machine learning, and dataset management to achieve scalable and replicable results.\n",
    "\n",
    "The key objectives include:\n",
    "\n",
    "1. Designing a pipeline for object detection using YOLOv8.\n",
    "2. Documenting the process to ensure reproducibility and scalability.\n",
    "3. Providing tools for visualization and analysis to showcase the modelâ€™s performance.\n",
    "\n",
    "### 2. Dataset Creation ðŸ“\n",
    "\n",
    "The dataset creation process is streamlined using the **`lego-bricks-ml-vision`** package. This package provides commands for downloading datasets, preprocessing images, and converting annotations.\n",
    "\n",
    "#### 2.1 Dataset Overview \n",
    "\n",
    "The dataset used for this project is hosted on Kaggle:\n",
    "- **Dataset Name**: [Spiled LEGO Bricks](https://www.kaggle.com/datasets/migueldilalla/spiled-lego-bricks)\n",
    "- **Contents**:\n",
    "  - **Images**: 1803 images (600Ã—800 resolution)\n",
    "  - **Annotations**: LabelMe-compatible `.txt` files with bounding box data.\n",
    "\n",
    "#### 2.2 Setting Up the Environment \n",
    "\n",
    "Install the **`lego-bricks-ml-vision`** package from PyPI:\n",
    "\n",
    "```python\n",
    "!pip install lego-bricks-ml-vision\n",
    "```\n",
    "\n",
    "Configure the pipeline:\n",
    "\n",
    "```python\n",
    "from lego_bricks_ml_vision import setup_environment\n",
    "setup_environment()\n",
    "```\n",
    "\n",
    "This command ensures that all dependencies are installed and that your environment is ready.\n",
    "\n",
    "#### 2.3 Downloading the Dataset \n",
    "\n",
    "The dataset can be directly downloaded and extracted using the following commands:\n",
    "\n",
    "```python\n",
    "!run-pipeline download-dataset \\\n",
    "    --kaggle-dataset \"migueldilalla/spiled-lego-bricks\" \\\n",
    "    --output-dir \"datasets\"\n",
    "```\n",
    "\n",
    "#### 2.4 Preprocessing Images \n",
    "\n",
    "Resize the images to a consistent size (e.g., 256x256) for model training:\n",
    "\n",
    "```python\n",
    "!run-pipeline preprocess-images \\\n",
    "    --input-dir \"datasets/Images_600x800\" \\\n",
    "    --output-dir \"datasets/processed_images\" \\\n",
    "    --target-size 256\n",
    "```\n",
    "\n",
    "#### 2.5 Converting Annotations \n",
    "\n",
    "Convert annotations from LabelMe format to YOLO format:\n",
    "\n",
    "```python\n",
    "!run-pipeline labelme-to-yolo \\\n",
    "    --input-folder \"datasets/LabelMe_txt_bricks\" \\\n",
    "    --output-folder \"datasets/annotations\"\n",
    "```\n",
    "\n",
    "By automating these tasks, the package ensures consistency and reduces manual effort.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Model Training ðŸ§¬\n",
    "\n",
    "The project uses YOLOv8 for LEGO brick detection. Training is performed using the preprocessed dataset and YOLO-compatible annotations.\n",
    "\n",
    "#### 3.1 Training the YOLO Model\n",
    "\n",
    "The `train_yolo_pipeline` function enables straightforward model training:\n",
    "\n",
    "```python\n",
    "!run-pipeline train-yolo \\\n",
    "    --dataset-path \"datasets\" \\\n",
    "    --epochs 50 \\\n",
    "    --img-size 256\n",
    "```\n",
    "\n",
    "#### 3.2 Validating the Model\n",
    "\n",
    "Evaluate the trained model on test images:\n",
    "\n",
    "```python\n",
    "!run-pipeline test-model \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --test-images-dir \"test_images\" \\\n",
    "    --output-dir \"results\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Visualization and Results ðŸŽ¨\n",
    "\n",
    "#### 4.1 Visualizing Results\n",
    "\n",
    "Visualize predictions and annotations using:\n",
    "\n",
    "```python\n",
    "!run-visualize annotate-results \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/model_results\"\n",
    "```\n",
    "\n",
    "#### 4.2 Generating Comparison Grids\n",
    "\n",
    "Compare predictions against ground truth:\n",
    "\n",
    "```python\n",
    "!run-visualize comparison-grid \\\n",
    "    --model-path \"YOLO_Lego_Detection/best.pt\" \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/comparison\"\n",
    "```\n",
    "\n",
    "#### 4.3 Creating Presentation Grids\n",
    "\n",
    "Summarize dataset samples in a grid format:\n",
    "\n",
    "```python\n",
    "!run-visualize create-grid \\\n",
    "    --input-folder \"datasets/processed_images\" \\\n",
    "    --output-folder \"presentation/dataset_samples\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Reflection and Future Work ðŸ”„\n",
    "\n",
    "This project demonstrates the effectiveness of modular pipelines for scalable machine learning workflows. Key insights include:\n",
    "\n",
    "- **Data Quality**: High-quality, annotated datasets significantly enhance model performance.\n",
    "- **Modularity**: Breaking down the pipeline into distinct stages improves reproducibility.\n",
    "- **Visualization**: Effective visual tools aid in debugging and communicating results.\n",
    "\n",
    "#### Future Improvements:\n",
    "1. Expanding the dataset to include more LEGO pieces.\n",
    "2. Integrating semi-automated annotation tools.\n",
    "3. Developing an interactive interface for real-time predictions.\n",
    "\n",
    "---\n",
    "\n",
    "For more details, refer to the [LEGO Bricks ML Vision Documentation](https://github.com/MiguelDiLalla/LEGO_Bricks_ML_Vision).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook saved to: C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\Technical_Report.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nbformat as nbf\n",
    "\n",
    "# Paths for input and output\n",
    "input_md_path = r\"C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\Technical_Report.md\"\n",
    "output_nb_path = r\"C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\Technical_Report.ipynb\"\n",
    "\n",
    "# Read the markdown file\n",
    "with open(input_md_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize a new notebook\n",
    "notebook = nbf.v4.new_notebook()\n",
    "\n",
    "# Process the markdown file line by line\n",
    "current_cell_type = \"markdown\"\n",
    "current_cell_content = []\n",
    "\n",
    "for line in lines:\n",
    "    # Detect code block start or end\n",
    "    if line.strip().startswith(\"```\"):  # Toggle between markdown and code\n",
    "        if current_cell_type == \"code\":\n",
    "            # End of a code cell\n",
    "            notebook.cells.append(nbf.v4.new_code_cell(\"\".join(current_cell_content)))\n",
    "            current_cell_content = []\n",
    "            current_cell_type = \"markdown\"\n",
    "        else:\n",
    "            # End of a markdown cell\n",
    "            if current_cell_content:\n",
    "                notebook.cells.append(nbf.v4.new_markdown_cell(\"\".join(current_cell_content)))\n",
    "            current_cell_content = []\n",
    "            current_cell_type = \"code\"\n",
    "    else:\n",
    "        # Append content to the current cell\n",
    "        current_cell_content.append(line)\n",
    "\n",
    "# Add any remaining content as a final cell\n",
    "if current_cell_content:\n",
    "    if current_cell_type == \"markdown\":\n",
    "        notebook.cells.append(nbf.v4.new_markdown_cell(\"\".join(current_cell_content)))\n",
    "    elif current_cell_type == \"code\":\n",
    "        notebook.cells.append(nbf.v4.new_code_cell(\"\".join(current_cell_content)))\n",
    "\n",
    "# Save the notebook\n",
    "nbf.write(notebook, output_nb_path)\n",
    "print(f\"Notebook saved to: {output_nb_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnvHaB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
