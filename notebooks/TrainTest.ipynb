{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"nvidia-smi\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "if os.environ.get('COLAB_GPU') is not None:\n",
    "    !pip install ultralytics\n",
    "    !pip install optuna\n",
    "\n",
    "elif os.path.exists(\"/kaggle\"):  # Kaggle\n",
    "    !pip install ultralytics\n",
    "    !pip install optuna\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline_satup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Detected Environment': 'local'}\n",
      "\n",
      "[INFO] Entorno detectado: Local\n",
      "\n",
      "{'Rutas Configuradas': {'output_path': 'c:\\\\Users\\\\User\\\\Projects_Unprotected\\\\LEGO_Bricks_ML_Vision\\\\notebooks\\\\working\\\\output',\n",
      "                        'raw_images_path': 'working/spiled-lego-bricks\\\\Images_600x800',\n",
      "                        'raw_labels_path': 'working/spiled-lego-bricks\\\\LabelMe_txt_bricks'}}\n",
      "{'Dataset Estructura': {'working/spiled-lego-bricks\\\\Images_600x800': 1803,\n",
      "                        'working/spiled-lego-bricks\\\\LabelMe_txt_bricks': 1803}}\n",
      "[INFO] Estructura de carpetas creada en c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output.\n",
      "{'Partición Completada': {'test': 179, 'train': 1262, 'val': 362}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\albumentations\\core\\validation.py:45: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Augmented data saved to c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output\\augmented_dataset.\n",
      "[INFO] Augmented data merged into train set at c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output.\n",
      "[INFO] dataset.yaml created at: c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output\\dataset\\dataset.yaml\n",
      "{'Validación Final': {'test': 179, 'train': 5048, 'val': 362}}\n",
      "\n",
      "[INFO] Pipeline setup completed with augmentations and dataset.yaml creation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from pprint import pprint\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# === Configuración Inicial ===\n",
    "def detect_environment():\n",
    "    \"\"\"\n",
    "    Detecta el entorno de ejecución (Kaggle, Google Colab o Local).\n",
    "\n",
    "    Returns:\n",
    "    - str: Nombre del entorno detectado.\n",
    "    \"\"\"\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        environment = \"colab\"\n",
    "    elif os.path.exists(\"/kaggle\"):\n",
    "        environment = \"kaggle\"\n",
    "    else:\n",
    "        environment = \"local\"\n",
    "    pprint({\"Detected Environment\": environment})\n",
    "    return environment\n",
    "\n",
    "\n",
    "def setup_environment(base_path=\"/kaggle/working/output\"):\n",
    "    \"\"\"\n",
    "    Configura el entorno según el sistema detectado y prepara el dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - base_path (str): Carpeta base donde se configurará la salida.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Rutas configuradas para las imágenes y etiquetas crudas.\n",
    "    \"\"\"\n",
    "    environment = detect_environment()\n",
    "    print(f\"\\n[INFO] Entorno detectado: {environment.capitalize()}\\n\")\n",
    "\n",
    "    if environment == \"kaggle\":\n",
    "        dataset_path = \"/kaggle/input/spiled-lego-bricks\"\n",
    "        required_folders = [\"Images_600x800\", \"LabelMe_txt_bricks\"]\n",
    "        for folder in required_folders:\n",
    "            full_path = os.path.join(dataset_path, folder)\n",
    "            if not os.path.exists(full_path):\n",
    "                raise FileNotFoundError(f\"[ERROR] Carpeta requerida no encontrada: {full_path}\")\n",
    "            print(f\"[INFO] Carpeta verificada: {full_path}\")\n",
    "\n",
    "        return {\n",
    "            \"raw_images_path\": os.path.join(dataset_path, \"Images_600x800\"),\n",
    "            \"raw_labels_path\": os.path.join(dataset_path, \"LabelMe_txt_bricks\"),\n",
    "            \"output_path\": base_path\n",
    "        }\n",
    "    elif environment == \"colab\":\n",
    "            from google.colab import userdata\n",
    "            kaggle_path = \"kaggle.json\"\n",
    "            if not os.path.exists(kaggle_path):\n",
    "                # raise EnvironmentError(\"[ERROR] Sube tu archivo kaggle.json al entorno Colab en /root/.kaggle/\")\n",
    "                os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "            \n",
    "            \n",
    "                kaggle_user = userdata.get('KaggleUser')\n",
    "                kaggle_token = userdata.get('KaggleToken')\n",
    "                if not kaggle_user or not kaggle_token:\n",
    "                    raise EnvironmentError(\"[ERROR] No se encontraron las credenciales de Kaggle en Google Colab.\")\n",
    "                kaggle_data = {\n",
    "                    \"username\": kaggle_user,\n",
    "                    \"key\": kaggle_token\n",
    "                }\n",
    "                with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "                    json.dump(kaggle_data, f)\n",
    "                    print(\"[INFO] Credenciales de Kaggle configuradas en Google Colab.\")\n",
    "            else:\n",
    "                os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "                shutil.move(kaggle_path, \"/root/.kaggle/kaggle.json\")\n",
    "                print(\"[INFO] Archivo kaggle.json movido a /root/.kaggle/\")\n",
    "            os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
    "            os.makedirs(\"working\", exist_ok=True)\n",
    "            os.makedirs(\"working/spiled-lego-bricks\", exist_ok=True)\n",
    "            os.system(\"kaggle datasets download -d migueldilalla/spiled-lego-bricks -p working/spiled-lego-bricks --unzip\")\n",
    "            os.makedirs(\"/working/output\", exist_ok=True)\n",
    "            dataset_path = \"working/spiled-lego-bricks\"\n",
    "\n",
    "            return {\n",
    "                \"raw_images_path\": os.path.join(dataset_path, \"Images_600x800\"),\n",
    "                \"raw_labels_path\": os.path.join(dataset_path, \"LabelMe_txt_bricks\"),\n",
    "                \"output_path\": os.path.join(os.getcwd(), \"working\", \"output\")\n",
    "            }\n",
    "\n",
    "\n",
    "    elif environment == \"local\":\n",
    "        kaggle_json_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "        if not os.path.exists(kaggle_json_path):\n",
    "            raise EnvironmentError(\"[ERROR] Archivo kaggle.json no encontrado en ~/.kaggle/\")\n",
    "        os.makedirs(\"working\", exist_ok=True)\n",
    "        os.makedirs(\"working/spiled-lego-bricks\", exist_ok=True)\n",
    "        if not os.listdir(\"working/spiled-lego-bricks\"):\n",
    "            os.system(\"kaggle datasets download -d migueldilalla/spiled-lego-bricks -p working/spiled-lego-bricks --unzip\")\n",
    "        os.makedirs(\"working/output\", exist_ok=True)\n",
    "        dataset_path = \"working/spiled-lego-bricks\"\n",
    "\n",
    "        return {\n",
    "             \"raw_images_path\": os.path.join(dataset_path, \"Images_600x800\"),\n",
    "            \"raw_labels_path\": os.path.join(dataset_path, \"LabelMe_txt_bricks\"),\n",
    "            \"output_path\": os.path.join(os.getcwd(), \"working\", \"output\")\n",
    "        }\n",
    "    else:\n",
    "        while True:\n",
    "            user_input = input(\"[PROMPT] No se detectó un entorno. Por favor, escribe 'k' para Kaggle, 'g' para Google Colab, o 'l' para Local: \").strip().lower()\n",
    "            if user_input in [\"k\", \"g\", \"l\"]:\n",
    "                return setup_environment_custom(user_input, base_path)\n",
    "            print(\"[ERROR] Entrada inválida. Intenta nuevamente.\")\n",
    "\n",
    "def setup_environment_custom(choice, base_path):\n",
    "    \"\"\"\n",
    "    Configura el entorno manualmente basado en la elección del usuario.\n",
    "\n",
    "    Parameters:\n",
    "    - choice (str): 'k' para Kaggle, 'g' para Colab, 'l' para Local.\n",
    "    - base_path (str): Ruta base para la salida.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Rutas configuradas para las imágenes y etiquetas crudas.\n",
    "    \"\"\"\n",
    "    if choice == \"k\":\n",
    "        return setup_environment()\n",
    "    elif choice == \"g\":\n",
    "        return setup_environment(base_path=\"working\")\n",
    "    elif choice == \"l\":\n",
    "        return setup_environment(base_path=\"working\")\n",
    "    else:\n",
    "        raise EnvironmentError(\"[ERROR] Configuración desconocida.\")\n",
    "\n",
    "def verify_dataset_structure(raw_images_path, raw_labels_path):\n",
    "    \"\"\"\n",
    "    Verifica la existencia de las carpetas requeridas en el dataset y muestra estadísticas iniciales.\n",
    "\n",
    "    Parameters:\n",
    "    - raw_images_path (str): Ruta a las imágenes crudas.\n",
    "    - raw_labels_path (str): Ruta a las etiquetas crudas.\n",
    "    \"\"\"\n",
    "    required_folders = [raw_images_path, raw_labels_path]\n",
    "    summary = {}\n",
    "    for folder in required_folders:\n",
    "        if not os.path.exists(folder):\n",
    "            raise FileNotFoundError(f\"[ERROR] Carpeta requerida no encontrada: {folder}\")\n",
    "\n",
    "        num_files = len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))])\n",
    "        if num_files == 0:\n",
    "            raise ValueError(f\"[ERROR] La carpeta {folder} está vacía.\")\n",
    "        summary[folder] = num_files\n",
    "\n",
    "    pprint({\"Dataset Estructura\": summary})\n",
    "\n",
    "def create_preprocessing_structure(output_dir=\"/kaggle/working/output\"):\n",
    "    \"\"\"\n",
    "    Crea la estructura de carpetas para PREPROCESSING/.\n",
    "\n",
    "    Parameters:\n",
    "    - output_dir (str): Ruta base para la carpeta PREPROCESSING/.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    subfolders = [\n",
    "        \"dataset/images/train\", \"dataset/images/val\", \"dataset/images/test\",\n",
    "        \"dataset/labels/train\", \"dataset/labels/val\", \"dataset/labels/test\",\n",
    "        \"test_images\"\n",
    "    ]\n",
    "    for subfolder in subfolders:\n",
    "        os.makedirs(os.path.join(output_dir, subfolder), exist_ok=True)\n",
    "    print(f\"[INFO] Estructura de carpetas creada en {output_dir}.\")\n",
    "\n",
    "def copy_and_partition_data(input_images, input_labels, output_dir):\n",
    "    \"\"\"\n",
    "    Copia imágenes y etiquetas a las carpetas correspondientes y realiza la partición de datos.\n",
    "\n",
    "    Parameters:\n",
    "    - input_images (str): Carpeta de imágenes de entrada.\n",
    "    - input_labels (str): Carpeta de etiquetas de entrada.\n",
    "    - output_dir (str): Carpeta base para PREPROCESSING/.\n",
    "    \"\"\"\n",
    "    images = sorted([f for f in os.listdir(input_images) if f.endswith(\".jpg\")])\n",
    "    labels = sorted([f for f in os.listdir(input_labels) if f.endswith(\".txt\")])\n",
    "\n",
    "    if len(images) != len(labels):\n",
    "        raise ValueError(\"[ERROR] Número de imágenes y etiquetas no coincide.\")\n",
    "\n",
    "    image_paths = [os.path.join(input_images, img) for img in images]\n",
    "    label_paths = [os.path.join(input_labels, lbl) for lbl in labels]\n",
    "\n",
    "    train_imgs, temp_imgs, train_lbls, temp_lbls = train_test_split(image_paths, label_paths, test_size=0.3, random_state=42)\n",
    "    val_imgs, test_imgs, val_lbls, test_lbls = train_test_split(temp_imgs, temp_lbls, test_size=0.33, random_state=42)\n",
    "\n",
    "    partitions = {\n",
    "        \"train\": (train_imgs, train_lbls),\n",
    "        \"val\": (val_imgs, val_lbls),\n",
    "        \"test\": (test_imgs, test_lbls)\n",
    "    }\n",
    "\n",
    "    for partition, (imgs, lbls) in partitions.items():\n",
    "        for img, lbl in zip(imgs, lbls):\n",
    "            shutil.copy(img, os.path.join(output_dir, f\"dataset/images/{partition}/\"))\n",
    "            shutil.copy(lbl, os.path.join(output_dir, f\"dataset/labels/{partition}/\"))\n",
    "\n",
    "    pprint({\"Partición Completada\": {partition: len(imgs) for partition, (imgs, _) in partitions.items()}})\n",
    "\n",
    "def augment_data(input_images, input_labels, output_dir, num_augmentations=2):\n",
    "    \"\"\"\n",
    "    Aplica aumentaciones al dataset y guarda imágenes y etiquetas aumentadas.\n",
    "\n",
    "    Parameters:\n",
    "    - input_images (str): Carpeta de imágenes originales.\n",
    "    - input_labels (str): Carpeta de etiquetas en formato YOLO.\n",
    "    - output_dir (str): Carpeta donde se guardarán los datos aumentados.\n",
    "    - num_augmentations (int): Número de versiones aumentadas por imagen.\n",
    "    \"\"\"\n",
    "    aug_images_dir = os.path.join(output_dir, \"augmented_images\")\n",
    "    aug_labels_dir = os.path.join(output_dir, \"augmented_labels\")\n",
    "    os.makedirs(aug_images_dir, exist_ok=True)\n",
    "    os.makedirs(aug_labels_dir, exist_ok=True)\n",
    "\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.Resize(height=640, width=640),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "    images = sorted([f for f in os.listdir(input_images) if f.endswith(\".jpg\")])\n",
    "    for img_file in images:\n",
    "        img_path = os.path.join(input_images, img_file)\n",
    "        label_path = os.path.join(input_labels, img_file.replace(\".jpg\", \".txt\"))\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        bboxes, class_labels = load_labels(label_path)\n",
    "\n",
    "        for i in range(num_augmentations):\n",
    "            augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "            aug_image = augmented[\"image\"]\n",
    "            aug_bboxes = augmented[\"bboxes\"]\n",
    "            aug_labels = augmented[\"class_labels\"]\n",
    "\n",
    "            aug_image_path = os.path.join(aug_images_dir, f\"{img_file.split('.')[0]}_aug{i}.jpg\")\n",
    "            cv2.imwrite(aug_image_path, aug_image)\n",
    "\n",
    "            aug_label_path = os.path.join(aug_labels_dir, f\"{img_file.split('.')[0]}_aug{i}.txt\")\n",
    "            save_labels(aug_label_path, aug_bboxes, aug_labels)\n",
    "\n",
    "    print(f\"[INFO] Augmented data saved to {output_dir}.\")\n",
    "\n",
    "def load_labels(label_path):\n",
    "    \"\"\"\n",
    "    Carga etiquetas en formato YOLO desde un archivo .txt.\n",
    "\n",
    "    Parameters:\n",
    "    - label_path (str): Ruta al archivo de etiquetas en formato YOLO.\n",
    "\n",
    "    Returns:\n",
    "    - bboxes (list): Lista de bounding boxes en formato YOLO.\n",
    "    - class_labels (list): Lista de etiquetas de clase.\n",
    "    \"\"\"\n",
    "    bboxes, class_labels = [], []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "        bboxes.append([x_center, y_center, width, height])\n",
    "        class_labels.append(int(class_id))\n",
    "    return bboxes, class_labels\n",
    "\n",
    "def save_labels(output_path, bboxes, class_labels):\n",
    "    \"\"\"\n",
    "    Guarda etiquetas en formato YOLO en un archivo .txt.\n",
    "\n",
    "    Parameters:\n",
    "    - output_path (str): Ruta donde se guardará el archivo de etiquetas.\n",
    "    - bboxes (list): Lista de bounding boxes en formato YOLO.\n",
    "    - class_labels (list): Lista de etiquetas de clase.\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for bbox, label in zip(bboxes, class_labels):\n",
    "            f.write(f\"{label} {' '.join(map(str, bbox))}\\n\")\n",
    "\n",
    "\n",
    "def copy_augmented_to_train(augmented_dir, output_path):\n",
    "    \"\"\"\n",
    "    Copia los datos aumentados a las subcarpetas correspondientes de 'train'.\n",
    "\n",
    "    Parameters:\n",
    "    - augmented_dir (str): Directorio que contiene imágenes y etiquetas aumentadas.\n",
    "    - output_path(str): Ruta base para la salida.\n",
    "    \"\"\"\n",
    "    aug_images_dir = os.path.join(augmented_dir, \"augmented_images\")\n",
    "    aug_labels_dir = os.path.join(augmented_dir, \"augmented_labels\")\n",
    "    train_images_dir = os.path.join(output_path, \"dataset/images/train\")\n",
    "    train_labels_dir = os.path.join(output_path, \"dataset/labels/train\")\n",
    "\n",
    "    for img_file in os.listdir(aug_images_dir):\n",
    "        shutil.copy(os.path.join(aug_images_dir, img_file), train_images_dir)\n",
    "\n",
    "    for label_file in os.listdir(aug_labels_dir):\n",
    "        shutil.copy(os.path.join(aug_labels_dir, label_file), train_labels_dir)\n",
    "\n",
    "    print(f\"[INFO] Augmented data merged into train set at {output_path}.\")\n",
    "\n",
    "def create_dataset_yaml(output_path, num_classes, class_names):\n",
    "    \"\"\"\n",
    "    Creates a dataset.yaml file with absolute paths for YOLO training.\n",
    "\n",
    "    Parameters:\n",
    "    - output_path (str): Base directory where the dataset.yaml file will be saved.\n",
    "    - num_classes (int): Total number of classes.\n",
    "    - class_names (list): List of class names.\n",
    "    \"\"\"\n",
    "    # Resolve absolute paths for train and val folders\n",
    "    dataset_dir = os.path.abspath(output_path)\n",
    "    train_path = os.path.join(dataset_dir, \"images/train\")\n",
    "    val_path = os.path.join(dataset_dir, \"images/val\")\n",
    "\n",
    "    # Create the dataset configuration dictionary\n",
    "    dataset_config = {\n",
    "        \"path\": dataset_dir,\n",
    "        \"train\": train_path,\n",
    "        \"val\": val_path,\n",
    "        \"nc\": num_classes,\n",
    "        \"names\": {i: name for i, name in enumerate(class_names)}\n",
    "    }\n",
    "\n",
    "    # Save the configuration to the dataset.yaml file\n",
    "    yaml_path = os.path.join(dataset_dir, \"dataset.yaml\")\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"[INFO] dataset.yaml created at: {yaml_path}\")\n",
    "\n",
    "def validate_final_structure(output_dir=\"/kaggle/working/output\"):\n",
    "    \"\"\"\n",
    "    Valida que las carpetas de imágenes y etiquetas contengan archivos coincidentes.\n",
    "\n",
    "    Parameters:\n",
    "    - output_dir (str): Carpeta base para PREPROCESSING/.\n",
    "    \"\"\"\n",
    "    partitions = [\"train\", \"val\", \"test\"]\n",
    "    summary = {}\n",
    "\n",
    "    # flag = True\n",
    "\n",
    "    for partition in partitions:\n",
    "        images = sorted(os.listdir(os.path.join(output_dir, f\"dataset/images/{partition}/\")))\n",
    "        labels = sorted(os.listdir(os.path.join(output_dir, f\"dataset/labels/{partition}/\")))\n",
    "\n",
    "        \n",
    "        # if flag:\n",
    "        #     print(output_dir, f\"dataset/images/{partition}/\")\n",
    "        #     flag = False\n",
    "        #     #open the folder in file explorer\n",
    "        #     os.system(f\"explorer {os.path.join(output_dir, f'dataset/images/{partition}/').replace('/', '\\\\')}\")\n",
    "        \n",
    "        if len(images) != len(labels):\n",
    "            raise ValueError(f\"[ERROR] Desbalance entre imágenes y etiquetas en {partition}.\")\n",
    "        summary[partition] = len(images)\n",
    "    \n",
    "    pprint({\"Validación Final\": summary})\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecución principal del pipeline.\n",
    "    \"\"\"\n",
    "    paths = setup_environment()\n",
    "    pprint({\"Rutas Configuradas\": paths})\n",
    "\n",
    "    verify_dataset_structure(paths[\"raw_images_path\"], paths[\"raw_labels_path\"])\n",
    "\n",
    "    create_preprocessing_structure(paths[\"output_path\"])\n",
    "\n",
    "    copy_and_partition_data(paths[\"raw_images_path\"], paths[\"raw_labels_path\"], paths[\"output_path\"])\n",
    "\n",
    "    augment_data(\n",
    "        input_images=os.path.join(paths[\"output_path\"], \"dataset/images/train\"),\n",
    "        input_labels=os.path.join(paths[\"output_path\"], \"dataset/labels/train\"),\n",
    "        output_dir=os.path.join(paths[\"output_path\"], \"augmented_dataset\"),\n",
    "        num_augmentations=3\n",
    "    )\n",
    "\n",
    "    copy_augmented_to_train(\n",
    "        augmented_dir=os.path.join(paths[\"output_path\"], \"augmented_dataset\"),\n",
    "        output_path=paths[\"output_path\"]\n",
    "    )\n",
    "\n",
    "    create_dataset_yaml(\n",
    "        output_path=os.path.join(paths[\"output_path\"], \"dataset\"),\n",
    "        num_classes=1,  # Replace with the actual number of classes\n",
    "        class_names=[\"brick\"]  # Add all class names here\n",
    "    )\n",
    "\n",
    "    validate_final_structure(paths[\"output_path\"])\n",
    "    print(\"\\n[INFO] Pipeline setup completed with augmentations and dataset.yaml creation.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 14:36:24,792 - INFO - [INFO] Usando dataset.yaml en: c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output\\dataset\\dataset.yaml\n",
      "2025-01-22 14:36:24,867 - INFO - [INFO] Iniciando entrenamiento regular...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n",
      "c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output\\dataset\\dataset.yaml\n",
      "New https://pypi.org/project/ultralytics/8.3.65 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.99  Python-3.12.7 torch-2.4.1+cpu CPU (Intel Core(TM) i5-8265U 1.60GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=c:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output\\dataset\\dataset.yaml, epochs=4, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=regular_yolo_training/20250122_143624, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=regular_yolo_training\\20250122_143624\\train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output\\dataset\\labels\\train.cache... 5048 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5048/5048 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\ultralytics\\data\\augment.py:1837: UserWarning: Argument 'quality_lower' is not valid and will be ignored.\n",
      "  A.ImageCompression(quality_lower=75, p=0.0),\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Projects_Unprotected\\LEGO_Bricks_ML_Vision\\notebooks\\working\\output\\dataset\\labels\\val.cache... 362 images, 0 backgrounds, 0 corrupt: 100%|██████████| 362/362 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to regular_yolo_training\\20250122_143624\\train\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.9' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mregular_yolo_training\\20250122_143624\\train\u001b[0m\n",
      "Starting training for 4 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "        1/4         0G      1.699      3.335      1.265         97        640:   1%|          | 2/316 [00:26<1:10:33, 13.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 195\u001b[0m\n\u001b[0;32m    192\u001b[0m         train_model(dataset_yaml, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)  \u001b[38;5;66;03m# Tamaño de imagen predeterminado\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 195\u001b[0m     main(optuna_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 192\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(optuna_mode)\u001b[0m\n\u001b[0;32m    190\u001b[0m     run_optuna_study(dataset_yaml, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     train_model(dataset_yaml, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 122\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(dataset_yaml, pretrained_model, epochs, batch_size, learning_rate, momentum, imgsz)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Iniciando entrenamiento regular...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 122\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    123\u001b[0m         data\u001b[38;5;241m=\u001b[39mdataset_yaml,\n\u001b[0;32m    124\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    125\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    126\u001b[0m         imgsz\u001b[38;5;241m=\u001b[39mimgsz,\n\u001b[0;32m    127\u001b[0m         lr0\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    128\u001b[0m         momentum\u001b[38;5;241m=\u001b[39mmomentum,\n\u001b[0;32m    129\u001b[0m         project\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[0;32m    130\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m         device\u001b[38;5;241m=\u001b[39mget_device()\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Entrenamiento completado. Resultados guardados en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\ultralytics\\engine\\model.py:803\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:393\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    389\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    523\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[0;32m    290\u001b[0m     tensors,\n\u001b[0;32m    291\u001b[0m     grad_tensors_,\n\u001b[0;32m    292\u001b[0m     retain_graph,\n\u001b[0;32m    293\u001b[0m     create_graph,\n\u001b[0;32m    294\u001b[0m     inputs,\n\u001b[0;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    297\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\MiguelEnvHaB\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCAS = 4\n",
    "\n",
    "# === Configuración del Logger ===\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# === Detección del dispositivo ===\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Detecta el dispositivo adecuado para la ejecución.\n",
    "\n",
    "    Returns:\n",
    "    - str: Dispositivo a usar (\"cpu\", \"0\", \"0,1\").\n",
    "    \"\"\"\n",
    "    if os.environ.get('COLAB_GPU') is not None:\n",
    "        return \"0\"  # Colab\n",
    "    elif os.path.exists(\"/kaggle\"):  # Kaggle\n",
    "        return \"0,1\"\n",
    "    else:\n",
    "        return \"cpu\"  # Local\n",
    "\n",
    "# === Callback personalizado para barra de progreso ===\n",
    "class ProgressBarCallback:\n",
    "    def __init__(self, total_epochs):\n",
    "        self.total_epochs = total_epochs\n",
    "        self.pbar = None\n",
    "\n",
    "    def on_train_start(self, trainer, **kwargs):\n",
    "        # Inicializar barra de progreso\n",
    "        self.pbar = tqdm(total=self.total_epochs, desc=\"Progreso del entrenamiento\", unit=\"época\")\n",
    "\n",
    "    def on_epoch_end(self, trainer, **kwargs):\n",
    "        # Actualizar barra de progreso al final de cada época\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_postfix({\"Última época\": kwargs.get('epoch') + 1})\n",
    "\n",
    "    def on_train_end(self, trainer, **kwargs):\n",
    "        # Cerrar barra de progreso\n",
    "        self.pbar.close()\n",
    "\n",
    "# === Configuración de la Función Objetivo de Optuna ===\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Función objetivo para Optuna que entrena el modelo YOLO utilizando hiperparámetros sugeridos.\n",
    "\n",
    "    Returns:\n",
    "    - mAP50 (float): Precisión media a IoU 0.5, métrica a optimizar.\n",
    "    \"\"\"\n",
    "    # Definir espacio de búsqueda para hiperparámetros\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 8, 32, step=8)\n",
    "    momentum = trial.suggest_uniform(\"momentum\", 0.8, 0.99)\n",
    "    imgsz = trial.suggest_categorical(\"imgsz\", [320, 480, 640, 800])  # Tamaños de imagen\n",
    "\n",
    "    # Inicializar modelo YOLO\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    # Configurar entrenamiento\n",
    "    project_name = \"optuna_yolo_training\"\n",
    "    dataset_yaml = os.path.join(os.getcwd(), \"working\", \"output\", \"dataset\", \"dataset.yaml\")\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=dataset_yaml,\n",
    "            epochs=EPOCAS,  # Épocas fijas para experimentos\n",
    "            batch=batch_size,\n",
    "            imgsz=imgsz,\n",
    "            lr0=learning_rate,\n",
    "            momentum=momentum,\n",
    "            project=project_name,\n",
    "            name=f\"trial_{trial.number}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            device=get_device()\n",
    "        )\n",
    "\n",
    "        # Evaluar el modelo\n",
    "        metrics = model.val()\n",
    "        return metrics[\"mAP50\"]  # Devolver mAP50 como métrica objetivo\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] Error durante el entrenamiento en el trial {trial.number}: {e}\")\n",
    "        return float(\"nan\")\n",
    "\n",
    "# === Entrenamiento Regular (Sin Optuna) ===\n",
    "def train_model(dataset_yaml=None, pretrained_model=\"yolov8n.pt\", epochs=EPOCAS, batch_size=16, learning_rate=0.001, momentum=0.9, imgsz=640):\n",
    "    \"\"\"\n",
    "    Entrena el modelo YOLO con hiperparámetros definidos manualmente.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_yaml (str): Ruta al archivo dataset.yaml.\n",
    "    - pretrained_model (str): Modelo YOLO preentrenado.\n",
    "    - epochs (int): Número de épocas para el entrenamiento.\n",
    "    - batch_size (int): Tamaño del batch.\n",
    "    - learning_rate (float): Tasa de aprendizaje inicial.\n",
    "    - momentum (float): Momento para el optimizador.\n",
    "    - imgsz (int): Tamaño de las imágenes de entrada.\n",
    "    \"\"\"\n",
    "    dataset_yaml = dataset_yaml or os.path.join(os.getcwd(), \"working\", \"output\", \"dataset\", \"dataset.yaml\")\n",
    "\n",
    "    if not os.path.exists(dataset_yaml):\n",
    "        logging.error(f\"[ERROR] dataset.yaml no encontrado en {dataset_yaml}. Asegúrate de que el pipeline_setup.py lo haya generado.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"[INFO] Usando dataset.yaml en: {dataset_yaml}\")\n",
    "\n",
    "    model = YOLO(pretrained_model)\n",
    "\n",
    "    output_dir = f\"regular_yolo_training/{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Registrar el callback de barra de progreso\n",
    "    progress_bar = ProgressBarCallback(total_epochs=epochs)\n",
    "    model.add_callback(\"on_train_start\", progress_bar.on_train_start)\n",
    "    model.add_callback(\"on_epoch_end\", progress_bar.on_epoch_end)\n",
    "    model.add_callback(\"on_train_end\", progress_bar.on_train_end)\n",
    "\n",
    "    try:\n",
    "        logging.info(\"[INFO] Iniciando entrenamiento regular...\")\n",
    "        model.train(\n",
    "            data=dataset_yaml,\n",
    "            epochs=epochs,\n",
    "            batch=batch_size,\n",
    "            imgsz=imgsz,\n",
    "            lr0=learning_rate,\n",
    "            momentum=momentum,\n",
    "            project=output_dir,\n",
    "            name=\"train\",\n",
    "            device=get_device()\n",
    "        )\n",
    "        logging.info(f\"[INFO] Entrenamiento completado. Resultados guardados en {output_dir}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[ERROR] Error durante el entrenamiento: {e}\")\n",
    "\n",
    "# === Integración de Optuna en el Pipeline ===\n",
    "def run_optuna_study(dataset_yaml=None, n_trials=20):\n",
    "    \"\"\"\n",
    "    Ejecuta un estudio de Optuna para optimizar los hiperparámetros de YOLO.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_yaml (str): Ruta al archivo dataset.yaml.\n",
    "    - n_trials (int): Número de pruebas a ejecutar.\n",
    "    \"\"\"\n",
    "    dataset_yaml = dataset_yaml or os.path.join(os.getcwd(), \"working\", \"output\", \"dataset\", \"dataset.yaml\")\n",
    "\n",
    "    if not os.path.exists(dataset_yaml):\n",
    "        logging.error(f\"[ERROR] dataset.yaml no encontrado en {dataset_yaml}. Asegúrate de que el pipeline_setup.py lo haya generado.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"[INFO] Usando dataset.yaml en: {dataset_yaml}\")\n",
    "\n",
    "    logging.info(\"[INFO] Iniciando optimización con Optuna...\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    # Mostrar resultados\n",
    "    logging.info(f\"[INFO] Mejor conjunto de hiperparámetros: {study.best_params}\")\n",
    "    logging.info(f\"[INFO] Mejor mAP50 obtenido: {study.best_value}\")\n",
    "\n",
    "    # Guardar resultados\n",
    "    study.trials_dataframe().to_csv(\"optuna_results.csv\")\n",
    "    optuna.visualization.plot_optimization_history(study).write_html(\"optuna_optimization_history.html\")\n",
    "\n",
    "\n",
    "# === Función Principal ===\n",
    "def main(optuna_mode=False):\n",
    "    \"\"\"\n",
    "    Ejecuta el entrenamiento con o sin Optuna.\n",
    "\n",
    "    Parameters:\n",
    "    - optuna_mode (bool): Si es True, utiliza Optuna para optimizar hiperparámetros.\n",
    "    \"\"\"\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        print('google colab')\n",
    "        dataset_yaml = os.path.join(os.getcwd(), \"working\", \"output\", \"dataset\", \"dataset.yaml\")\n",
    "        print(dataset_yaml)\n",
    "    elif os.path.exists(\"/kaggle\"):\n",
    "        print('kaggle')\n",
    "        dataset_yaml = os.path.join(os.getcwd(), \"output\", \"dataset\", \"dataset.yaml\")\n",
    "        print(dataset_yaml)\n",
    "    else:\n",
    "        print('local')\n",
    "        dataset_yaml = os.path.join(os.getcwd(), \"working\", \"output\", \"dataset\", \"dataset.yaml\")\n",
    "        print(dataset_yaml)\n",
    "\n",
    "\n",
    "    if optuna_mode:\n",
    "        run_optuna_study(dataset_yaml, n_trials=20)\n",
    "    else:\n",
    "        train_model(dataset_yaml, imgsz=640)  # Tamaño de imagen predeterminado\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(optuna_mode=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiguelEnvHaB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
