{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Bricks Identification Project: A Journey of Learning and Adaptation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Motivation \n",
    "\n",
    "Este proyecto surge como una oportunidad para aplicar y demostrar mis habilidades t茅cnicas en el contexto de un cambio profesional hacia la ciencia de datos e inteligencia artificial. Durante esta transici贸n, decid铆 combinar mi pasi贸n por los LEGO con mi inter茅s por la visi贸n por computadora, dando vida a una idea que conecta creatividad y tecnolog铆a.\n",
    "\n",
    "### 1.1 La Inspiraci贸n del Proyecto П\n",
    "\n",
    "LEGO ha sido una de mis pasiones desde la infancia. Me fascinaba c贸mo piezas aparentemente desordenadas pod铆an transformarse en estructuras organizadas y funcionales. Este proyecto busca replicar esa habilidad humana, ense帽ando a una m谩quina a identificar, clasificar y organizar piezas individuales en im谩genes desordenadas. M谩s all谩 de ser un simple experimento t茅cnico, esta iniciativa refleja mi inter茅s por explorar c贸mo la inteligencia artificial puede emular procesos humanos de reconocimiento visual.\n",
    "\n",
    "### 1.2 Prop贸sito y Objetivos \n",
    "\n",
    "El prop贸sito principal del proyecto es desarrollar una soluci贸n pr谩ctica y escalable que demuestre mis habilidades en ciencia de datos y visi贸n por computadora. Los objetivos espec铆ficos incluyen:\n",
    "\n",
    "1. Dise帽ar un pipeline eficiente para la detecci贸n y clasificaci贸n de piezas de LEGO.\n",
    "2. Documentar el proceso de desarrollo, desde la creaci贸n del dataset hasta la implementaci贸n del modelo.\n",
    "3. Generar resultados replicables y visualizaciones claras que destaquen el impacto de mi enfoque t茅cnico.\n",
    "\n",
    "Este proyecto tambi茅n busca ser una base para aplicaciones futuras, como sistemas de clasificaci贸n rob贸tica o asistentes visuales en tiempo real, mostrando la capacidad de escalar esta soluci贸n inicial hacia un impacto m谩s amplio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creaci贸n del Dataset 锔\n",
    "\n",
    "El 茅xito de este proyecto dependi贸 en gran medida de un dataset bien estructurado y diverso que capturara la naturaleza de las piezas de LEGO. El proceso de creaci贸n del dataset fue dividido en dos fases principales: una inicial centrada en los ladrillos b谩sicos y otra posterior dedicada a los studs.\n",
    "\n",
    "### 2.1 Recopilaci贸n de Datos \n",
    "\n",
    "Para la primera fase, seleccion茅 ladrillos b谩sicos de mi colecci贸n, excluyendo tiles y piezas transparentes, y los clasifiqu茅 por dimensiones. En un espacio bien iluminado, dispuse los ladrillos con suficiente separaci贸n para que fueran f谩cilmente distinguibles. Usando la c谩mara de mi m贸vil configurada en modo de baja calidad y captura autom谩tica, gener茅 m谩s de 2000 im谩genes mientras caminaba lentamente por la habitaci贸n, enfoc谩ndome en 谩ngulos t铆picos desde los que un usuario de LEGO observar铆a las piezas.\n",
    "\n",
    "En la segunda fase, mont茅 un set fotogr谩fico casero utilizando una plataforma giratoria hecha con piezas de LEGO. Coloqu茅 nuevos conjuntos de ladrillos sobre esta plataforma y captur茅 im谩genes desde un tr铆pode con el m贸vil, utilizando captura automatizada nuevamente.\n",
    "\n",
    "### 2.2 Anotaci贸n de los Datos \n",
    "\n",
    "En la primera fase, utilic茅 LabelMe para anotar las piezas con bounding boxes en las m谩s de 2000 im谩genes, eliminando aquellas que estaban borrosas. Posteriormente, desarroll茅 scripts para convertir estas anotaciones al formato compatible con YOLO y organizar las carpetas de acuerdo con los requerimientos del modelo.\n",
    "\n",
    "En la segunda fase, utilic茅 un modelo entrenado inicialmente para detectar ladrillos y gener茅 anotaciones de puntos (point annotations) dentro de las bounding boxes recortadas. Un script adicional transform贸 estos puntos en nuevas bounding boxes din谩micas, adapt谩ndose a las dimensiones y posiciones de los studs detectados.\n",
    "\n",
    "### 2.3 Limpieza y Preparaci贸n del Dataset Ч\n",
    "\n",
    "Las im谩genes borrosas o redundantes fueron eliminadas. Para mitigar la falta de calidad en algunas capturas iniciales, implement茅 t茅cnicas de aumento de datos (data augmentation) directamente en el alimentador del modelo durante las sesiones de entrenamiento. Esto incluy贸 rotaciones, variaciones de iluminaci贸n y espejado para incrementar la diversidad de las muestras.\n",
    "\n",
    "### 2.4 Insights para Iteraciones Futuras \n",
    "\n",
    "- **Automatizaci贸n en la anotaci贸n inicial**: Considera herramientas como Supervisely o plataformas que integren anotaci贸n semiautom谩tica para acelerar procesos iniciales de bounding boxes.\n",
    "- **Mejorar la calidad inicial**: Aunque la baja calidad fue 煤til para la primera fase, para futuros proyectos se recomienda una resoluci贸n est谩ndar para maximizar el detalle en las im谩genes.\n",
    "- **Balance de clases**: Implementar an谩lisis de distribuci贸n m谩s temprano en el proceso puede garantizar un balance adecuado en el dataset y evitar clases subrepresentadas.\n",
    "- **Data augmentation externo**: Herramientas como Albumentations o Fastai podr铆an ofrecer t茅cnicas m谩s avanzadas de aumento, como distorsiones geom茅tricas y filtros, fuera del alimentador del modelo.\n",
    "- **Pruebas preliminares del modelo**: Entrenar modelos peque帽os desde el inicio puede revelar r谩pidamente problemas en el dataset, como errores de anotaci贸n o distribuciones desbalanceadas, y ahorrar tiempo en iteraciones posteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecci贸n del Modelo \n",
    "\n",
    "### 3.1 Elecci贸n del Modelo \n",
    "\n",
    "El desaf铆o central del proyecto era dise帽ar un modelo que pudiera identificar piezas individuales de LEGO en im谩genes desordenadas y con condiciones variables de iluminaci贸n y fondo. Para abordar este problema, era crucial elegir un modelo que equilibrara precisi贸n, rapidez y facilidad de implementaci贸n. Tras investigar varias opciones, seleccion茅 YOLO (You Only Look Once), espec铆ficamente la versi贸n YOLOv8n, por las siguientes razones:\n",
    "\n",
    "- **Simplicidad y Configuraci贸n Inicial**: YOLO ofrec铆a una configuraci贸n amigable para mi hardware con capacidades de GPU limitadas. Su implementaci贸n directa me permiti贸 centrarme m谩s en la preparaci贸n del dataset y en los ajustes iterativos.\n",
    "- **Velocidad en Detecci贸n en Tiempo Real**: YOLO es conocido por su capacidad de realizar detecciones en una sola pasada de red neuronal, optimizando tanto el tiempo como el uso de recursos computacionales. Esto result贸 ideal para entrenar y validar r谩pidamente el modelo con un dataset en constante refinamiento.\n",
    "- **Robustez en Ambientes Complejos**: Su arquitectura permite manejar im谩genes con m煤ltiples objetos, incluso en escenarios donde las piezas est谩n parcialmente ocluidas, lo que alineaba perfectamente con las condiciones del proyecto.\n",
    "\n",
    "### 3.2 Estrategia de Entrenamiento y Adaptaci贸n 锔\n",
    "\n",
    "El proceso de entrenamiento incluy贸 los siguientes pasos:\n",
    "\n",
    "- **Creaci贸n y Preparaci贸n del Dataset**: Se defini贸 un pipeline para convertir anotaciones en formato LabelMe a un formato compatible con YOLO. Esto incluy贸 la limpieza de datos, aumento (augmentation) durante el entrenamiento y un split 80-20 para entrenamiento y validaci贸n.\n",
    "- **Hiperpar谩metros**: Ajust茅 los siguientes par谩metros clave para optimizar el rendimiento:\n",
    "    - Tama帽o de im谩genes: Utilic茅 im谩genes redimensionadas para maximizar la compatibilidad con el modelo.\n",
    "    - pocas: Comenc茅 con 50 茅pocas para pruebas r谩pidas, aumentando gradualmente seg煤n los resultados.\n",
    "    - Tasa de aprendizaje inicial: 0.001, con un decaimiento c铆clico (cos_lr).\n",
    "- **Uso de Scripts Personalizados**: Implement茅 scripts para:\n",
    "    - Recortar piezas detectadas en im谩genes, simplificando tareas posteriores de clasificaci贸n.\n",
    "    - Transformar anotaciones de puntos clave en bounding boxes adaptativas seg煤n los studs detectados y dimensiones de entrada.\n",
    "- **Iteraciones y Validaci贸n**: Cada iteraci贸n del modelo fue validada visualizando predicciones sobre nuevas im谩genes del dataset, ajustando hiperpar谩metros seg煤n las m茅tricas de precisi贸n y recall.\n",
    "\n",
    "### 3.3 Ejemplos y Visualizaciones \n",
    "\n",
    "Para esta secci贸n se incluir谩n:\n",
    "\n",
    "- Im谩genes con Bounding Boxes de ladrillos detectados: Visualizaciones de ejemplos representativos de detecciones exitosas, resaltando piezas con m煤ltiples colores y tama帽os.\n",
    "- Comparaci贸n antes y despu茅s del modelo: Mostrar ejemplos de im谩genes con y sin anotaciones generadas autom谩ticamente por el modelo.\n",
    "- Visualizaci贸n de transformaci贸n de keypoints a bounding boxes: Ejemplos ilustrativos de c贸mo las anotaciones de studs se convirtieron en cajas 2D.\n",
    "\n",
    "## 4. Pr贸ximos Pasos \n",
    "\n",
    "El desarrollo iterativo del modelo ha proporcionado un camino claro para expandir el alcance del proyecto. A medida que se contin煤e mejorando, estas iteraciones ayudar谩n a explorar nuevas 谩reas de aplicaci贸n y optimizaci贸n en el reconocimiento visual de LEGO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementaci贸n del Modelo y Validaci贸n \n",
    "\n",
    "### 4.1 Entrenamiento Inicial y Ajustes 锔\n",
    "\n",
    "Una vez seleccionado el modelo YOLOv8n, el entrenamiento se realiz贸 iterativamente para ajustar el modelo a las condiciones espec铆ficas del dataset:\n",
    "\n",
    "- **Inicio del Entrenamiento**: Se utiliz贸 el dataset procesado y anotado para realizar pruebas iniciales con un modelo preentrenado. Estas pruebas se centraron en establecer una base para los par谩metros clave, como el tama帽o de las im谩genes y el n煤mero de 茅pocas.\n",
    "- **Evaluaci贸n Continua**: Durante el entrenamiento, se monitorearon m茅tricas como la precisi贸n y el recall para identificar 谩reas de mejora. Las visualizaciones de las predicciones ayudaron a identificar sesgos o problemas en el dataset.\n",
    "\n",
    "### 4.2 Validaci贸n en Escenarios Controlados И\n",
    "\n",
    "Para evaluar el rendimiento del modelo:\n",
    "\n",
    "- **Pruebas en Dataset Anotado**: Se utilizaron im谩genes del conjunto de validaci贸n para comparar la detecci贸n y clasificaci贸n con las etiquetas originales. Esto permiti贸 identificar las clases o condiciones donde el modelo ten铆a mayor dificultad.\n",
    "- **Pruebas con Transformaciones**: Se aplicaron aumentos artificiales (rotaciones, cambios de iluminaci贸n, etc.) para evaluar la robustez del modelo ante variaciones comunes en la captura de im谩genes.\n",
    "\n",
    "### 4.3 Resultados en Im谩genes Reales \n",
    "\n",
    "El modelo fue probado en escenarios m谩s diversos:\n",
    "\n",
    "- **Colecci贸n No Anotada**: Se seleccionaron im谩genes reales del entorno, no incluidas en el entrenamiento, para validar la capacidad del modelo en condiciones no vistas.\n",
    "- **Evaluaci贸n de Robustez**: Se analizaron las predicciones en piezas o configuraciones no consideradas en el dise帽o inicial del dataset, evaluando su capacidad de generalizaci贸n.\n",
    "\n",
    "### 4.4 Visualizaciones y M茅tricas \n",
    "\n",
    "Para esta secci贸n se incluir谩n:\n",
    "\n",
    "- **Predicciones con Bounding Boxes**: Im谩genes que muestran c贸mo el modelo detecta las piezas, con especial atenci贸n a las detecciones err贸neas o falsas positivas.\n",
    "- **Estad铆sticas Generales**: Tablas y gr谩ficos que presentan las m茅tricas clave: precisi贸n, recall, F1-score, y tiempo promedio por predicci贸n.\n",
    "- **An谩lisis Comparativo**: Comparaci贸n de ejemplos con predicciones y etiquetas originales, mostrando casos representativos de 茅xito y 谩reas de mejora.\n",
    "- **Visualizaci贸n Tipo Spread Grid**: Una visualizaci贸n tipo grid de miniaturas, mostrando im谩genes anotadas aleatorias de todo el dataset.\n",
    "\n",
    "## 5. Pr贸ximos Pasos \n",
    "\n",
    "El desarrollo iterativo del modelo ha proporcionado un camino claro para expandir el alcance del proyecto. A medida que se contin煤e mejorando, estas iteraciones ayudar谩n a explorar nuevas 谩reas de aplicaci贸n y optimizaci贸n en el reconocimiento visual de LEGO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflexi贸n y Futuro \n",
    "\n",
    "### 5.1 Lecciones Aprendidas \n",
    "\n",
    "Este proyecto no solo ampli贸 mis conocimientos t茅cnicos en visi贸n por computadora y machine learning, sino que tambi茅n reforz贸 habilidades esenciales como:\n",
    "\n",
    "- **Gesti贸n de Proyectos T茅cnicos**: Desde la conceptualizaci贸n hasta la ejecuci贸n, aprend铆 a planificar y priorizar tareas clave para lograr un resultado completo.\n",
    "- **Iteraci贸n y Resoluci贸n de Problemas**: Los desaf铆os encontrados, como la selecci贸n inicial de MediaPipe y ajustes en el dataset, me ense帽aron a ser flexible y adaptarme r谩pidamente.\n",
    "- **Documentaci贸n y Visualizaci贸n**: Documentar el proceso de manera clara y crear visualizaciones efectivas fue crucial para comunicar el impacto del trabajo.\n",
    "\n",
    "### 5.2 Mejoras Futuras \n",
    "\n",
    "Si pudiera comenzar de nuevo, considerar铆a:\n",
    "\n",
    "- **Ampliar el Dataset Inicial**: Incluir m谩s clases y piezas m谩s variadas desde el principio habr铆a mejorado la capacidad del modelo para generalizar.\n",
    "- **Explorar Alternativas a YOLO**: Experimentar con otros modelos para comparar rendimiento y adaptabilidad.\n",
    "- **Automatizar Anotaciones**: Implementar t茅cnicas m谩s avanzadas para reducir el tiempo dedicado a tareas manuales.\n",
    "\n",
    "### 5.3 Pr贸ximos Pasos \n",
    "\n",
    "- **Optimizaci贸n del Modelo**: Afinar los hiperpar谩metros y explorar t茅cnicas de fine-tuning m谩s avanzadas.\n",
    "- **Ampliaci贸n del Dataset**: Incorporar nuevos tipos de piezas, incluidos tiles y elementos transparentes.\n",
    "- **Desarrollo de una Interfaz**: Crear una aplicaci贸n interactiva que permita a los usuarios cargar im谩genes y obtener predicciones en tiempo real.\n",
    "- **Exploraci贸n de Nuevas Aplicaciones**: Investigar c贸mo este pipeline podr铆a adaptarse a otros dominios, como la clasificaci贸n de piezas en manufactura o reciclaje.\n",
    "\n",
    "Con estos pasos, espero seguir construyendo sobre este proyecto y expandiendo su alcance e impacto potencial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Introduction**\n",
    "This notebook narrates the development of a project that started as a personal challenge and became a demonstration of creative problem-solving and a deep dive into computer vision. The project explores how computer vision techniques can be used to identify and analyze LEGO bricks. \n",
    "\n",
    "### **Motivation**\n",
    "As a lifelong learner and a problem-solver, I found this project to be a perfect opportunity to apply my curiosity and drive to a practical challenge. It also reflects a significant moment in my life: transitioning from my work in the hospitality industry to pursuing a career in technology, where my skills and passions can have a greater impact.\n",
    "\n",
    "## **Problem Statement**\n",
    "LEGO bricks come in many shapes and sizes, often with subtle differences. The challenge was to create a system capable of identifying individual bricks and determining their dimensions using computer vision techniques. While the initial scope was limited to 26 distinct brick types, the problem presented several complexities:\n",
    "\n",
    "- Variability in brick dimensions and shapes.\n",
    "- The need for accurate annotations to train detection models.\n",
    "- Limited data availability, requiring adaptive solutions.\n",
    "\n",
    "## **Methodology**\n",
    "\n",
    "### **1. Initial Approach: Direct Brick Classification**\n",
    "The project began with the idea of classifying LEGO bricks directly using object detection models like YOLO. However, early experimentation revealed significant challenges:\n",
    "\n",
    "- **Dataset limitations**: The dataset was small, unbalanced, and contained subtle differences between classes.\n",
    "- **Model performance**: Direct classification yielded low accuracy due to the aforementioned challenges.\n",
    "\n",
    "### **2. Adaptation: Focusing on Stud Detection**\n",
    "To overcome these hurdles, the approach shifted towards detecting studs (the small bumps on LEGO bricks) and using their positions to infer brick dimensions. This adjustment allowed for:\n",
    "\n",
    "- Simplified classification logic.\n",
    "- Better utilization of the dataset by focusing on a common feature across all bricks.\n",
    "\n",
    "The process involved:\n",
    "- Annotating images with stud positions using LabelMe.\n",
    "- Training a YOLOv8 model to detect studs.\n",
    "- Developing algorithms to compute brick dimensions from the detected stud positions.\n",
    "\n",
    "### **3. Experimentation and Iteration**\n",
    "The development process was highly iterative, involving:\n",
    "- Multiple rounds of dataset refinement and augmentation.\n",
    "- Experimenting with model hyperparameters to improve detection accuracy.\n",
    "- Validating the dimension-calculation algorithms with test images.\n",
    "\n",
    "## **Results**\n",
    "The project achieved:\n",
    "- **Accurate stud detection**: The trained YOLO model demonstrated high precision and recall in detecting studs.\n",
    "- **Dimension calculation**: Algorithms successfully inferred the dimensions of various bricks using detected stud positions.\n",
    "\n",
    "### **Visualizations**\n",
    "- Examples of stud detection with bounding boxes.\n",
    "- Graphs showing model performance metrics (precision, recall, F1 score).\n",
    "\n",
    "## **Reflection and Learnings**\n",
    "This project exemplified the power of curiosity and adaptability in tackling challenges. Key takeaways include:\n",
    "\n",
    "1. The importance of flexibility: Pivoting to a simpler approach yielded better results and deeper insights.\n",
    "2. Learning through experimentation: Iterative testing refined the solution and improved my understanding of the problem.\n",
    "3. A new direction: The project reaffirmed my passion for learning and solving complex problems, motivating me to transition into a technology-focused career.\n",
    "\n",
    "## **Future Directions**\n",
    "This project is a starting point. Potential next steps include:\n",
    "- Expanding the dataset to include more brick types.\n",
    "- Refining the detection and dimension-calculation algorithms for production-level accuracy.\n",
    "- Scaling the solution for real-world applications, such as automated sorting or inventory management.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Code and Implementation**\n",
    "### **1. Data Preparation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "```python\n",
    "# Example code for data preprocessing\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess images\n",
    "image_dir = 'data/raw'\n",
    "processed_dir = 'data/processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "for image_file in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    # Resize, normalize, and save\n",
    "    processed_image = cv2.resize(image, (640, 640))\n",
    "    cv2.imwrite(os.path.join(processed_dir, image_file), processed_image)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **2. Model Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "```python\n",
    "# Example code for training the YOLO model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(data='data.yaml', epochs=50, imgsz=640)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **3. Dimension Calculation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "```python\n",
    "# Algorithm to calculate brick dimensions from stud positions\n",
    "def calculate_dimensions(stud_positions):\n",
    "    rows = len(set([pos[1] for pos in stud_positions]))  # Unique Y-coordinates\n",
    "    cols = len(set([pos[0] for pos in stud_positions]))  # Unique X-coordinates\n",
    "    return rows, cols\n",
    "\n",
    "# Example usage\n",
    "stud_positions = [(10, 20), (10, 40), (30, 20), (30, 40)]\n",
    "dimensions = calculate_dimensions(stud_positions)\n",
    "print(f\"Brick dimensions: {dimensions[0]} rows x {dimensions[1]} columns\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **Closing Remarks**\n",
    "This notebook not only showcases a technical solution but also tells the story of how a love for learning and persistence can turn a simple idea into a meaningful project. By sharing this journey, I aim to inspire others and demonstrate my readiness for new challenges in the field of technology.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
